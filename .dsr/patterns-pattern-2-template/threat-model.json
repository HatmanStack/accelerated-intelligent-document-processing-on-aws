[
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-001",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Information Disclosure",
    "severity": "Medium",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction",
    "title": "Potential sensitive data exposure via insufficient guardrail configuration",
    "issue": "The template conditionally applies Bedrock guardrails for GenAI operations based on provided parameters. If guardrails are not configured (empty GuardrailId and GuardrailVersion), the LLM operations could potentially expose sensitive information from documents or produce unsafe outputs.",
    "attack_vector": "If guardrails aren't configured, an attacker could potentially craft inputs that cause the LLM to expose sensitive information from processed documents or produce harmful content.",
    "impact": "Potential exposure of sensitive information from processed documents, generation of harmful content, or information leakage through model responses.",
    "remediation": "Ensure guardrails are always configured by making the BedrockGuardrailId and BedrockGuardrailVersion parameters required rather than optional, or implement additional validation logic to ensure guardrails are properly configured before allowing document processing.",
    "priority": 2,
    "estimated_effort": "Low",
    "cwe_id": "CWE-200",
    "compliance_violations": ["AI/ML Security Best Practices"],
    "references": ["https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-002",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Tampering",
    "severity": "Medium",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, ProcessResultsFunction, SummarizationFunction",
    "title": "Missing input validation for document processing",
    "issue": "The Lambda functions don't appear to implement comprehensive input validation for incoming documents or parameters. This could allow maliciously crafted inputs to potentially bypass security controls or cause unexpected behavior.",
    "attack_vector": "An attacker could submit specially crafted documents or inputs designed to bypass validation checks, manipulate AI models, or cause unexpected behavior in the processing pipeline.",
    "impact": "Potential security bypass, data manipulation, or denial of service in document processing pipeline.",
    "remediation": "Implement comprehensive input validation in all Lambda functions to validate document formats, sizes, content types, and processing parameters before performing operations. Ensure that all input sources are properly sanitized and validated.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-20",
    "compliance_violations": ["OWASP Top 10 API Security - API3:2023 Broken Object Property Level Authorization"],
    "references": ["https://owasp.org/API-Security/editions/2023/en/0xa3-broken-object-property-level-authorization/"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-003",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Elevation of Privilege",
    "severity": "Medium",
    "resource_type": "AWS::IAM::Policy",
    "resource_name": "OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction Policies",
    "title": "Overly permissive Bedrock model access",
    "issue": "The IAM policies for Lambda functions grant broad access to all Bedrock foundation models using wildcard resources (`arn:aws:bedrock:*::foundation-model/*`). This violates the principle of least privilege and could allow unintended model access.",
    "attack_vector": "If a Lambda function is compromised, an attacker could potentially invoke any Bedrock model, including those that might have higher costs or different security characteristics than intended.",
    "impact": "Potential for unauthorized model usage, increased costs, or access to models with different security properties than intended for the application.",
    "remediation": "Restrict Bedrock model access to only the specific models required for each function's operation. Replace wildcard resources with explicit ARNs for each approved model.",
    "priority": 2,
    "estimated_effort": "Low",
    "cwe_id": "CWE-272",
    "compliance_violations": ["AWS Well-Architected Framework - Security Pillar"],
    "references": ["https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_permissions_least_privileges.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-004",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Repudiation",
    "severity": "Medium",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "All Lambda Functions",
    "title": "Insufficient audit logging for AI operations",
    "issue": "While CloudWatch logging is implemented, there appears to be no specific audit logging for critical AI operations such as model invocations, classification decisions, or extraction results. This could make it difficult to trace actions or investigate security incidents.",
    "attack_vector": "Without comprehensive audit logs, an attacker could potentially perform malicious activities through the AI system without leaving sufficient evidence trails.",
    "impact": "Difficulty in detecting, investigating, and responding to security incidents or compliance violations involving AI processing.",
    "remediation": "Implement comprehensive audit logging for all AI operations, including model invocations, inputs (with appropriate PII redaction), outputs, and decision points. Store these logs securely with appropriate retention periods.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-778",
    "compliance_violations": ["NIST AI Risk Management Framework"],
    "references": ["https://www.nist.gov/itl/ai-risk-management-framework"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-005",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Denial of Service",
    "severity": "Medium",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "All Lambda Functions",
    "title": "Missing concurrency controls and throttling protection",
    "issue": "The Lambda functions do not have reserved concurrency or provisioned concurrency settings, which could lead to resource exhaustion under heavy load or during DoS attacks.",
    "attack_vector": "An attacker could flood the system with document processing requests, potentially exhausting Lambda concurrency limits and causing legitimate requests to be throttled.",
    "impact": "Service disruption for legitimate users, processing delays, or complete denial of service under attack conditions.",
    "remediation": "Implement appropriate concurrency controls for Lambda functions, including reserved concurrency to prevent resource exhaustion. Consider implementing request throttling at the API layer and monitoring for unusual traffic patterns.",
    "priority": 3,
    "estimated_effort": "Low",
    "cwe_id": "CWE-400",
    "compliance_violations": ["AWS Well-Architected Framework - Reliability Pillar"],
    "references": ["https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-006",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Information Disclosure",
    "severity": "Low",
    "resource_type": "AWS::CloudWatch::Dashboard",
    "resource_name": "Dashboard",
    "title": "Potential exposure of processing metrics in CloudWatch dashboard",
    "issue": "The CloudWatch dashboard could potentially expose sensitive information about document processing patterns, volume, and performance characteristics. Without proper dashboard access controls, this information could be visible to unauthorized users.",
    "attack_vector": "An attacker with access to the AWS console but without need-to-know for this specific application could view the dashboard and gain insights into processing patterns, document volumes, or potential system weaknesses.",
    "impact": "Exposure of operational patterns and potential intelligence gathering for more targeted attacks.",
    "remediation": "Ensure CloudWatch dashboards are only accessible to authorized personnel through appropriate IAM policies. Consider implementing additional access controls and audit logging for dashboard access.",
    "priority": 4,
    "estimated_effort": "Low",
    "cwe_id": "CWE-668",
    "compliance_violations": ["AWS Well-Architected Framework - Security Pillar"],
    "references": ["https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards_Permissions.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-007",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Tampering",
    "severity": "Medium",
    "resource_type": "AWS::CloudFormation::CustomResource",
    "resource_name": "UpdateDefaultConfig, UpdateSchemaConfig",
    "title": "Potential insecure handling of configuration data",
    "issue": "The template uses CustomResources to update configuration data without clear validation or integrity checks. This could potentially allow tampering with configuration settings if the UpdateConfigurationFunction is compromised.",
    "attack_vector": "If the UpdateConfigurationFunction has vulnerabilities or is compromised, an attacker could potentially manipulate configuration data, affecting document processing security or functionality.",
    "impact": "Potential manipulation of AI processing parameters, security controls, or workflow logic, leading to security bypasses or unexpected system behavior.",
    "remediation": "Implement comprehensive validation, integrity checking, and change auditing for all configuration updates. Consider adding approval workflows for critical configuration changes and integrity verification mechanisms.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-642",
    "compliance_violations": ["AWS Well-Architected Framework - Security Pillar"],
    "references": ["https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_change_management_secure_ci_cd.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-008",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Elevation of Privilege",
    "severity": "Low",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "OCRFunction",
    "title": "Overly permissive Textract permissions",
    "issue": "The OCRFunction has broad permissions to Textract APIs with a wildcard resource ('*') since Textract doesn't support resource-level permissions. While unavoidable due to AWS service limitations, this still represents a deviation from least privilege principles.",
    "attack_vector": "If the OCRFunction is compromised, an attacker could potentially use its permissions to perform Textract operations on any documents accessible to the function, not just those intended for processing.",
    "impact": "Potential unauthorized use of Textract services, leading to increased costs or processing of unintended documents.",
    "remediation": "While resource-level permissions aren't supported for Textract, implement additional application-level controls to ensure the function only processes appropriate documents. Consider implementing request validation, access logging, and monitoring for unusual Textract usage patterns.",
    "priority": 3,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-272",
    "compliance_violations": ["AWS Well-Architected Framework - Security Pillar"],
    "references": ["https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_permissions_least_privileges.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-009",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Spoofing",
    "severity": "Medium",
    "resource_type": "AWS::Lambda::Function",
    "resource_name": "All Lambda Functions with AppSync Access",
    "title": "Potential unauthorized AppSync API access",
    "issue": "Lambda functions have broad permissions to invoke AppSync GraphQL Mutation operations. Without proper request authentication and authorization within the functions, this could potentially allow unauthorized mutations.",
    "attack_vector": "If a Lambda function is compromised, an attacker could potentially execute unauthorized GraphQL mutations, potentially manipulating document status or other data.",
    "impact": "Unauthorized data manipulation, status changes, or system state modifications through GraphQL mutations.",
    "remediation": "Implement proper authentication and authorization checks within Lambda functions before executing GraphQL mutations. Consider implementing request signing or other mechanisms to verify the authenticity of mutation requests.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-306",
    "compliance_violations": ["OWASP Top 10 API Security - API2:2023 Broken Authentication"],
    "references": ["https://owasp.org/API-Security/editions/2023/en/0xa2-broken-authentication/"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-PATTERN-2-THREAT-010",
    "stack": "aws-genai-idp-pattern-2",
    "stride_category": "Information Disclosure",
    "severity": "Low",
    "resource_type": "AWS::Logs::LogGroup",
    "resource_name": "All LogGroups",
    "title": "Potential sensitive data exposure in logs",
    "issue": "While logs are encrypted with a customer-managed KMS key, there's no explicit control to prevent sensitive data from being logged in CloudWatch. Processing document text might inadvertently log PII or other sensitive information.",
    "attack_vector": "An attacker with access to CloudWatch logs could potentially extract sensitive information that was inadvertently logged during document processing.",
    "impact": "Exposure of sensitive information from processed documents, potentially including PII or confidential business information.",
    "remediation": "Implement log sanitization mechanisms to redact or mask sensitive information before logging. Consider implementing log review procedures and additional access controls for log data.",
    "priority": 3,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-532",
    "compliance_violations": ["GDPR Article 32", "CCPA"],
    "references": ["https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/mask-sensitive-log-data.html"],
    "status": "Open"
  }
]