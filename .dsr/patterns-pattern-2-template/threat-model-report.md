# CloudFormation Threat Model Report

**Template:** `threat-model.md`  
**Analysis Date:** 2025-08-19_17-08-11  
**Generated By:** CloudFormation Threat Modeling Tool  

## Executive Summary

This threat model analysis identified **10** security threats. The analysis reveals **0** critical, **0** high, **7** medium, and **3** low severity findings.

## Priority Actions

### 2. Ensure guardrails are always configured by making the BedrockGuardrailId and BedrockGuardrailVersion parameters required rather than optional, or implement additional validation logic to ensure guardrails are properly configured before allowing document processing.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-001  
**Business Impact:** Potential exposure of sensitive information from processed documents, generation of harmful content, or information leakage through model responses.

### 2. Implement comprehensive input validation in all Lambda functions to validate document formats, sizes, content types, and processing parameters before performing operations. Ensure that all input sources are properly sanitized and validated.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-002  
**Business Impact:** Potential security bypass, data manipulation, or denial of service in document processing pipeline.

### 2. Restrict Bedrock model access to only the specific models required for each function's operation. Replace wildcard resources with explicit ARNs for each approved model.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-003  
**Business Impact:** Potential for unauthorized model usage, increased costs, or access to models with different security properties than intended for the application.

### 2. Implement comprehensive audit logging for all AI operations, including model invocations, inputs (with appropriate PII redaction), outputs, and decision points. Store these logs securely with appropriate retention periods.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-004  
**Business Impact:** Difficulty in detecting, investigating, and responding to security incidents or compliance violations involving AI processing.

### 2. Implement comprehensive validation, integrity checking, and change auditing for all configuration updates. Consider adding approval workflows for critical configuration changes and integrity verification mechanisms.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-007  
**Business Impact:** Potential manipulation of AI processing parameters, security controls, or workflow logic, leading to security bypasses or unexpected system behavior.

### 2. Implement proper authentication and authorization checks within Lambda functions before executing GraphQL mutations. Consider implementing request signing or other mechanisms to verify the authenticity of mutation requests.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-009  
**Business Impact:** Unauthorized data manipulation, status changes, or system state modifications through GraphQL mutations.

### 3. Implement appropriate concurrency controls for Lambda functions, including reserved concurrency to prevent resource exhaustion. Consider implementing request throttling at the API layer and monitoring for unusual traffic patterns.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-005  
**Business Impact:** Service disruption for legitimate users, processing delays, or complete denial of service under attack conditions.

### 3. While resource-level permissions aren't supported for Textract, implement additional application-level controls to ensure the function only processes appropriate documents. Consider implementing request validation, access logging, and monitoring for unusual Textract usage patterns.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-008  
**Business Impact:** Potential unauthorized use of Textract services, leading to increased costs or processing of unintended documents.

### 3. Implement log sanitization mechanisms to redact or mask sensitive information before logging. Consider implementing log review procedures and additional access controls for log data.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-010  
**Business Impact:** Exposure of sensitive information from processed documents, potentially including PII or confidential business information.

### 4. Ensure CloudWatch dashboards are only accessible to authorized personnel through appropriate IAM policies. Consider implementing additional access controls and audit logging for dashboard access.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-PATTERN-2-THREAT-006  
**Business Impact:** Exposure of operational patterns and potential intelligence gathering for more targeted attacks.



## Detailed Threat Analysis

## Medium Severity Threats

### AWS-GENAI-IDP-PATTERN-2-THREAT-001: Potential sensitive data exposure via insufficient guardrail configuration

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction` (AWS::Lambda::Function)  
**CWE ID:** CWE-200

#### Issue
The template conditionally applies Bedrock guardrails for GenAI operations based on provided parameters. If guardrails are not configured (empty GuardrailId and GuardrailVersion), the LLM operations could potentially expose sensitive information from documents or produce unsafe outputs.

#### Attack Vector
If guardrails aren't configured, an attacker could potentially craft inputs that cause the LLM to expose sensitive information from processed documents or produce harmful content.

#### Potential Impact
Potential exposure of sensitive information from processed documents, generation of harmful content, or information leakage through model responses.

#### Remediation
Ensure guardrails are always configured by making the BedrockGuardrailId and BedrockGuardrailVersion parameters required rather than optional, or implement additional validation logic to ensure guardrails are properly configured before allowing document processing.

**References:**
- https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-002: Missing input validation for document processing

**STRIDE Category:** Tampering  
**Affected Resource:** `OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, ProcessResultsFunction, SummarizationFunction` (AWS::Lambda::Function)  
**CWE ID:** CWE-20

#### Issue
The Lambda functions don't appear to implement comprehensive input validation for incoming documents or parameters. This could allow maliciously crafted inputs to potentially bypass security controls or cause unexpected behavior.

#### Attack Vector
An attacker could submit specially crafted documents or inputs designed to bypass validation checks, manipulate AI models, or cause unexpected behavior in the processing pipeline.

#### Potential Impact
Potential security bypass, data manipulation, or denial of service in document processing pipeline.

#### Remediation
Implement comprehensive input validation in all Lambda functions to validate document formats, sizes, content types, and processing parameters before performing operations. Ensure that all input sources are properly sanitized and validated.

**References:**
- https://owasp.org/API-Security/editions/2023/en/0xa3-broken-object-property-level-authorization/

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-003: Overly permissive Bedrock model access

**STRIDE Category:** Elevation of Privilege  
**Affected Resource:** `OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction Policies` (AWS::IAM::Policy)  
**CWE ID:** CWE-272

#### Issue
The IAM policies for Lambda functions grant broad access to all Bedrock foundation models using wildcard resources (`arn:aws:bedrock:*::foundation-model/*`). This violates the principle of least privilege and could allow unintended model access.

#### Attack Vector
If a Lambda function is compromised, an attacker could potentially invoke any Bedrock model, including those that might have higher costs or different security characteristics than intended.

#### Potential Impact
Potential for unauthorized model usage, increased costs, or access to models with different security properties than intended for the application.

#### Remediation
Restrict Bedrock model access to only the specific models required for each function's operation. Replace wildcard resources with explicit ARNs for each approved model.

**References:**
- https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_permissions_least_privileges.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-004: Insufficient audit logging for AI operations

**STRIDE Category:** Repudiation  
**Affected Resource:** `All Lambda Functions` (AWS::Lambda::Function)  
**CWE ID:** CWE-778

#### Issue
While CloudWatch logging is implemented, there appears to be no specific audit logging for critical AI operations such as model invocations, classification decisions, or extraction results. This could make it difficult to trace actions or investigate security incidents.

#### Attack Vector
Without comprehensive audit logs, an attacker could potentially perform malicious activities through the AI system without leaving sufficient evidence trails.

#### Potential Impact
Difficulty in detecting, investigating, and responding to security incidents or compliance violations involving AI processing.

#### Remediation
Implement comprehensive audit logging for all AI operations, including model invocations, inputs (with appropriate PII redaction), outputs, and decision points. Store these logs securely with appropriate retention periods.

**References:**
- https://www.nist.gov/itl/ai-risk-management-framework

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-005: Missing concurrency controls and throttling protection

**STRIDE Category:** Denial of Service  
**Affected Resource:** `All Lambda Functions` (AWS::Lambda::Function)  
**CWE ID:** CWE-400

#### Issue
The Lambda functions do not have reserved concurrency or provisioned concurrency settings, which could lead to resource exhaustion under heavy load or during DoS attacks.

#### Attack Vector
An attacker could flood the system with document processing requests, potentially exhausting Lambda concurrency limits and causing legitimate requests to be throttled.

#### Potential Impact
Service disruption for legitimate users, processing delays, or complete denial of service under attack conditions.

#### Remediation
Implement appropriate concurrency controls for Lambda functions, including reserved concurrency to prevent resource exhaustion. Consider implementing request throttling at the API layer and monitoring for unusual traffic patterns.

**References:**
- https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-007: Potential insecure handling of configuration data

**STRIDE Category:** Tampering  
**Affected Resource:** `UpdateDefaultConfig, UpdateSchemaConfig` (AWS::CloudFormation::CustomResource)  
**CWE ID:** CWE-642

#### Issue
The template uses CustomResources to update configuration data without clear validation or integrity checks. This could potentially allow tampering with configuration settings if the UpdateConfigurationFunction is compromised.

#### Attack Vector
If the UpdateConfigurationFunction has vulnerabilities or is compromised, an attacker could potentially manipulate configuration data, affecting document processing security or functionality.

#### Potential Impact
Potential manipulation of AI processing parameters, security controls, or workflow logic, leading to security bypasses or unexpected system behavior.

#### Remediation
Implement comprehensive validation, integrity checking, and change auditing for all configuration updates. Consider adding approval workflows for critical configuration changes and integrity verification mechanisms.

**References:**
- https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_change_management_secure_ci_cd.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-009: Potential unauthorized AppSync API access

**STRIDE Category:** Spoofing  
**Affected Resource:** `All Lambda Functions with AppSync Access` (AWS::Lambda::Function)  
**CWE ID:** CWE-306

#### Issue
Lambda functions have broad permissions to invoke AppSync GraphQL Mutation operations. Without proper request authentication and authorization within the functions, this could potentially allow unauthorized mutations.

#### Attack Vector
If a Lambda function is compromised, an attacker could potentially execute unauthorized GraphQL mutations, potentially manipulating document status or other data.

#### Potential Impact
Unauthorized data manipulation, status changes, or system state modifications through GraphQL mutations.

#### Remediation
Implement proper authentication and authorization checks within Lambda functions before executing GraphQL mutations. Consider implementing request signing or other mechanisms to verify the authenticity of mutation requests.

**References:**
- https://owasp.org/API-Security/editions/2023/en/0xa2-broken-authentication/

---

## Low Severity Threats

### AWS-GENAI-IDP-PATTERN-2-THREAT-006: Potential exposure of processing metrics in CloudWatch dashboard

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `Dashboard` (AWS::CloudWatch::Dashboard)  
**CWE ID:** CWE-668

#### Issue
The CloudWatch dashboard could potentially expose sensitive information about document processing patterns, volume, and performance characteristics. Without proper dashboard access controls, this information could be visible to unauthorized users.

#### Attack Vector
An attacker with access to the AWS console but without need-to-know for this specific application could view the dashboard and gain insights into processing patterns, document volumes, or potential system weaknesses.

#### Potential Impact
Exposure of operational patterns and potential intelligence gathering for more targeted attacks.

#### Remediation
Ensure CloudWatch dashboards are only accessible to authorized personnel through appropriate IAM policies. Consider implementing additional access controls and audit logging for dashboard access.

**References:**
- https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards_Permissions.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-008: Overly permissive Textract permissions

**STRIDE Category:** Elevation of Privilege  
**Affected Resource:** `OCRFunction` (AWS::Lambda::Function)  
**CWE ID:** CWE-272

#### Issue
The OCRFunction has broad permissions to Textract APIs with a wildcard resource ('*') since Textract doesn't support resource-level permissions. While unavoidable due to AWS service limitations, this still represents a deviation from least privilege principles.

#### Attack Vector
If the OCRFunction is compromised, an attacker could potentially use its permissions to perform Textract operations on any documents accessible to the function, not just those intended for processing.

#### Potential Impact
Potential unauthorized use of Textract services, leading to increased costs or processing of unintended documents.

#### Remediation
While resource-level permissions aren't supported for Textract, implement additional application-level controls to ensure the function only processes appropriate documents. Consider implementing request validation, access logging, and monitoring for unusual Textract usage patterns.

**References:**
- https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/sec_permissions_least_privileges.html

---

### AWS-GENAI-IDP-PATTERN-2-THREAT-010: Potential sensitive data exposure in logs

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `All LogGroups` (AWS::Logs::LogGroup)  
**CWE ID:** CWE-532

#### Issue
While logs are encrypted with a customer-managed KMS key, there's no explicit control to prevent sensitive data from being logged in CloudWatch. Processing document text might inadvertently log PII or other sensitive information.

#### Attack Vector
An attacker with access to CloudWatch logs could potentially extract sensitive information that was inadvertently logged during document processing.

#### Potential Impact
Exposure of sensitive information from processed documents, potentially including PII or confidential business information.

#### Remediation
Implement log sanitization mechanisms to redact or mask sensitive information before logging. Consider implementing log review procedures and additional access controls for log data.

**References:**
- https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/mask-sensitive-log-data.html

---



---

*This report was generated automatically using STRIDE threat modeling methodology.*