[
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-001",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Elevation of Privilege",
    "severity": "High",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction",
    "title": "Overly Permissive IAM Policies for Lambda Functions",
    "issue": "Multiple Lambda functions have overly broad permissions such as S3 CRUD permissions on entire buckets and Bedrock access to all foundation models, which violates the principle of least privilege. This creates unnecessary access paths and increases the attack surface.",
    "attack_vector": "If one of the Lambda functions is compromised (e.g., through code injection or dependency vulnerabilities), an attacker could leverage the broad permissions to access, modify, or delete data across multiple buckets, or use expensive Bedrock models to run unauthorized workloads.",
    "impact": "Unauthorized data access, potential data breaches, excessive AWS costs from unauthorized model usage, and potential violation of data protection regulations.",
    "remediation": "Implement more granular IAM policies by limiting S3 access to specific paths/prefixes needed by each function. For Bedrock, specify only the exact models needed by each function rather than allowing all foundation models. Also consider using resource-based conditions to further restrict access.",
    "priority": 1,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-272",
    "compliance_violations": ["CIS AWS Foundations Benchmark 1.16", "AWS Well-Architected Security Pillar"],
    "references": ["https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-002",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Repudiation",
    "severity": "Medium",
    "resource_type": "AWS::Serverless::StateMachine",
    "resource_name": "DocumentProcessingStateMachine",
    "title": "Execution History Could Expose Sensitive Data",
    "issue": "The Step Functions state machine is configured with 'IncludeExecutionData: true', which means that potentially sensitive document data could be included in the execution history and logs, creating a risk of sensitive information disclosure.",
    "attack_vector": "An attacker with access to the CloudWatch logs or Step Functions execution history could extract sensitive information from processed documents without directly accessing the source data.",
    "impact": "Potential exposure of confidential information from processed documents, which could lead to data breaches and regulatory violations.",
    "remediation": "Set 'IncludeExecutionData: false' in the Step Functions logging configuration to prevent sensitive data from being logged. Implement data minimization in the workflow by ensuring that sensitive information is not passed between state machine steps unless absolutely necessary.",
    "priority": 2,
    "estimated_effort": "Low",
    "cwe_id": "CWE-532",
    "compliance_violations": ["GDPR Article 5", "CCPA", "PCI DSS Requirement 3.4"],
    "references": ["https://docs.aws.amazon.com/step-functions/latest/dg/cloudwatch-logs.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-003",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Information Disclosure",
    "severity": "Medium",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "All Lambda Functions",
    "title": "Possible Sensitive Data Exposure in Lambda Logs",
    "issue": "Lambda functions processing document data may log sensitive information as part of their execution, especially when running at DEBUG or INFO log levels. There's no evidence of log filtering or redaction mechanisms for PII or sensitive content.",
    "attack_vector": "An attacker with access to CloudWatch logs could extract sensitive information from log entries without needing direct access to the data stores.",
    "impact": "Unauthorized exposure of confidential information, potential compliance violations, and increased risk of data breaches.",
    "remediation": "Implement log sanitization in all Lambda functions to redact or mask sensitive data before logging. Set appropriate log levels for production (WARN or ERROR rather than DEBUG or INFO). Consider implementing a centralized logging solution with PII detection and redaction capabilities.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-532",
    "compliance_violations": ["GDPR Article 32", "HIPAA Security Rule"],
    "references": ["https://docs.aws.amazon.com/lambda/latest/dg/logging-using-cloudwatch-logs.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-004",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Tampering",
    "severity": "Medium",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "All Lambda Functions",
    "title": "No Input Validation for Document Processing",
    "issue": "There's no evidence of input validation or sanitization for incoming documents before processing. This could lead to processing of malicious files or unexpected content that might compromise the system.",
    "attack_vector": "An attacker could upload specially crafted documents designed to exploit vulnerabilities in the document processing libraries or cause the system to behave unexpectedly.",
    "impact": "Potential denial of service through resource exhaustion, code injection if vulnerabilities exist in processing libraries, or data corruption.",
    "remediation": "Implement comprehensive input validation for all document inputs. Add file type verification, size limits, content scanning, and sanitization before processing. Consider integrating with a malware scanning solution for uploaded documents.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-20",
    "compliance_violations": ["OWASP API Security Top 10 - API8:2023 Security Misconfiguration"],
    "references": ["https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-005",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Denial of Service",
    "severity": "Medium",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "OCRFunction, ClassificationFunction, ExtractionFunction",
    "title": "No Resource Throttling or Quotas",
    "issue": "The template lacks defined concurrency limits, quotas, or rate limiting for Lambda functions. This makes the system vulnerable to resource exhaustion attacks or unintentional DoS during high traffic periods.",
    "attack_vector": "An attacker could trigger many simultaneous document processing requests, potentially causing resource exhaustion, increased costs, or service disruption.",
    "impact": "Service unavailability, excessive AWS costs, degraded performance for legitimate users, and potential failure to meet SLAs.",
    "remediation": "Implement reserved concurrency for critical Lambda functions. Set up appropriate throttling and rate limiting at the API level. Consider implementing a queue-based architecture for handling high volumes of document processing requests.",
    "priority": 3,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-770",
    "compliance_violations": ["AWS Well-Architected Framework - Reliability Pillar"],
    "references": ["https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-006",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Information Disclosure",
    "severity": "High",
    "resource_type": "AWS::CloudFormation::CustomResource",
    "resource_name": "UpdateSchemaConfig, UpdateDefaultConfig",
    "title": "Sensitive Configuration Data in CloudFormation",
    "issue": "The template contains extensive configuration details including system prompts and task prompts for AI models directly in CloudFormation. These could contain sensitive information or reveal internal business logic that should not be visible in infrastructure code.",
    "attack_vector": "An attacker with access to CloudFormation templates or stack history could extract sensitive prompts or business logic that could be used to understand or manipulate the document processing system.",
    "impact": "Exposure of intellectual property, business logic, or prompt engineering that gives competitive advantage. Could enable attackers to craft inputs that manipulate model outputs.",
    "remediation": "Move sensitive configuration data to secure parameter storage like AWS Systems Manager Parameter Store or AWS Secrets Manager, and reference them in CloudFormation. Use KMS encryption for all sensitive configuration values.",
    "priority": 1,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-200",
    "compliance_violations": ["NIST 800-53 SC-28", "ISO 27001 A.8.2.3"],
    "references": ["https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-007",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Tampering",
    "severity": "High",
    "resource_type": "AWS::CloudFormation::CustomResource",
    "resource_name": "UpdateSchemaConfig",
    "title": "No Validation of Schema Configuration Updates",
    "issue": "The system uses custom resources to update configuration schemas but doesn't appear to implement validation of configuration changes. This could lead to injection of malicious configuration that affects the behavior of document processing functions.",
    "attack_vector": "An attacker with access to the configuration update mechanism could inject malicious configuration data that could alter system behavior, extract information, or create security vulnerabilities.",
    "impact": "System compromise, data exfiltration, or injection of malicious behavior into the document processing pipeline.",
    "remediation": "Implement strict validation of all configuration changes against a well-defined schema. Add integrity checks and approval workflows for configuration changes. Consider implementing versioning for configurations with rollback capabilities.",
    "priority": 1,
    "estimated_effort": "High",
    "cwe_id": "CWE-915",
    "compliance_violations": ["NIST 800-53 CM-3", "ISO 27001 A.14.2.2"],
    "references": ["https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-008",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Spoofing",
    "severity": "Medium",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "All Lambda Functions",
    "title": "No Authentication for Internal API Calls",
    "issue": "The template shows Lambda functions making calls to AppSync GraphQL APIs but does not clearly define or enforce authentication between these internal services.",
    "attack_vector": "If an attacker gains access to execute code within the environment, they could potentially make unauthorized calls to internal APIs without proper authentication checks.",
    "impact": "Unauthorized data manipulation, injection of false data into the processing pipeline, or exfiltration of sensitive information from internal services.",
    "remediation": "Implement proper service-to-service authentication using IAM roles with request signing. Consider implementing API keys or JWT tokens for GraphQL API access with appropriate authorization checks.",
    "priority": 2,
    "estimated_effort": "Medium",
    "cwe_id": "CWE-306",
    "compliance_violations": ["OWASP API Security Top 10 - API2:2023 Broken Authentication"],
    "references": ["https://docs.aws.amazon.com/appsync/latest/devguide/security-authz.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-009",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Information Disclosure",
    "severity": "Medium",
    "resource_type": "AWS::CloudWatch::Dashboard",
    "resource_name": "Dashboard",
    "title": "Sensitive Information in CloudWatch Dashboard",
    "issue": "The CloudWatch dashboard could potentially expose sensitive operational data and metrics about the document processing system, including processing volumes, error rates, and performance characteristics.",
    "attack_vector": "An attacker with access to CloudWatch could gather intelligence about system behavior, identify potential vulnerabilities, or monitor for specific patterns that might indicate high-value document processing.",
    "impact": "Information disclosure that provides attackers with insights into system behavior and potential attack vectors. Could reveal business-sensitive information about document processing volumes.",
    "remediation": "Implement strict access controls on CloudWatch dashboards. Review dashboard content to ensure it doesn't reveal sensitive information. Consider creating separate dashboards for different user roles with appropriate access controls.",
    "priority": 3,
    "estimated_effort": "Low",
    "cwe_id": "CWE-200",
    "compliance_violations": ["ISO 27001 A.8.2.3"],
    "references": ["https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards_Sharing.html"],
    "status": "Open"
  },
  {
    "id": "AWS-GENAI-IDP-ACCELERATOR-THREAT-010",
    "stack": "AWS GenAI IDP Accelerator",
    "stride_category": "Information Disclosure",
    "severity": "High",
    "resource_type": "AWS::Serverless::Function",
    "resource_name": "All Lambda Functions with Bedrock Access",
    "title": "Potential Data Leakage to External AI Models",
    "issue": "Lambda functions that interact with Amazon Bedrock or other LLM services could potentially send sensitive document data to these services without proper controls for data minimization or filtering.",
    "attack_vector": "Sensitive information from processed documents could be included in prompts sent to external AI services, where it might be used for model training or retained in logs.",
    "impact": "Unauthorized disclosure of sensitive or regulated information to third-party AI services, potential regulatory compliance violations, and data privacy concerns.",
    "remediation": "Implement data minimization techniques to ensure only necessary information is sent to AI models. Add PII detection and redaction before sending data to external services. Consider using private endpoints for Bedrock access. Use the guardrail features consistently across all functions.",
    "priority": 1,
    "estimated_effort": "High",
    "cwe_id": "CWE-200",
    "compliance_violations": ["GDPR Article 5", "CCPA", "HIPAA"],
    "references": ["https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html"],
    "status": "Open"
  }
]