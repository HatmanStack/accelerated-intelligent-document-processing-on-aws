# CloudFormation Threat Model Report

**Template:** `threat-model.md`  
**Analysis Date:** 2025-08-19_17-08-17  
**Generated By:** CloudFormation Threat Modeling Tool  

## Executive Summary

This threat model analysis identified **10** security threats. The analysis reveals **0** critical, **4** high, **6** medium, and **0** low severity findings.

## Priority Actions

### 1. Implement more granular IAM policies by limiting S3 access to specific paths/prefixes needed by each function. For Bedrock, specify only the exact models needed by each function rather than allowing all foundation models. Also consider using resource-based conditions to further restrict access.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-001  
**Business Impact:** Unauthorized data access, potential data breaches, excessive AWS costs from unauthorized model usage, and potential violation of data protection regulations.

### 1. Move sensitive configuration data to secure parameter storage like AWS Systems Manager Parameter Store or AWS Secrets Manager, and reference them in CloudFormation. Use KMS encryption for all sensitive configuration values.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-006  
**Business Impact:** Exposure of intellectual property, business logic, or prompt engineering that gives competitive advantage. Could enable attackers to craft inputs that manipulate model outputs.

### 1. Implement strict validation of all configuration changes against a well-defined schema. Add integrity checks and approval workflows for configuration changes. Consider implementing versioning for configurations with rollback capabilities.

**Effort:** High  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-007  
**Business Impact:** System compromise, data exfiltration, or injection of malicious behavior into the document processing pipeline.

### 1. Implement data minimization techniques to ensure only necessary information is sent to AI models. Add PII detection and redaction before sending data to external services. Consider using private endpoints for Bedrock access. Use the guardrail features consistently across all functions.

**Effort:** High  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-010  
**Business Impact:** Unauthorized disclosure of sensitive or regulated information to third-party AI services, potential regulatory compliance violations, and data privacy concerns.

### 2. Set 'IncludeExecutionData: false' in the Step Functions logging configuration to prevent sensitive data from being logged. Implement data minimization in the workflow by ensuring that sensitive information is not passed between state machine steps unless absolutely necessary.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-002  
**Business Impact:** Potential exposure of confidential information from processed documents, which could lead to data breaches and regulatory violations.

### 2. Implement log sanitization in all Lambda functions to redact or mask sensitive data before logging. Set appropriate log levels for production (WARN or ERROR rather than DEBUG or INFO). Consider implementing a centralized logging solution with PII detection and redaction capabilities.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-003  
**Business Impact:** Unauthorized exposure of confidential information, potential compliance violations, and increased risk of data breaches.

### 2. Implement comprehensive input validation for all document inputs. Add file type verification, size limits, content scanning, and sanitization before processing. Consider integrating with a malware scanning solution for uploaded documents.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-004  
**Business Impact:** Potential denial of service through resource exhaustion, code injection if vulnerabilities exist in processing libraries, or data corruption.

### 2. Implement proper service-to-service authentication using IAM roles with request signing. Consider implementing API keys or JWT tokens for GraphQL API access with appropriate authorization checks.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-008  
**Business Impact:** Unauthorized data manipulation, injection of false data into the processing pipeline, or exfiltration of sensitive information from internal services.

### 3. Implement reserved concurrency for critical Lambda functions. Set up appropriate throttling and rate limiting at the API level. Consider implementing a queue-based architecture for handling high volumes of document processing requests.

**Effort:** Medium  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-005  
**Business Impact:** Service unavailability, excessive AWS costs, degraded performance for legitimate users, and potential failure to meet SLAs.

### 3. Implement strict access controls on CloudWatch dashboards. Review dashboard content to ensure it doesn't reveal sensitive information. Consider creating separate dashboards for different user roles with appropriate access controls.

**Effort:** Low  
**Related Threats:** AWS-GENAI-IDP-ACCELERATOR-THREAT-009  
**Business Impact:** Information disclosure that provides attackers with insights into system behavior and potential attack vectors. Could reveal business-sensitive information about document processing volumes.



## Detailed Threat Analysis

## High Severity Threats

### AWS-GENAI-IDP-ACCELERATOR-THREAT-001: Overly Permissive IAM Policies for Lambda Functions

**STRIDE Category:** Elevation of Privilege  
**Affected Resource:** `OCRFunction, ClassificationFunction, ExtractionFunction, AssessmentFunction, SummarizationFunction` (AWS::Serverless::Function)  
**CWE ID:** CWE-272

#### Issue
Multiple Lambda functions have overly broad permissions such as S3 CRUD permissions on entire buckets and Bedrock access to all foundation models, which violates the principle of least privilege. This creates unnecessary access paths and increases the attack surface.

#### Attack Vector
If one of the Lambda functions is compromised (e.g., through code injection or dependency vulnerabilities), an attacker could leverage the broad permissions to access, modify, or delete data across multiple buckets, or use expensive Bedrock models to run unauthorized workloads.

#### Potential Impact
Unauthorized data access, potential data breaches, excessive AWS costs from unauthorized model usage, and potential violation of data protection regulations.

#### Remediation
Implement more granular IAM policies by limiting S3 access to specific paths/prefixes needed by each function. For Bedrock, specify only the exact models needed by each function rather than allowing all foundation models. Also consider using resource-based conditions to further restrict access.

**References:**
- https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-006: Sensitive Configuration Data in CloudFormation

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `UpdateSchemaConfig, UpdateDefaultConfig` (AWS::CloudFormation::CustomResource)  
**CWE ID:** CWE-200

#### Issue
The template contains extensive configuration details including system prompts and task prompts for AI models directly in CloudFormation. These could contain sensitive information or reveal internal business logic that should not be visible in infrastructure code.

#### Attack Vector
An attacker with access to CloudFormation templates or stack history could extract sensitive prompts or business logic that could be used to understand or manipulate the document processing system.

#### Potential Impact
Exposure of intellectual property, business logic, or prompt engineering that gives competitive advantage. Could enable attackers to craft inputs that manipulate model outputs.

#### Remediation
Move sensitive configuration data to secure parameter storage like AWS Systems Manager Parameter Store or AWS Secrets Manager, and reference them in CloudFormation. Use KMS encryption for all sensitive configuration values.

**References:**
- https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-007: No Validation of Schema Configuration Updates

**STRIDE Category:** Tampering  
**Affected Resource:** `UpdateSchemaConfig` (AWS::CloudFormation::CustomResource)  
**CWE ID:** CWE-915

#### Issue
The system uses custom resources to update configuration schemas but doesn't appear to implement validation of configuration changes. This could lead to injection of malicious configuration that affects the behavior of document processing functions.

#### Attack Vector
An attacker with access to the configuration update mechanism could inject malicious configuration data that could alter system behavior, extract information, or create security vulnerabilities.

#### Potential Impact
System compromise, data exfiltration, or injection of malicious behavior into the document processing pipeline.

#### Remediation
Implement strict validation of all configuration changes against a well-defined schema. Add integrity checks and approval workflows for configuration changes. Consider implementing versioning for configurations with rollback capabilities.

**References:**
- https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-010: Potential Data Leakage to External AI Models

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `All Lambda Functions with Bedrock Access` (AWS::Serverless::Function)  
**CWE ID:** CWE-200

#### Issue
Lambda functions that interact with Amazon Bedrock or other LLM services could potentially send sensitive document data to these services without proper controls for data minimization or filtering.

#### Attack Vector
Sensitive information from processed documents could be included in prompts sent to external AI services, where it might be used for model training or retained in logs.

#### Potential Impact
Unauthorized disclosure of sensitive or regulated information to third-party AI services, potential regulatory compliance violations, and data privacy concerns.

#### Remediation
Implement data minimization techniques to ensure only necessary information is sent to AI models. Add PII detection and redaction before sending data to external services. Consider using private endpoints for Bedrock access. Use the guardrail features consistently across all functions.

**References:**
- https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html

---

## Medium Severity Threats

### AWS-GENAI-IDP-ACCELERATOR-THREAT-002: Execution History Could Expose Sensitive Data

**STRIDE Category:** Repudiation  
**Affected Resource:** `DocumentProcessingStateMachine` (AWS::Serverless::StateMachine)  
**CWE ID:** CWE-532

#### Issue
The Step Functions state machine is configured with 'IncludeExecutionData: true', which means that potentially sensitive document data could be included in the execution history and logs, creating a risk of sensitive information disclosure.

#### Attack Vector
An attacker with access to the CloudWatch logs or Step Functions execution history could extract sensitive information from processed documents without directly accessing the source data.

#### Potential Impact
Potential exposure of confidential information from processed documents, which could lead to data breaches and regulatory violations.

#### Remediation
Set 'IncludeExecutionData: false' in the Step Functions logging configuration to prevent sensitive data from being logged. Implement data minimization in the workflow by ensuring that sensitive information is not passed between state machine steps unless absolutely necessary.

**References:**
- https://docs.aws.amazon.com/step-functions/latest/dg/cloudwatch-logs.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-003: Possible Sensitive Data Exposure in Lambda Logs

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `All Lambda Functions` (AWS::Serverless::Function)  
**CWE ID:** CWE-532

#### Issue
Lambda functions processing document data may log sensitive information as part of their execution, especially when running at DEBUG or INFO log levels. There's no evidence of log filtering or redaction mechanisms for PII or sensitive content.

#### Attack Vector
An attacker with access to CloudWatch logs could extract sensitive information from log entries without needing direct access to the data stores.

#### Potential Impact
Unauthorized exposure of confidential information, potential compliance violations, and increased risk of data breaches.

#### Remediation
Implement log sanitization in all Lambda functions to redact or mask sensitive data before logging. Set appropriate log levels for production (WARN or ERROR rather than DEBUG or INFO). Consider implementing a centralized logging solution with PII detection and redaction capabilities.

**References:**
- https://docs.aws.amazon.com/lambda/latest/dg/logging-using-cloudwatch-logs.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-004: No Input Validation for Document Processing

**STRIDE Category:** Tampering  
**Affected Resource:** `All Lambda Functions` (AWS::Serverless::Function)  
**CWE ID:** CWE-20

#### Issue
There's no evidence of input validation or sanitization for incoming documents before processing. This could lead to processing of malicious files or unexpected content that might compromise the system.

#### Attack Vector
An attacker could upload specially crafted documents designed to exploit vulnerabilities in the document processing libraries or cause the system to behave unexpectedly.

#### Potential Impact
Potential denial of service through resource exhaustion, code injection if vulnerabilities exist in processing libraries, or data corruption.

#### Remediation
Implement comprehensive input validation for all document inputs. Add file type verification, size limits, content scanning, and sanitization before processing. Consider integrating with a malware scanning solution for uploaded documents.

**References:**
- https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-005: No Resource Throttling or Quotas

**STRIDE Category:** Denial of Service  
**Affected Resource:** `OCRFunction, ClassificationFunction, ExtractionFunction` (AWS::Serverless::Function)  
**CWE ID:** CWE-770

#### Issue
The template lacks defined concurrency limits, quotas, or rate limiting for Lambda functions. This makes the system vulnerable to resource exhaustion attacks or unintentional DoS during high traffic periods.

#### Attack Vector
An attacker could trigger many simultaneous document processing requests, potentially causing resource exhaustion, increased costs, or service disruption.

#### Potential Impact
Service unavailability, excessive AWS costs, degraded performance for legitimate users, and potential failure to meet SLAs.

#### Remediation
Implement reserved concurrency for critical Lambda functions. Set up appropriate throttling and rate limiting at the API level. Consider implementing a queue-based architecture for handling high volumes of document processing requests.

**References:**
- https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-008: No Authentication for Internal API Calls

**STRIDE Category:** Spoofing  
**Affected Resource:** `All Lambda Functions` (AWS::Serverless::Function)  
**CWE ID:** CWE-306

#### Issue
The template shows Lambda functions making calls to AppSync GraphQL APIs but does not clearly define or enforce authentication between these internal services.

#### Attack Vector
If an attacker gains access to execute code within the environment, they could potentially make unauthorized calls to internal APIs without proper authentication checks.

#### Potential Impact
Unauthorized data manipulation, injection of false data into the processing pipeline, or exfiltration of sensitive information from internal services.

#### Remediation
Implement proper service-to-service authentication using IAM roles with request signing. Consider implementing API keys or JWT tokens for GraphQL API access with appropriate authorization checks.

**References:**
- https://docs.aws.amazon.com/appsync/latest/devguide/security-authz.html

---

### AWS-GENAI-IDP-ACCELERATOR-THREAT-009: Sensitive Information in CloudWatch Dashboard

**STRIDE Category:** Information Disclosure  
**Affected Resource:** `Dashboard` (AWS::CloudWatch::Dashboard)  
**CWE ID:** CWE-200

#### Issue
The CloudWatch dashboard could potentially expose sensitive operational data and metrics about the document processing system, including processing volumes, error rates, and performance characteristics.

#### Attack Vector
An attacker with access to CloudWatch could gather intelligence about system behavior, identify potential vulnerabilities, or monitor for specific patterns that might indicate high-value document processing.

#### Potential Impact
Information disclosure that provides attackers with insights into system behavior and potential attack vectors. Could reveal business-sensitive information about document processing volumes.

#### Remediation
Implement strict access controls on CloudWatch dashboards. Review dashboard content to ensure it doesn't reveal sensitive information. Consider creating separate dashboards for different user roles with appropriate access controls.

**References:**
- https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards_Sharing.html

---



---

*This report was generated automatically using STRIDE threat modeling methodology.*