{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Document Processing with Assessment\n",
    "\n",
    "This notebook demonstrates how to process a document using the modular Document-based approach with:\n",
    "\n",
    "1. OCR Service - Convert a PDF document to text using AWS Textract\n",
    "2. Classification Service - Classify document pages into sections using Bedrock\n",
    "3. Extraction Service - Extract structured information from sections using Bedrock\n",
    "4. **Assessment Service - Assess the confidence and accuracy of extraction results**\n",
    "5. Evaluation Service - Evaluate accuracy of extracted information\n",
    "\n",
    "Each step uses the unified Document object model for data flow and consistency.\n",
    "\n",
    "> **Note**: This notebook uses AWS services including S3, Textract, and Bedrock. You need valid AWS credentials with appropriate permissions to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "The IDP common package supports granular installation through extras. You can install:\n",
    "- `[core]` - Just core functionality \n",
    "- `[ocr]` - OCR service with Textract dependencies\n",
    "- `[classification]` - Classification service dependencies\n",
    "- `[extraction]` - Extraction service dependencies\n",
    "- `[evaluation]` - Evaluation service dependencies\n",
    "- `[all]` - All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: idp_common 0.3.6\n",
      "Uninstalling idp_common-0.3.6:\n",
      "  Successfully uninstalled idp_common-0.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Version: 0.3.7\n",
      "Location: /home/ec2-user/.local/lib/python3.11/site-packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure that modules are autoreloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First uninstall existing package (to ensure we get the latest version)\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package with all components in development mode\n",
    "%pip install -q -e \"../lib/idp_common_pkg[dev, all]\"\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\"\n",
    "\n",
    "# Optionally use a .env file for environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  \n",
    "except ImportError:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup:\n",
      "METRIC_NAMESPACE: IDP-Notebook-Assessment-Example\n",
      "AWS_REGION: us-west-2\n",
      "Input bucket: idp-notebook-assess-input-912625584728-us-west-2\n",
      "Output bucket: idp-notebook-assess-output-912625584728-us-west-2\n",
      "SAMPLE_PDF_PATH: ../samples/rvl_cdip_package.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "# Import base libraries\n",
    "from idp_common.models import Document, Status, Section, Page\n",
    "from idp_common import ocr, classification, extraction, assessment, evaluation\n",
    "\n",
    "# Configure logging \n",
    "logging.basicConfig(level=logging.WARNING)  # Set root logger to WARNING (less verbose)\n",
    "logging.getLogger('idp_common.ocr.service').setLevel(logging.INFO)  # Focus on service logs\n",
    "logging.getLogger('textractor').setLevel(logging.WARNING)  # Suppress textractor logs\n",
    "logging.getLogger('idp_common.evaluation.service').setLevel(logging.DEBUG)  # Enable evaluation logs\n",
    "logging.getLogger('idp_common.assessment.service').setLevel(logging.DEBUG)  # Enable assessment logs\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.DEBUG)  # show prompts\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Notebook-Assessment-Example'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Define sample PDF path \n",
    "SAMPLE_PDF_PATH = \"../samples/rvl_cdip_package.pdf\"\n",
    "\n",
    "# Create unique bucket names based on account ID and region\n",
    "input_bucket_name =  os.getenv(\"IDP_INPUT_BUCKET_NAME\", f\"idp-notebook-assess-input-{account_id}-{region}\")\n",
    "output_bucket_name = os.getenv(\"IDP_OUTPUT_BUCKET_NAME\", f\"idp-notebook-assess-output-{account_id}-{region}\")\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"METRIC_NAMESPACE: {os.environ.get('METRIC_NAMESPACE')}\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"Input bucket: {input_bucket_name}\")\n",
    "print(f\"Output bucket: {output_bucket_name}\")\n",
    "print(f\"SAMPLE_PDF_PATH: {SAMPLE_PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up S3 Buckets and Upload Sample File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket idp-notebook-assess-input-912625584728-us-west-2 already exists\n",
      "Bucket idp-notebook-assess-output-912625584728-us-west-2 already exists\n",
      "Uploaded sample file to: s3://idp-notebook-assess-input-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Helper function to parse S3 URIs\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "# Helper function to load JSON from S3\n",
    "def load_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(content)\n",
    "\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure both buckets exist\n",
    "ensure_bucket_exists(input_bucket_name)\n",
    "ensure_bucket_exists(output_bucket_name)\n",
    "\n",
    "# Upload the sample file to S3\n",
    "sample_file_key = \"sample-assessment-\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".pdf\"\n",
    "with open(SAMPLE_PDF_PATH, 'rb') as file_data:\n",
    "    s3_client.upload_fileobj(file_data, input_bucket_name, sample_file_key)\n",
    "\n",
    "print(f\"Uploaded sample file to: s3://{input_bucket_name}/{sample_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Configuration with Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration created with assessment capabilities\n"
     ]
    }
   ],
   "source": [
    "# Sample configuration that includes assessment section\n",
    "CONFIG = {\n",
    "    \"ocr\": {\"features\": [{\"name\": \"LAYOUT\"},{\"name\": \"TABLES\"},{\"name\": \"SIGNATURES\"}]},\n",
    "    \"classification\": {\n",
    "        \"top_p\": \"0.1\",\n",
    "        \"max_tokens\": \"4096\",\n",
    "        \"top_k\": \"5\",\n",
    "        \"task_prompt\": \"<task-description>\\nYou are a document classification system. Your task is to analyze a document package containing multiple pages and identify distinct document segments, classifying each segment according to the predefined document types provided below.\\n</task-description>\\n\\n<document-types>\\n{CLASS_NAMES_AND_DESCRIPTIONS}\\n</document-types>\\n\\n<terminology-definitions>\\nKey terms used in this task:\\n- ordinal_start_page: The one-based beginning page number of a document segment within the document package\\n- ordinal_end_page: The one-based ending page number of a document segment within the document package\\n- document_type: The document type code detected for a document segment\\n- document segment: A continuous range of pages that form a single, complete document\\n</terminology-definitions>\\n\\n<classification-instructions>\\nFollow these steps to classify documents:\\n1. Read through the entire document package to understand its contents\\n2. Identify page ranges that form complete, distinct documents\\n3. Match each document segment to ONE of the document types listed in <document-types>\\n4. CRITICAL: Only use document types explicitly listed in the <document-types> section\\n5. If a document doesn't clearly match any listed type, assign it to the most similar listed type\\n6. Pay special attention to adjacent documents of the same type - they must be separated into distinct segments\\n7. Record the ordinal_start_page and ordinal_end_page for each identified segment\\n8. Provide appropriate reasons and facts for the predicted document type\\n</classification-instructions>\\n\\n<document-boundary-rules>\\nRules for determining document boundaries:\\n- Content continuity: Pages with continuing paragraphs, numbered sections, or ongoing narratives belong to the same document\\n- Visual consistency: Similar layouts, headers, footers, and styling indicate pages belong together\\n- Logical structure: Documents typically have clear beginning, middle, and end sections\\n- New document indicators: Title pages, cover sheets, or significantly different subject matter signal a new document\\n- Topic coherence: Pages discussing the same subject should be grouped together\\n- IMPORTANT: Distinct documents of the same type that are adjacent must be separated into different segments\\n</document-boundary-rules>\\n\\n<output-format>\\nReturn your classification as valid JSON following this exact structure:\\n```json\\n{\\n    \\\"segments\\\": [\\n        {\\n            \\\"ordinal_start_page\\\": 1,\\n            \\\"ordinal_end_page\\\": 3,\\n            \\\"type\\\": \\\"document_type_from_list\\\",\\n            \\\"reason\\\": \\\"facts and reasons to classify as the predicted type\\\",\\n        },\\n        {\\n            \\\"ordinal_start_page\\\": 4,\\n            \\\"ordinal_end_page\\\": 7,\\n            \\\"type\\\": \\\"document_type_from_list\\\"\\n            \\\"reason\\\": \\\"facts and reasons to classify as the predicted type\\\",\\n        }\\n    ]\\n}\\n```\\n</output-format>\\n\\n<<CACHEPOINT>>\\n\\n<document-text>\\n{DOCUMENT_TEXT}\\n</document-text>\\n\\n<final-instructions>\\nAnalyze the <document-text> provided above and:\\n1. Apply the <classification-instructions> to identify distinct document segments\\n2. Use the <document-boundary-rules> to determine where one document ends and another begins\\n3. Classify each segment using ONLY the document types from the <document-types> list\\n4. Ensure adjacent documents of the same type are separated into distinct segments\\n5. Output your classification in the exact JSON format specified in <output-format>\\n6. You can get this information from the previous message. Analyze the previous messages to get these instructions.\\n\\nRemember: You must ONLY use document types that appear in the <document-types> reference data. Do not invent or create new document types.\\n</final-instructions>\",\n",
    "        \"temperature\": \"0.0\",\n",
    "        \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "        \"system_prompt\": \"You are a document classification expert who can analyze and classify multiple documents and their page boundaries within a document package from various domains. Your task is to determine the document type based on its content and structure, using the provided document type definitions. Your output must be valid JSON according to the requested format.\",\n",
    "        \"classificationMethod\": \"textbasedHolisticClassification\"\n",
    "    },\n",
    "    \"extraction\": {\n",
    "        \"top_p\": \"0.1\",\n",
    "        \"max_tokens\": \"4096\",\n",
    "        \"top_k\": \"5\",\n",
    "        \"task_prompt\": \"<background>\\nYou are an expert in document analysis and information extraction.  You can understand and extract key information from documents classified as type \\n{DOCUMENT_CLASS}.\\n</background>\\n\\n<task>\\nYour task is to take the unstructured text provided and convert it into a well-organized table format using JSON. Identify the main entities, attributes, or categories mentioned in the attributes list below and use them as keys in the JSON object.  Then, extract the relevant information from the text and populate the corresponding values in the JSON object.\\n</task>\\n\\n<extraction-guidelines>\\nGuidelines:\\n    1. Ensure that the data is accurately represented and properly formatted within\\n    the JSON structure\\n    2. Include double quotes around all keys and values\\n    3. Do not make up data - only extract information explicitly found in the\\n    document\\n    4. Do not use /n for new lines, use a space instead\\n    5. If a field is not found or if unsure, return null\\n    6. All dates should be in MM/DD/YYYY format\\n    7. Do not perform calculations or summations unless totals are explicitly given\\n    8. If an alias is not found in the document, return null\\n    9. Guidelines for checkboxes:\\n     9.A. CAREFULLY examine each checkbox, radio button, and selection field:\\n        - Look for marks like ✓, ✗, x, filled circles (●), darkened areas, or handwritten checks indicating selection\\n        - For checkboxes and multi-select fields, ONLY INCLUDE options that show clear visual evidence of selection\\n        - DO NOT list options that have no visible selection mark\\n     9.B. For ambiguous or overlapping tick marks:\\n        - If a mark overlaps between two or more checkboxes, determine which option contains the majority of the mark\\n        - Consider a checkbox selected if the mark is primarily inside the check box or over the option text\\n        - When a mark touches multiple options, analyze which option was most likely intended based on position and density. For handwritten checks, the mark typically flows from the selected checkbox outward.\\n        - Carefully analyze visual cues and contextual hints. Think from a human perspective, anticipate natural tendencies, and apply thoughtful reasoning to make the best possible judgment.\\n    10. Think step by step first and then answer.\\n\\n</extraction-guidelines>\\n\\n<attributes>\\n{ATTRIBUTE_NAMES_AND_DESCRIPTIONS}\\n</attributes>\\n\\n<<CACHEPOINT>>\\n\\n<document-text>\\n{DOCUMENT_TEXT}\\n</document-text>\\n\\n<document_image>\\n{DOCUMENT_IMAGE}\\n</document_image>\\n\\n<final-instructions>\\nExtract key information from the document and return a JSON object with the following key steps: 1. Carefully analyze the document text to identify the requested attributes 2. Extract only information explicitly found in the document - never make up data 3. Format all dates as MM/DD/YYYY and replace newlines with spaces 4. For checkboxes, only include options with clear visual selection marks 5. Use null for any fields not found in the document 6. Ensure the output is properly formatted JSON with quoted keys and values 7. Think step by step before finalizing your answer\\n</final-instructions>\",\n",
    "        \"temperature\": \"0.0\",\n",
    "        \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "        \"system_prompt\": \"You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\"\n",
    "    },\n",
    "    \"assessment\": {\n",
    "        \"top_p\": \"0.1\",\n",
    "        \"max_tokens\": \"4096\",\n",
    "        \"top_k\": \"5\",\n",
    "        \"task_prompt\": \"<background>\\nYou are an expert document analysis assessment system. Your task is to evaluate the confidence and accuracy of extraction results for a document of class {DOCUMENT_CLASS}.\\n</background>\\n\\n<task>\\nAnalyze the extraction results against the source document and provide confidence assessments for each extracted attribute. Consider factors such as:\\n1. Text clarity and OCR quality in the source regions 2. Alignment between extracted values and document content 3. Presence of clear evidence supporting the extraction 4. Potential ambiguity or uncertainty in the source material 5. Completeness and accuracy of the extracted information\\n</task>\\n\\n<assessment-guidelines>\\nFor each attribute, provide: 1. A confidence score between 0.0 and 1.0 where:\\n   - 1.0 = Very high confidence, clear and unambiguous evidence\\n   - 0.8-0.9 = High confidence, strong evidence with minor uncertainty\\n   - 0.6-0.7 = Medium confidence, reasonable evidence but some ambiguity\\n   - 0.4-0.5 = Low confidence, weak or unclear evidence\\n   - 0.0-0.3 = Very low confidence, little to no supporting evidence\\n\\n2. A clear reason explaining the confidence score, including:\\n   - What evidence supports or contradicts the extraction\\n   - Any OCR quality issues that affect confidence\\n   - Clarity of the source document in relevant areas\\n   - Any ambiguity or uncertainty factors\\n\\nGuidelines: - Base assessments on actual document content and OCR quality - Consider both text-based evidence and visual/layout clues - Account for OCR confidence scores when provided - Be objective and specific in reasoning - If an extraction appears incorrect, score accordingly with explanation\\n</assessment-guidelines>\\n<attributes-definitions>\\n{ATTRIBUTE_NAMES_AND_DESCRIPTIONS}\\n</attributes-definitions>\\n\\n<<CACHEPOINT>>\\n\\n<extraction-results>\\n{EXTRACTION_RESULTS}\\n</extraction-results>\\n\\n<document-image>\\n{DOCUMENT_IMAGE}\\n</document-image>\\n\\n<ocr-text-confidence-results>\\n{OCR_TEXT_CONFIDENCE}\\n</ocr-text-confidence-results>\\n\\n<final-instructions>\\nAnalyze the extraction results against the source document and provide confidence assessments. Return a JSON object with the following structure:\\n\\n  {\\n    \\\"attribute_name_1\\\": {\\n      \\\"confidence_score\\\": 0.85,\\n      \\\"confidence_reason\\\": \\\"Clear text evidence found in document header with high OCR confidence (0.98). Value matches exactly.\\\"\\n    },\\n    \\\"attribute_name_2\\\": {\\n      \\\"confidence_score\\\": 0.65,\\n      \\\"confidence_reason\\\": \\\"Text is partially unclear due to poor scan quality. OCR confidence low (0.72) in this region.\\\"\\n    }\\n  }\\n\\nInclude assessments for ALL attributes present in the extraction results.\\n</final-instructions>\",\n",
    "        \"temperature\": \"0.0\",\n",
    "        \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "        \"system_prompt\": \"You are a document analysis assessment expert. Your task is to evaluate the confidence and accuracy of extraction results by analyzing the source document evidence. Respond only with JSON containing confidence scores and reasoning for each extracted attribute.\"\n",
    "    },\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"name\": \"letter\",\n",
    "            \"description\": \"A formal written correspondence with sender/recipient addresses, date, salutation, body, and closing signature\",\n",
    "            \"attributes\": [\n",
    "                {\n",
    "                    \"name\": \"sender_name\",\n",
    "                    \"description\": \"The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"sender_address\",\n",
    "                    \"description\": \"The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"recipient_name\",\n",
    "                    \"description\": \"The name of the person or entity receiving the letter. Look for this after 'to', 'recipient', 'addressee', or at the beginning of the letter.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"recipient_address\",\n",
    "                    \"description\": \"The physical address where the letter is to be delivered. Often labeled as 'to address' or 'delivery address', typically appearing below the recipient name.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"date\",\n",
    "                    \"description\": \"The date when the letter was written. Look for a standalone date or text following phrases like 'written on' or 'dated'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"subject\",\n",
    "                    \"description\": \"The topic or main point of the letter. Often preceded by 'subject', 'RE:', or 'regarding'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"letter_type\",\n",
    "                    \"description\": \"The category or classification of the letter, such as 'complaint', 'inquiry', 'invitation', etc. May be indicated by 'type' or 'category'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"signature\",\n",
    "                    \"description\": \"The handwritten name or mark of the sender at the end of the letter. May follow terms like 'signed by' or simply appear at the bottom of the document.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"cc\",\n",
    "                    \"description\": \"Names of people who receive a copy of the letter in addition to the main recipient. Often preceded by 'cc', 'carbon copy', or 'copy to'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"reference_number\",\n",
    "                    \"description\": \"An identifying number or code associated with the letter. Look for labels like 'ref', 'reference', or 'our ref'.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"form\",\n",
    "            \"description\": \"A structured document with labeled fields, checkboxes, or blanks requiring user input and completion\",\n",
    "            \"attributes\": [\n",
    "                {\n",
    "                    \"name\": \"form_type\",\n",
    "                    \"description\": \"The category or purpose of the form, such as 'application', 'registration', 'request', etc. May be identified by 'form name', 'document type', or 'form category'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"form_id\",\n",
    "                    \"description\": \"The unique identifier for the form, typically a number or alphanumeric code. Often labeled as 'form number', 'id', or 'reference number'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"submission_date\",\n",
    "                    \"description\": \"The date when the form was submitted or filed. Look for text near 'date', 'submitted on', or 'filed on'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"submitter_name\",\n",
    "                    \"description\": \"The name of the person who submitted the form. May be labeled as 'name', 'submitted by', or 'filed by'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"submitter_id\",\n",
    "                    \"description\": \"An identification number for the person submitting the form, such as social security number, employee ID, etc. Often labeled as 'id number', 'identification', or 'reference'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"approval_status\",\n",
    "                    \"description\": \"The current state of approval for the form, such as 'approved', 'pending', 'rejected', etc. Look for terms like 'status', 'approved', or 'pending'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"processed_by\",\n",
    "                    \"description\": \"The name of the person or department that processed the form. May be indicated by 'processor', 'handled by', or 'approved by'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"processing_date\",\n",
    "                    \"description\": \"The date when the form was processed or completed. Look for labels like 'processed on' or 'completion date'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"department\",\n",
    "                    \"description\": \"The organizational unit responsible for the form. Often abbreviated as 'dept' or may appear as 'department' or 'division'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"comments\",\n",
    "                    \"description\": \"Additional notes or remarks about the form. Look for sections labeled 'notes', 'remarks', or 'comments'.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"email\",\n",
    "            \"description\": \"A digital message with email headers (To/From/Subject), timestamps, and conversational threading\",\n",
    "            \"attributes\": [\n",
    "                {\n",
    "                    \"name\": \"from_address\",\n",
    "                    \"description\": \"The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"to_address\",\n",
    "                    \"description\": \"The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"cc_address\",\n",
    "                    \"description\": \"Email addresses of additional recipients who receive copies. Look for 'cc' or 'carbon copy' followed by one or more email addresses.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"bcc_address\",\n",
    "                    \"description\": \"Email addresses of hidden recipients. May be labeled as 'bcc' or 'blind copy'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"subject\",\n",
    "                    \"description\": \"The topic of the email. Often preceded by 'subject', 'RE:', or 'regarding'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"date_sent\",\n",
    "                    \"description\": \"The date and time when the email was sent. Look for 'date', 'sent on', or 'received', typically in the email header.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"attachments\",\n",
    "                    \"description\": \"Files included with the email. May be indicated by 'attached', 'attachment', or 'enclosed', often with icons or file names.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"priority\",\n",
    "                    \"description\": \"The urgency level of the email, such as 'high', 'normal', etc. Look for 'priority' or 'importance'.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"thread_id\",\n",
    "                    \"description\": \"An identifier for the email conversation. May be labeled as 'thread' or 'conversation', typically not visible to regular users.\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"message_id\",\n",
    "                    \"description\": \"A unique identifier for the specific email. Look for 'message id' or 'email id', usually hidden in the email metadata.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Configuration created with assessment capabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Document with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.ocr.service:OCR Service initialized with DPI: None\n",
      "INFO:idp_common.ocr.service:OCR Service initialized with features: ['LAYOUT']\n",
      "INFO:idp_common.ocr.service:OCR Service initialized with Textract backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created document with ID: rvl-cdip-package-assessment\n",
      "Status: QUEUED\n",
      "\n",
      "Processing document with OCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.ocr.service:Detected file type: pdf\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 5\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 3\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 2\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 1\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 10\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 9\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 8\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 6\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 4\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 7\n",
      "INFO:idp_common.ocr.service:Sorting 10 pages by page number\n",
      "INFO:idp_common.ocr.service:OCR processing completed in 5.57 seconds\n",
      "INFO:idp_common.ocr.service:Processed 10 pages, with 0 errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR processing completed in 5.57 seconds\n",
      "Document status: QUEUED\n",
      "Number of pages processed: 10\n",
      "\n",
      "Processed pages:\n",
      "Page 1: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/1/image.jpg\n",
      "Page 2: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/2/image.jpg\n",
      "Page 3: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/3/image.jpg\n",
      "Page 4: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/4/image.jpg\n",
      "Page 5: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/5/image.jpg\n",
      "Page 6: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/6/image.jpg\n",
      "Page 7: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/7/image.jpg\n",
      "Page 8: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/8/image.jpg\n",
      "Page 9: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/9/image.jpg\n",
      "Page 10: Image URI: s3://idp-notebook-assess-output-912625584728-us-west-2/sample-assessment-2025-07-09_13-45-57.pdf/pages/10/image.jpg\n",
      "\n",
      "Metering:\n",
      "{\"OCR/textract/analyze_document-Layout\": {\"pages\": 10}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new Document\n",
    "document = Document(\n",
    "    id=\"rvl-cdip-package-assessment\",\n",
    "    input_bucket=input_bucket_name,\n",
    "    input_key=sample_file_key,\n",
    "    output_bucket=output_bucket_name,\n",
    "    status=Status.QUEUED\n",
    ")\n",
    "\n",
    "print(f\"Created document with ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "\n",
    "# Create OCR service with Textract\n",
    "ocr_service = ocr.OcrService(\n",
    "    region=region,\n",
    "    enhanced_features=['LAYOUT']\n",
    ")\n",
    "\n",
    "# Process document with OCR\n",
    "print(\"\\nProcessing document with OCR...\")\n",
    "start_time = time.time()\n",
    "document = ocr_service.process_document(document)\n",
    "ocr_time = time.time() - start_time\n",
    "\n",
    "print(f\"OCR processing completed in {ocr_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of pages processed: {document.num_pages}\")\n",
    "\n",
    "# Show pages information\n",
    "print(\"\\nProcessed pages:\")\n",
    "for page_id, page in document.pages.items():\n",
    "    print(f\"Page {page_id}: Image URI: {page.image_uri}\")\n",
    "print(\"\\nMetering:\")\n",
    "print(json.dumps(document.metering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classify the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <task-description>\n",
      "You are a document classificati...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 422 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 2568 words\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document classification expert who can analyze and classify multiple documents and their page boundaries within a document package from various domains. Your task is to determine the document type based on its content and structure, using the provided document type definitions. Your output must be valid JSON according to the requested format.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': '<task-description>\\nYou are a document classification system. Your task is to analyze a document package containing multiple pages and identify distinct document segments, classifying each segment according to the predefined document types provided below.\\n</task-description>\\n\\n<document-types>\\n| type | description |\\n| --- | --- |\\n| letter | A formal written correspondence with sender/recipient addresses, date, salutation, body, and closing signature |\\n| form | A structured document with labeled fields, checkboxes, or blanks requiring user input and completion |\\n| email | A digital message with email headers (To/From/Subject), timestamps, and conversational threading |\\n</document-types>\\n\\n<terminology-definitions>\\nKey terms used in this task:\\n- ordinal_start_page: The one-based beginning page number of a document segment within the document package\\n- ordinal_end_page: The one-based ending page number of a document segment within the document package\\n- document_type: The document type code detected for a document segment\\n- document segment: A continuous range of pages that form a single, complete document\\n</terminology-definitions>\\n\\n<classification-instructions>\\nFollow these steps to classify documents:\\n1. Read through the entire document package to understand its contents\\n2. Identify page ranges that form complete, distinct documents\\n3. Match each document segment to ONE of the document types listed in <document-types>\\n4. CRITICAL: Only use document types explicitly listed in the <document-types> section\\n5. If a document doesn\\'t clearly match any listed type, assign it to the most similar listed type\\n6. Pay special attention to adjacent documents of the same type - they must be separated into distinct segments\\n7. Record the ordinal_start_page and ordinal_end_page for each identified segment\\n8. Provide appropriate reasons and facts for the predicted document type\\n</classification-instructions>\\n\\n<document-boundary-rules>\\nRules for determining document boundaries:\\n- Content continuity: Pages with continuing paragraphs, numbered sections, or ongoing narratives belong to the same document\\n- Visual consistency: Similar layouts, headers, footers, and styling indicate pages belong together\\n- Logical structure: Documents typically have clear beginning, middle, and end sections\\n- New document indicators: Title pages, cover sheets, or significantly different subject matter signal a new document\\n- Topic coherence: Pages discussing the same subject should be grouped together\\n- IMPORTANT: Distinct documents of the same type that are adjacent must be separated into different segments\\n</document-boundary-rules>\\n\\n<output-format>\\nReturn your classification as valid JSON following this exact structure:\\n```json\\n{\\n    \"segments\": [\\n        {\\n            \"ordinal_start_page\": 1,\\n            \"ordinal_end_page\": 3,\\n            \"type\": \"document_type_from_list\",\\n            \"reason\": \"facts and reasons to classify as the predicted type\",\\n        },\\n        {\\n            \"ordinal_start_page\": 4,\\n            \"ordinal_end_page\": 7,\\n            \"type\": \"document_type_from_list\"\\n            \"reason\": \"facts and reasons to classify as the predicted type\",\\n        }\\n    ]\\n}\\n```\\n</output-format>\\n\\n'}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<document-text>\\n<page-number>1</page-number>\\n\\n\\nWESTERN DARK FIRED TOBACCO GROWERS\\' ASSOCIATION \\n\\n206 Maple Street P. O. Box 1056 Murrey, Kennucky 42071-1056 \\n\\n(502) 753-3341 FAX (502) 753-0069/3342 \\n\\nOctober 11, 1995 \\n\\nThe Honorable Wendell H. Ford United States Senate Washington, D. c. 20510 \\n\\n## Dear Senator Ford: \\n\\nOn behalf of the Western Dark Fired Tobacco Growers\\' Association and the 9,000 tobacco producers it represents, I an obligated to convey our strong opposition to the \"Commitment to Our Children\\' petition being circulated by several Members of Congress. \\n\\nIn the tobacco industry, no one wants young people to consume tobacco products and age restriction laws are on the books in every state in the nation. We must take action to better enforce these laws, not create more bureaucracy. \\n\\nThere are those in our society who want to add inefficient hampering an adult\\'s First Amendment right to the freedom of choice government bureaucracy, thus destroying our family farms and in using a legal product. \\n\\nYou may have been approached by those who say they are supporting Administration (FDA) regulation of tobacco. However, if FDA is the cause of youth smoking prevention by pushing the Food and Drug given the authority to regulate tobacco because it is a \"nicotine delivery device\", farmers will be forced to deal with yet another government agency. Already our producers deal with and are monitored by the United States Department of Agriculture, the Administration and many others. We know first hand what Environmental Protection Agency, the Occupational Safety and Health a We certainly need your support and involvement to prevent FDA from nightmare federal government regulations can create for farmers. joining the ranks of federal tobacco regulators. \\n\\nChildren\" petition, looking at it for what it is; more anti-tobacco I urge you to consider the consequences of the \"Commitment to Cur indoctrination, rather than a solution to a problem which everyone, starting with parents, should address in a responsible manner. \\n\\nSincerely, Will E Clack Will E. Clark General Manager \\n\\nTNJB 0008497\\n\\n\\n<page-number>2</page-number>\\n# LAB SERVICES CONSISTENCY REPORT \\n\\nDATE: 7/28/93\\n TECHNICIAN: LC\\n SHIFT: A\\nTrial 8\\n LINE: 2\\n AREA: 52\\n SAMPLE ID: stuffbox 2\\nPRODUCT UNIT CODE: 0728- ABC\\nPhilip Confidential Beris\\n REASON FOR REQUEST: test\\n\\nREQUESTED DELIVERY TIME:\\n\\nTIME SAMPLE RECEIVED: -\\n\\nTIME ANALYSIS COMPLETED:\\n\\nDATA COMMUNICATED TO\\nGone\\nAT 1105\\n\\nPerson\\nTime\\n\\nDRYING TIME\\n\\n\\n\\n\\nA\\tB\\tC\\tD\\tE\\tIN:\\tOUT:\\nSAMPLE A\\tCONTAINER\\tSAMPLE\\tDILUTION\\tDEUTED\\nCONTAINER\\tWEIGHT IN\\tWEIGHT IN\\tFACTOR\\tSAMPLE\\nWEIGHT IN\\tGRAMS\\tGRAMS\\tWEIGHT IN\\nGRAMS\\t(A-B)\\tGRAMS\\nF\\tG\\tH\\tI\\n1159.3\\t6\\t6955.8\\tWEIGHT IN\\tPAPER\\tFILTER\\tGRAMS\\tWEIGHT IN\\tSAMPLE\\tWEIGHT IN\\tPAPER\\tSAMPLE &\\tH-P\\t% CONSISTENCY\\t0 x D x 100\\nGRAMS\\tGRAMS\\nWET\\tDRY\\nAVERAGE: 3.68\\tCONSISTENCY\\tSAMPLE # 10\\tSAMPLE #711\\t2.645\\t2853\\t84568\\t79.235\\t3.366\\t3123\\t3.62\\t3.64\\nRANGE: 15\\nSAMPLE #$ 12\\t2.847\\t89.776\\t3.411\\t3.77\\nMETER READING:\\nCOMMENTS:\\n\\n\\n\\nACONSIST WID\\n\\n\\n2030053328\\n\\n\\n<page-number>3</page-number>\\n# Ashley Bratich \\n\\nFrom: Kelahan, Ben To: TI New York\\'; \"TI Minnesota\\' Ce: Ashley Bratich (MSMAIL) Subject: FW: Morning Team Notes 4/20 Date: Saturday, April 18, 1998 2:09PM \\n\\nOriginal Message From: Byron Nelson [SMTP:bnelson@wka.com] Sent: Friday, April 17. 1998 5:25 PM To: Judy Albert: Carolyn: Jackie Cohen (AWMA): Frank: Goody; Henry; Hollant; Chris Holt; Hurst: Jim: Joe; John; Benjamin Kelahan; Cheryl Klein: Walt Klein; Lbeckwith; Rob Meyne; Mkatz; Morrow; Powers; Randy; Roger; Ron; Shorep; Steve Strawsburg: Suggsm; Matthew Tilley; whitey Co: Bob Fackler; Bob Stone Subject: Morning Team Notes 4/20 \\n\\nFalmouth, MA - On 4/15, town meeting representatives defeated by a 84-77 vote a warrent article calling for a 100 percent ban on smoking in restaurants. On 4/16, a motion to reconsider the vote was soundly rejected 104-49. The restaurant owner\\'s moderate alternative was not considered because the town counsel found the article to be unconstitutional. \\n\\nWaseca County, MN On 4/7, the county commissioners once again tabled consideration of a new tobacco retailing ordinance. Waseca is the 11th Minnesota community to put the issue on hold. \\n\\nWadena County, MN - In mid-March, the county commissioners tabled consideration of a new tobacco retailing ordinance until 4/23. At that time, they will take up a model ordinance that mirrors the state law. Bob Fackler requests calls to retailers to alert them to attend. \\n\\n1612 \\n\\nPage 1\\n\\n\\nTI1716-0284\\n\\n\\n<page-number>4</page-number>\\nLE CHOIHGPAT Mulation assay- Alyodal 401F Book No. 354 \\n\\nin Page No. 85,08.343 \\n\\nI lyectives To measure the ability of a test substance to induse matation\\n at the hypoxamhine gurnine phosphoubaryl transferase (haprt) loan\\n in Chinese Hamster Overy (CHO) cells on de basis that the presemption\\n mutants. by visture of the loss of the HGPRT activity are unabe\\n to convert purine analogs, such as G. throgramine (6-ta) to\\n toxic metabolities and hence escape their lethal effects, which\\n is liowever, excountered by the wild type cells.\\n Nativials and Methods: Refer to Standard Operating Procedure PH314\\n Spensor: american Cyanamid Company\\n Test Citicle Glyoxal 40 LF\\n Description clear liquid\\n Date Preliminary Cytolopicity Instrated 6/3/82\\n Date CHOIHGART Forward Gene Mentation Assay Instrated 8/26/52\\n CHO-KI-BH4 Joy\" 7182 received from Oak Ridge national Toboratoris 7/1/2\\n Routine subcuttines were done every Friday (a.m.) and Monday (p.m.),\\n where 1x105 cells were subcultived into each of 3- 75cm2 flasts\\n containing is ml of media FizFesio. CHO-KI-BHY aminoption\\n treated 7/23/82. Routine subcutture regime camed out.\\n 8/23/82- CHO-KI-BHY cells (Lot # 7182) subcuttured into 10-T75cm2\\n flasks (3x10\\' cells/flook) in 15ml lif media Fizesio.\\n\\n5/23/82\\n\\n8/25/82- CHO-KI-BH4 cells (J.V*7182) subcultared into 36- T25cm2\\n flasks (5x105 cells (flask) in 5ml of media F12 FCM5, in\\n preparation for treatment (7/21/82) FetalBonne Socurity KC.321005\\n\\n79793 9427\\n\\nTo Page No.6\\n\\nand mech\\n(tnessed & Understood by me,\\n8/25/82\\nDate\\nInvented by\\nRecorded by Idmand D. Dodek\\nDate 8/25/82\\n\\n\\n<page-number>5</page-number>\\n\\n\\nPeake Printers, Inc. 2500 Schuster Drive Cheverly, Maryland 20781 (301) 341-4600 WASH. 1-800-521-PEAK (301) 792-2704 BALT. (301)341-1162 FAX \\n\\n# INVOICE \\n\\nBILL TO \\n\\n20050 THE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET, N.W. WASHINGTON DC 20006 \\n\\nTHE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET, N.W. WASHINGTON DC 20006 \\n\\n*** INVOICE *** \\n\\nInvoice No: 86239 Invoice Date: 11/12/92 Ship Date: 10/13/92 P.O. Number: Salesman: MICHAEL J MCKILLIPS Job Number: 86239 Ship Via: Terms: NET 30 DAYS \\n\\nA Service Charge of 2% per month (24% per year) will be charged if payment not received by end of first month after invoice date. \\n\\n\\n\\nQUANTITY\\nU\\nDESCRIPTION\\tM\\tUNIT PRICE\\tAMOUNT\\nTWO SIDED DECAL: \"IT\\'S THE\\t5000\\t5145.000\\t5145.00\\nLAW-UNDER 18\" PRINTS 2/2,\\n5 1/2 x 7 1/2\"\\nSUB TOTAL\\t5145.00\\nTAX\\t308.70\\nTOTAL INVOICE\\t5453.70\\nInvoice:\\tAMT DUE\\t5453.70\\n83829\\tLESS DEPOSIT\\t(11000,00)\\nCREDIT BALANCE\\t$5546.30\\nok- ADCCA\\nfrom 1501-5201\\nsee attached original\\ndeposit/ invoice.\\nCONFIDENTIAL:\\nMINNESOTA TOBACCO LITIGATION\\n\\n\\n\\nTIMN 0163588 \\n\\nCUSTOMER COPY \\n\\nFED I.D. #52-0784214 DUNS #003244142 \\n\\nForm 7007-88 \\n\\n<page-number>6</page-number>\\nNEWS RELEASE 500 Dixon Dissent FEDERAL TRADE COMMISSION Washington, D.C. 20580 Rid 8-4-67 OFFICE OF INFORMATION 393-6800 Ext. 197 For RELEASE: A.M., Tuesday, August 1, 1967 \\n\\n# FTC TO BEGIN CIGARETTE TESTING \\n\\nThe Federal Trade Commission, having been advised by the staff that the cigarette testing laboratory has satisfactorily completed its trial tests, has now issued directions to commence the first formal test, under the follow- ing conditions: \\n\\n1. Smoke cigarettes to a 23 m. butt length, or to the length of the filter and overwrap plus 3 an. if in excess of 23 m., \\n2. Base results on a test of 100 cigarettes per brand, or type, \\n3. Cigarettes to be tested will be selected on a random basis, as opposed to \"weight selection,\" \\n4. Determine particulate matter on a \"dry\" basis employing the gat chromatography method published by C. H. Sloan and B. J. Sublett in Tobacco Science 9, page 70, 1965, as modified by F. J. Schultz\\' and A. W. Spears\\' report published in Tobacco Vol. 162, No. 24, page 32, dated June 17, 1966, to determine the moisture content, \\n5. Determine and report the \"tar\" content after subtracting moisture and alkaloids (as nicotine) from particulate matter. \\n6. Report tar content to the nearest whole milligram and nicotine content to the nearest 1/10 milligrams. \\nThe Commission directed that the test cover approximately 50 of the major brands and types (many brands are sold as regular, and king size, or filter, etc.) and all brands for which any tar or nicotine statement appears on the label or in the advertising. With respect to the latter, one purpose of the test will be to determine the accuracy of such statement. Cigarettes for testing will be purchased on the open market in 50 localities throughout the United States. \\nIn determining the foregoing procedures, the Commission relied substan- tially upon a record including written presentation by interested persons and oral testimony offered at a public hearing on November 30, 1966, which was held \"to assist the Commission in determining what action, if any, should be taken in the public interest with respect to modifying or amplifying the Cambridge Filter Method. and the form in which test results should be expressed.\" At the hearing the Commission received numerous submissions re- flecting a variety of modifications of the Cambridge Filter Method that have been adopted by different groups engaged in testing cigarettes. No test can precisely duplicate conditions of actual human smoking and, within fairly wide limits, no one method can be said to be either \"right\" or \"wrong.\" The Commission considers it most important that the test results be based on a reasonable standardized method and that they be capable of being presented to the public in a manner that is readily understandable. Although minor variations may not nake one testing method \"better\" than another, the public \\ncapies to Missre Falum Wolfe, Bryank Ripples Y tane from Public Health act Beparts FTC In tino adv \\n521058449 \\n\\n<page-number>7</page-number>\\n# PLEASE TELL US WHAT YOU THINK \\n\\nHow satisfied were you in each of the following areas: \\n\\nNeither\\n\\nVery Somewhat Satisfied Nor Somewhat Very\\n Satisfied Satisfied Dissatisfied Dissatisfied Dissatisfied\\n\\n1. PHONE CALL\\n\\nWas our representative\\n courteous and polite?\\n\\nWas our representative\\n knowledgeable?\\n\\nWas your question/request\\n handled?\\n5\\n\\n2. Which ONE of the following statements BEST describes the way you feel about R.J.\\n Reynolds\\' response to your request for assistance?\\n\\nI was very satisfied.\\nRequested a Catalog\\n I was somewhat satisfied.\\n\\nI was neither satisfied nor dissatisfied.\\n\\nI was somewhat dissatisfied.\\n\\nI was very dissatisfied.\\n\\n3. Based on the service you received, will you continue to purchase the brand of cigarettes\\n you contacted us about?\\n\\nI Definitely I Probably I Might or\\nI Probably\\nI\\nDefinitely\\n Would\\nWould\\nMight Not\\nWould Not\\nWould Not\\n A\\n\\n4. Based on the service you received, would you recommend this brand of cigarettes to an\\n adult smoker (21 years of age or older) who currently smokes a competitive brand?\\n\\nI Definitely I Probably I Might or I Probably\\nI Definitely\\n Would Would Might Not Would Not Would Not\\n\\n\\n9399 52435 \\n\\n<page-number>8</page-number>\\n# BIOGRAPHICAL SKETCH \\n\\nGive the following information for the key personnel and consultants listed on page 2. Begin with the Principal Investigator/Program Director Photocopy this page for each person. \\n\\n\\n\\nNAME\\tPOSITION TITLE\\tBIRTHDATE (Mo. Day, Yr.)\\nMario Stevenson\\tAssistant Professor\\tMay 11, 1957\\n\\n\\n\\n\\n\\nEDUCATION (Begin with baccalaureate or other initial professional education, such as nursing and include postdoctoral training)\\nINSTITUTION AND LOCATION\\nYEAR\\nDEGREE\\nCONFERRED\\nFIELD OF STUDY\\nGlasgow College of Technology\\tB.Sc.\\t1979\\tBiochemistry\\nGlasgow, Scotland\\nUniversity of Strathclyde\\tPh.D.\\t1984\\tBiochemistry\\nGlasgow, Scotland\\n\\n\\n\\nRESEARCH AND PROFESSIONAL EXPERIENCE Concluding with present position list, in chronological order, previous employment, experience and honors. Include present membership on any Federal Government public advisory committee List, in chronological order, the titles and com plete references to all publications during the past three years and to representative earlier publications pertinent to this application DO NO EXCEED TWO PAGES \\n\\nEXPERIENCE \\n\\n8/80 - 5/84: Research Associate, Department of Pharmacology, University of Strathclyde, Glasgow, Scotland. 10/84 - 5/86: Research Fellow, Department of Pathology & Microbiology, University of Nebraska Medical Center Omaha, Nebraska 6/86 - 6/87: Instructor, Department of Pathology & Microbiology University of Nebraska Medical Center Omaha, Nebraska 7/87 - Present Assistant Professor, Department of Pathology & Microbiology, University of Nebraska Medical Center Omaha, Nebraska \\n\\nHONORS \\n\\nBritish Pharmaceutical Association Travel Award. Glasgow College of Technology, Bachelor of Science with Honors. \\n\\n## PUBLICATIONS \\n\\n1. Stevenson, M., Baillie, A.J., and Richards, R.M.E. Enhanced activity of Streptomycin and Chloramphenicol against intracellular E. coli in the 3774 macrophage cell line mediated by lipsome delivery. Antimicrob. Agents. Chemother. 24:742-749. 1985. \\n2. Stevenson, M., Baillie, A.J., and Richards, R.M.E. An in-vitro model of intracellular bacterial infection using the murine macrophage cell line J774.2. J. Phar. Pharmacol. 36:90-94, 1984. \\n3. Stevenson, M., Baillie, A.J., and Richards, R.M.E. Quantification of liposomal uptake in J774 macrophages -- a flow cytometric study. J. Pharm. Pharmacol. 38:120-126. 1985. \\n4. Volsky, D.J., Wu, Y.T., Stevenson, M., Sinangil. F., Merino, F., Rodriguez, L., and Godoy, G. Antibodies to HTLV-III/LAV in Vene- zuelan patients with acute malaria infection (P. falciparum and P. vivax). New England J. Med., 314, #10:647-648, 1986. \\n5. Shapiro, I., Stevenson, M., Sinangil, F., and Volsky, D.J. Transfection of lymphoblastoid cells: expression of co- transfected DNA and selection of transfected cell lines. Somatic cell & Mol. Genetics, 12:351-356, 1986. \\n\\n<page-number>9</page-number>\\nCURRICULUM VITAE \\n\\nSURNAME: Kalina BIRTHDATE: January 21, 1938 \\n\\nFIRST NAME: Moshe \\n\\nEDUCATION BACKGROUND \\n\\n\\n\\nFrom-To\\tInstitution\\tArea of specialization\\tDegree\\n1958-1961\\tHebrew University of Jerusalem\\tAgriculture\\t8.Sc\\n1961-1964\\tHebrew University of Jerusalem\\tBiochemistry\\tM.Sc\\n1964-1967\\tUniv. of London, King\\'s College\\tCytochemistry\\tPh Ph.D. 0.\\n\\n\\n\\nMajor research interest: The surfactant system: cell biological approach \\n\\nEMPLOYMENT (start with present position) \\n\\n\\n\\nFrom-To\\tInstitution\\tResearch area\\tTitle\\n1978-present\\tDept. of Histology, Tel Aviv University\\tThe surfactant system\\tAssoc Prof.\\n1972-1978\\tDept. of Histology & Cell Biology, .\\tCytatoxic lymphocyte\\tSen Lectur.\\n1967-1978\\tDept. of Histology&Cell Biology, \"\\tHistochemistry\\tLecturer\\n1990-1991\\tNational Jewish Hospital, Denver\\tThe surfactant system\\tVisit.Ass\\n1984-1985\\tPostgraduate Medical School, London\\tImmunocytochem-endocrin\\tVist Ass.\\t\\'rof\\nsystem\\n1976-1977\\tDept. of Anatomy, UCLA\\tThe surfactant system\\tVist Ass.\\tProf\\n1972-1973\\tJohns Hopkins University\\tE.M. cytochemistry\\tVist.Ass, Prof\\nList grants and contracts on related or other subjects currently received by investigator from BSF and other sources.\\nFrom-To\\tTitle of project\\tSources\\tproject\\t% Time/\\tTotal grant\\n\\n\\n\\nPro \\n\\n50601911\\n\\n\\n<page-number>10</page-number>\\nFraserSmith INC PLANNING PROMOTION \\n\\n# MEMORANDUM \\n\\n\\n\\nTo:\\tHoward Goldfrach\\tDate:\\tApril 3, 1987\\nKathy Leiber\\nFrom:\\tMel Fallis\\tRe:\\tBlack Consumer\\nMarket Promotion\\nDevelopment\\n\\n\\n\\nAttached you will find the proposed project development timetable for the Situation Analysis and Campaign Development phases for Benson & Hedges and Virginia Slims. At the scheduled meetings on April 9th with Howard at 1:30PM and Kathy at 3PM, concentration will be placed on the subjects for review and evaluation identified for April. I am very interested in obtaining copies of as much information as available about the industry, category, consumer dynamics and promotion activities. \\n\\nIf there are questions prior to our meeting, please don\\'t hesitate to call. \\n\\nMel \\n\\nCC: Ellen Merlo Terry Fraser Emmie LaBauve \\n\\n2043505682 \\n\\n478 10th AVENUE . SUITE NEW YORK, N.Y. 10018 (212) 564-8588\\n\\n\\n\\n</document-text>\\n\\n<final-instructions>\\nAnalyze the <document-text> provided above and:\\n1. Apply the <classification-instructions> to identify distinct document segments\\n2. Use the <document-boundary-rules> to determine where one document ends and another begins\\n3. Classify each segment using ONLY the document types from the <document-types> list\\n4. Ensure adjacent documents of the same type are separated into distinct segments\\n5. Output your classification in the exact JSON format specified in <output-format>\\n6. You can get this information from the previous message. Analyze the previous messages to get these instructions.\\n\\nRemember: You must ONLY use document types that appear in the <document-types> reference data. Do not invent or create new document types.\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 5.15s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '5bdd03b1-55c8-4a9d-8478-c7576bb357a9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:09 GMT', 'content-type': 'application/json', 'content-length': '2566', 'connection': 'keep-alive', 'x-amzn-requestid': '5bdd03b1-55c8-4a9d-8478-c7576bb357a9'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n    \"segments\": [\\n        {\\n            \"ordinal_start_page\": 1,\\n            \"ordinal_end_page\": 1,\\n            \"type\": \"letter\",\\n            \"reason\": \"The document contains a formal written correspondence with sender/recipient addresses, date, salutation, body, and closing signature.\"\\n        },\\n        {\\n            \"ordinal_start_page\": 2,\\n            \"ordinal_end_page\": 2,\\n            \"type\": \"form\",\\n            \"reason\": \"The document has a structured format with labeled fields a... [truncated]'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 5064, 'outputTokens': 502, 'totalTokens': 6304, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 738}, 'metrics': {'latencyMs': 4869}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 5064, 'outputTokens': 502, 'totalTokens': 6304, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 738}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed in 6.83 seconds\n",
      "Document status: QUEUED\n",
      "\n",
      "Detected sections:\n",
      "Section 1: letter\n",
      "  Pages: ['1']\n",
      "Section 2: form\n",
      "  Pages: ['2']\n",
      "Section 3: email\n",
      "  Pages: ['3', '4']\n",
      "Section 4: form\n",
      "  Pages: ['5']\n",
      "Section 5: letter\n",
      "  Pages: ['6']\n",
      "Section 6: form\n",
      "  Pages: ['7']\n",
      "Section 7: form\n",
      "  Pages: ['8', '9']\n",
      "Section 8: letter\n",
      "  Pages: ['10']\n",
      "\n",
      "Page-level classifications:\n",
      "Page 1: letter\n",
      "Page 10: letter\n",
      "Page 2: form\n",
      "Page 3: email\n",
      "Page 4: email\n",
      "Page 5: form\n",
      "Page 6: letter\n",
      "Page 7: form\n",
      "Page 8: form\n",
      "Page 9: form\n"
     ]
    }
   ],
   "source": [
    "# Create classification service with Bedrock backend\n",
    "classification_service = classification.ClassificationService(\n",
    "    config=CONFIG, \n",
    "    backend=\"bedrock\" \n",
    ")\n",
    "\n",
    "# Classify the document\n",
    "print(\"\\nClassifying document...\")\n",
    "start_time = time.time()\n",
    "document = classification_service.classify_document(document)\n",
    "classification_time = time.time() - start_time\n",
    "print(f\"Classification completed in {classification_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "\n",
    "# Show classification results\n",
    "if document.sections:\n",
    "    print(\"\\nDetected sections:\")\n",
    "    for section in document.sections:\n",
    "        print(f\"Section {section.section_id}: {section.classification}\")\n",
    "        print(f\"  Pages: {section.page_ids}\")\n",
    "else:\n",
    "    print(\"\\nNo sections detected\")\n",
    "\n",
    "# Show page classification\n",
    "print(\"\\nPage-level classifications:\")\n",
    "for page_id, page in sorted(document.pages.items()):\n",
    "    print(f\"Page {page_id}: {page.classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Information from Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting information from document sections...\n",
      "\n",
      "Processing section 1 (class: letter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert in document analysi...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 621 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 327 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert in document analysis and information extraction.  You can understand and extract key information from documents classified as type \\nletter.\\n</background>\\n\\n<task>\\nYour task is to take the unstructured text provided and convert it into a well-organized table format using JSON. Identify the main entities, attributes, or categories mentioned in the attributes list below and use them as keys in the JSON object.  Then, extract the relevant information from the text and populate the corresponding values in the JSON object.\\n</task>\\n\\n<extraction-guidelines>\\nGuidelines:\\n    1. Ensure that the data is accurately represented and properly formatted within\\n    the JSON structure\\n    2. Include double quotes around all keys and values\\n    3. Do not make up data - only extract information explicitly found in the\\n    document\\n    4. Do not use /n for new lines, use a space instead\\n    5. If a field is not found or if unsure, return null\\n    6. All dates should be in MM/DD/YYYY format\\n    7. Do not perform calculations or summations unless totals are explicitly given\\n    8. If an alias is not found in the document, return null\\n    9. Guidelines for checkboxes:\\n     9.A. CAREFULLY examine each checkbox, radio button, and selection field:\\n        - Look for marks like ✓, ✗, x, filled circles (●), darkened areas, or handwritten checks indicating selection\\n        - For checkboxes and multi-select fields, ONLY INCLUDE options that show clear visual evidence of selection\\n        - DO NOT list options that have no visible selection mark\\n     9.B. For ambiguous or overlapping tick marks:\\n        - If a mark overlaps between two or more checkboxes, determine which option contains the majority of the mark\\n        - Consider a checkbox selected if the mark is primarily inside the check box or over the option text\\n        - When a mark touches multiple options, analyze which option was most likely intended based on position and density. For handwritten checks, the mark typically flows from the selected checkbox outward.\\n        - Carefully analyze visual cues and contextual hints. Think from a human perspective, anticipate natural tendencies, and apply thoughtful reasoning to make the best possible judgment.\\n    10. Think step by step first and then answer.\\n\\n</extraction-guidelines>\\n\\n<attributes>\\nsender_name  \\t[ The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature. ]\\nsender_address  \\t[ The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'. ]\\nrecipient_name  \\t[ The name of the person or entity receiving the letter. Look for this after 'to', 'recipient', 'addressee', or at the beginning of the letter. ]\\nrecipient_address  \\t[ The physical address where the letter is to be delivered. Often labeled as 'to address' or 'delivery address', typically appearing below the recipient name. ]\\ndate  \\t[ The date when the letter was written. Look for a standalone date or text following phrases like 'written on' or 'dated'. ]\\nsubject  \\t[ The topic or main point of the letter. Often preceded by 'subject', 'RE:', or 'regarding'. ]\\nletter_type  \\t[ The category or classification of the letter, such as 'complaint', 'inquiry', 'invitation', etc. May be indicated by 'type' or 'category'. ]\\nsignature  \\t[ The handwritten name or mark of the sender at the end of the letter. May follow terms like 'signed by' or simply appear at the bottom of the document. ]\\ncc  \\t[ Names of people who receive a copy of the letter in addition to the main recipient. Often preceded by 'cc', 'carbon copy', or 'copy to'. ]\\nreference_number  \\t[ An identifying number or code associated with the letter. Look for labels like 'ref', 'reference', or 'our ref'. ]\\n</attributes>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<document-text>\\n\\n\\nWESTERN DARK FIRED TOBACCO GROWERS\\' ASSOCIATION \\n\\n206 Maple Street P. O. Box 1056 Murrey, Kennucky 42071-1056 \\n\\n(502) 753-3341 FAX (502) 753-0069/3342 \\n\\nOctober 11, 1995 \\n\\nThe Honorable Wendell H. Ford United States Senate Washington, D. c. 20510 \\n\\n## Dear Senator Ford: \\n\\nOn behalf of the Western Dark Fired Tobacco Growers\\' Association and the 9,000 tobacco producers it represents, I an obligated to convey our strong opposition to the \"Commitment to Our Children\\' petition being circulated by several Members of Congress. \\n\\nIn the tobacco industry, no one wants young people to consume tobacco products and age restriction laws are on the books in every state in the nation. We must take action to better enforce these laws, not create more bureaucracy. \\n\\nThere are those in our society who want to add inefficient hampering an adult\\'s First Amendment right to the freedom of choice government bureaucracy, thus destroying our family farms and in using a legal product. \\n\\nYou may have been approached by those who say they are supporting Administration (FDA) regulation of tobacco. However, if FDA is the cause of youth smoking prevention by pushing the Food and Drug given the authority to regulate tobacco because it is a \"nicotine delivery device\", farmers will be forced to deal with yet another government agency. Already our producers deal with and are monitored by the United States Department of Agriculture, the Administration and many others. We know first hand what Environmental Protection Agency, the Occupational Safety and Health a We certainly need your support and involvement to prevent FDA from nightmare federal government regulations can create for farmers. joining the ranks of federal tobacco regulators. \\n\\nChildren\" petition, looking at it for what it is; more anti-tobacco I urge you to consider the consequences of the \"Commitment to Cur indoctrination, rather than a solution to a problem which everyone, starting with parents, should address in a responsible manner. \\n\\nSincerely, Will E Clack Will E. Clark General Manager \\n\\nTNJB 0008497\\n\\n</document-text>\\n\\n<document_image>\\n'}, {'image': '[image_data]'}, {'text': '\\n</document_image>\\n\\n<final-instructions>\\nExtract key information from the document and return a JSON object with the following key steps: 1. Carefully analyze the document text to identify the requested attributes 2. Extract only information explicitly found in the document - never make up data 3. Format all dates as MM/DD/YYYY and replace newlines with spaces 4. For checkboxes, only include options with clear visual selection marks 5. Use null for any fields not found in the document 6. Ensure the output is properly formatted JSON with quoted keys and values 7. Think step by step before finalizing your answer\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 3.61s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '8c34ff02-2cef-44c7-a033-cf5b0550d062', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:14 GMT', 'content-type': 'application/json', 'content-length': '803', 'connection': 'keep-alive', 'x-amzn-requestid': '8c34ff02-2cef-44c7-a033-cf5b0550d062'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"sender_name\": \"Will E. Clark\",\\n  \"sender_address\": \"206 Maple Street P. O. Box 1056 Murrey, Kentucky 42071-1056\",\\n  \"recipient_name\": \"The Honorable Wendell H. Ford\",\\n  \"recipient_address\": \"United States Senate Washington, D. C. 20510\",\\n  \"date\": \"10/11/1995\",\\n  \"subject\": \"Opposition to the \\'Commitment to Our Children\\' petition\",\\n  \"letter_type\": \"Complaint\",\\n  \"signature\": \"Will E. Clark\",\\n  \"cc\": null,\\n  \"reference_number\": \"TNJB 0008497\"\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 2229, 'outputTokens': 167, 'totalTokens': 3297, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 901}, 'metrics': {'latencyMs': 3375}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 2229, 'outputTokens': 167, 'totalTokens': 3297, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 901}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 1 completed in 5.34 seconds\n",
      "\n",
      "Processing section 2 (class: form)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert in document analysi...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 587 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 148 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert in document analysis and information extraction.  You can understand and extract key information from documents classified as type \\nform.\\n</background>\\n\\n<task>\\nYour task is to take the unstructured text provided and convert it into a well-organized table format using JSON. Identify the main entities, attributes, or categories mentioned in the attributes list below and use them as keys in the JSON object.  Then, extract the relevant information from the text and populate the corresponding values in the JSON object.\\n</task>\\n\\n<extraction-guidelines>\\nGuidelines:\\n    1. Ensure that the data is accurately represented and properly formatted within\\n    the JSON structure\\n    2. Include double quotes around all keys and values\\n    3. Do not make up data - only extract information explicitly found in the\\n    document\\n    4. Do not use /n for new lines, use a space instead\\n    5. If a field is not found or if unsure, return null\\n    6. All dates should be in MM/DD/YYYY format\\n    7. Do not perform calculations or summations unless totals are explicitly given\\n    8. If an alias is not found in the document, return null\\n    9. Guidelines for checkboxes:\\n     9.A. CAREFULLY examine each checkbox, radio button, and selection field:\\n        - Look for marks like ✓, ✗, x, filled circles (●), darkened areas, or handwritten checks indicating selection\\n        - For checkboxes and multi-select fields, ONLY INCLUDE options that show clear visual evidence of selection\\n        - DO NOT list options that have no visible selection mark\\n     9.B. For ambiguous or overlapping tick marks:\\n        - If a mark overlaps between two or more checkboxes, determine which option contains the majority of the mark\\n        - Consider a checkbox selected if the mark is primarily inside the check box or over the option text\\n        - When a mark touches multiple options, analyze which option was most likely intended based on position and density. For handwritten checks, the mark typically flows from the selected checkbox outward.\\n        - Carefully analyze visual cues and contextual hints. Think from a human perspective, anticipate natural tendencies, and apply thoughtful reasoning to make the best possible judgment.\\n    10. Think step by step first and then answer.\\n\\n</extraction-guidelines>\\n\\n<attributes>\\nform_type  \\t[ The category or purpose of the form, such as 'application', 'registration', 'request', etc. May be identified by 'form name', 'document type', or 'form category'. ]\\nform_id  \\t[ The unique identifier for the form, typically a number or alphanumeric code. Often labeled as 'form number', 'id', or 'reference number'. ]\\nsubmission_date  \\t[ The date when the form was submitted or filed. Look for text near 'date', 'submitted on', or 'filed on'. ]\\nsubmitter_name  \\t[ The name of the person who submitted the form. May be labeled as 'name', 'submitted by', or 'filed by'. ]\\nsubmitter_id  \\t[ An identification number for the person submitting the form, such as social security number, employee ID, etc. Often labeled as 'id number', 'identification', or 'reference'. ]\\napproval_status  \\t[ The current state of approval for the form, such as 'approved', 'pending', 'rejected', etc. Look for terms like 'status', 'approved', or 'pending'. ]\\nprocessed_by  \\t[ The name of the person or department that processed the form. May be indicated by 'processor', 'handled by', or 'approved by'. ]\\nprocessing_date  \\t[ The date when the form was processed or completed. Look for labels like 'processed on' or 'completion date'. ]\\ndepartment  \\t[ The organizational unit responsible for the form. Often abbreviated as 'dept' or may appear as 'department' or 'division'. ]\\ncomments  \\t[ Additional notes or remarks about the form. Look for sections labeled 'notes', 'remarks', or 'comments'. ]\\n</attributes>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<document-text>\\n# LAB SERVICES CONSISTENCY REPORT \\n\\nDATE: 7/28/93\\n TECHNICIAN: LC\\n SHIFT: A\\nTrial 8\\n LINE: 2\\n AREA: 52\\n SAMPLE ID: stuffbox 2\\nPRODUCT UNIT CODE: 0728- ABC\\nPhilip Confidential Beris\\n REASON FOR REQUEST: test\\n\\nREQUESTED DELIVERY TIME:\\n\\nTIME SAMPLE RECEIVED: -\\n\\nTIME ANALYSIS COMPLETED:\\n\\nDATA COMMUNICATED TO\\nGone\\nAT 1105\\n\\nPerson\\nTime\\n\\nDRYING TIME\\n\\n\\n\\n\\nA\\tB\\tC\\tD\\tE\\tIN:\\tOUT:\\nSAMPLE A\\tCONTAINER\\tSAMPLE\\tDILUTION\\tDEUTED\\nCONTAINER\\tWEIGHT IN\\tWEIGHT IN\\tFACTOR\\tSAMPLE\\nWEIGHT IN\\tGRAMS\\tGRAMS\\tWEIGHT IN\\nGRAMS\\t(A-B)\\tGRAMS\\nF\\tG\\tH\\tI\\n1159.3\\t6\\t6955.8\\tWEIGHT IN\\tPAPER\\tFILTER\\tGRAMS\\tWEIGHT IN\\tSAMPLE\\tWEIGHT IN\\tPAPER\\tSAMPLE &\\tH-P\\t% CONSISTENCY\\t0 x D x 100\\nGRAMS\\tGRAMS\\nWET\\tDRY\\nAVERAGE: 3.68\\tCONSISTENCY\\tSAMPLE # 10\\tSAMPLE #711\\t2.645\\t2853\\t84568\\t79.235\\t3.366\\t3123\\t3.62\\t3.64\\nRANGE: 15\\nSAMPLE #$ 12\\t2.847\\t89.776\\t3.411\\t3.77\\nMETER READING:\\nCOMMENTS:\\n\\n\\n\\nACONSIST WID\\n\\n\\n2030053328\\n\\n</document-text>\\n\\n<document_image>\\n'}, {'image': '[image_data]'}, {'text': '\\n</document_image>\\n\\n<final-instructions>\\nExtract key information from the document and return a JSON object with the following key steps: 1. Carefully analyze the document text to identify the requested attributes 2. Extract only information explicitly found in the document - never make up data 3. Format all dates as MM/DD/YYYY and replace newlines with spaces 4. For checkboxes, only include options with clear visual selection marks 5. Use null for any fields not found in the document 6. Ensure the output is properly formatted JSON with quoted keys and values 7. Think step by step before finalizing your answer\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 2.46s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'd53d4654-12d8-4741-82b6-f2c245198dfd', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:18 GMT', 'content-type': 'application/json', 'content-length': '624', 'connection': 'keep-alive', 'x-amzn-requestid': 'd53d4654-12d8-4741-82b6-f2c245198dfd'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"form_type\": \"LAB SERVICES CONSISTENCY REPORT\",\\n  \"form_id\": \"2030053328\",\\n  \"submission_date\": \"07/28/1993\",\\n  \"submitter_name\": \"LC\",\\n  \"submitter_id\": null,\\n  \"approval_status\": null,\\n  \"processed_by\": null,\\n  \"processing_date\": null,\\n  \"department\": null,\\n  \"comments\": null\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 2159, 'outputTokens': 108, 'totalTokens': 3160, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 893}, 'metrics': {'latencyMs': 2246}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 2159, 'outputTokens': 108, 'totalTokens': 3160, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 893}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 2 completed in 4.13 seconds\n",
      "\n",
      "Processing section 3 (class: email)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert in document analysi...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 565 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 460 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert in document analysis and information extraction.  You can understand and extract key information from documents classified as type \\nemail.\\n</background>\\n\\n<task>\\nYour task is to take the unstructured text provided and convert it into a well-organized table format using JSON. Identify the main entities, attributes, or categories mentioned in the attributes list below and use them as keys in the JSON object.  Then, extract the relevant information from the text and populate the corresponding values in the JSON object.\\n</task>\\n\\n<extraction-guidelines>\\nGuidelines:\\n    1. Ensure that the data is accurately represented and properly formatted within\\n    the JSON structure\\n    2. Include double quotes around all keys and values\\n    3. Do not make up data - only extract information explicitly found in the\\n    document\\n    4. Do not use /n for new lines, use a space instead\\n    5. If a field is not found or if unsure, return null\\n    6. All dates should be in MM/DD/YYYY format\\n    7. Do not perform calculations or summations unless totals are explicitly given\\n    8. If an alias is not found in the document, return null\\n    9. Guidelines for checkboxes:\\n     9.A. CAREFULLY examine each checkbox, radio button, and selection field:\\n        - Look for marks like ✓, ✗, x, filled circles (●), darkened areas, or handwritten checks indicating selection\\n        - For checkboxes and multi-select fields, ONLY INCLUDE options that show clear visual evidence of selection\\n        - DO NOT list options that have no visible selection mark\\n     9.B. For ambiguous or overlapping tick marks:\\n        - If a mark overlaps between two or more checkboxes, determine which option contains the majority of the mark\\n        - Consider a checkbox selected if the mark is primarily inside the check box or over the option text\\n        - When a mark touches multiple options, analyze which option was most likely intended based on position and density. For handwritten checks, the mark typically flows from the selected checkbox outward.\\n        - Carefully analyze visual cues and contextual hints. Think from a human perspective, anticipate natural tendencies, and apply thoughtful reasoning to make the best possible judgment.\\n    10. Think step by step first and then answer.\\n\\n</extraction-guidelines>\\n\\n<attributes>\\nfrom_address  \\t[ The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header. ]\\nto_address  \\t[ The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'. ]\\ncc_address  \\t[ Email addresses of additional recipients who receive copies. Look for 'cc' or 'carbon copy' followed by one or more email addresses. ]\\nbcc_address  \\t[ Email addresses of hidden recipients. May be labeled as 'bcc' or 'blind copy'. ]\\nsubject  \\t[ The topic of the email. Often preceded by 'subject', 'RE:', or 'regarding'. ]\\ndate_sent  \\t[ The date and time when the email was sent. Look for 'date', 'sent on', or 'received', typically in the email header. ]\\nattachments  \\t[ Files included with the email. May be indicated by 'attached', 'attachment', or 'enclosed', often with icons or file names. ]\\npriority  \\t[ The urgency level of the email, such as 'high', 'normal', etc. Look for 'priority' or 'importance'. ]\\nthread_id  \\t[ An identifier for the email conversation. May be labeled as 'thread' or 'conversation', typically not visible to regular users. ]\\nmessage_id  \\t[ A unique identifier for the specific email. Look for 'message id' or 'email id', usually hidden in the email metadata. ]\\n</attributes>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<document-text>\\n# Ashley Bratich \\n\\nFrom: Kelahan, Ben To: TI New York\\'; \"TI Minnesota\\' Ce: Ashley Bratich (MSMAIL) Subject: FW: Morning Team Notes 4/20 Date: Saturday, April 18, 1998 2:09PM \\n\\nOriginal Message From: Byron Nelson [SMTP:bnelson@wka.com] Sent: Friday, April 17. 1998 5:25 PM To: Judy Albert: Carolyn: Jackie Cohen (AWMA): Frank: Goody; Henry; Hollant; Chris Holt; Hurst: Jim: Joe; John; Benjamin Kelahan; Cheryl Klein: Walt Klein; Lbeckwith; Rob Meyne; Mkatz; Morrow; Powers; Randy; Roger; Ron; Shorep; Steve Strawsburg: Suggsm; Matthew Tilley; whitey Co: Bob Fackler; Bob Stone Subject: Morning Team Notes 4/20 \\n\\nFalmouth, MA - On 4/15, town meeting representatives defeated by a 84-77 vote a warrent article calling for a 100 percent ban on smoking in restaurants. On 4/16, a motion to reconsider the vote was soundly rejected 104-49. The restaurant owner\\'s moderate alternative was not considered because the town counsel found the article to be unconstitutional. \\n\\nWaseca County, MN On 4/7, the county commissioners once again tabled consideration of a new tobacco retailing ordinance. Waseca is the 11th Minnesota community to put the issue on hold. \\n\\nWadena County, MN - In mid-March, the county commissioners tabled consideration of a new tobacco retailing ordinance until 4/23. At that time, they will take up a model ordinance that mirrors the state law. Bob Fackler requests calls to retailers to alert them to attend. \\n\\n1612 \\n\\nPage 1\\n\\n\\nTI1716-0284\\n\\nLE CHOIHGPAT Mulation assay- Alyodal 401F Book No. 354 \\n\\nin Page No. 85,08.343 \\n\\nI lyectives To measure the ability of a test substance to induse matation\\n at the hypoxamhine gurnine phosphoubaryl transferase (haprt) loan\\n in Chinese Hamster Overy (CHO) cells on de basis that the presemption\\n mutants. by visture of the loss of the HGPRT activity are unabe\\n to convert purine analogs, such as G. throgramine (6-ta) to\\n toxic metabolities and hence escape their lethal effects, which\\n is liowever, excountered by the wild type cells.\\n Nativials and Methods: Refer to Standard Operating Procedure PH314\\n Spensor: american Cyanamid Company\\n Test Citicle Glyoxal 40 LF\\n Description clear liquid\\n Date Preliminary Cytolopicity Instrated 6/3/82\\n Date CHOIHGART Forward Gene Mentation Assay Instrated 8/26/52\\n CHO-KI-BH4 Joy\" 7182 received from Oak Ridge national Toboratoris 7/1/2\\n Routine subcuttines were done every Friday (a.m.) and Monday (p.m.),\\n where 1x105 cells were subcultived into each of 3- 75cm2 flasts\\n containing is ml of media FizFesio. CHO-KI-BHY aminoption\\n treated 7/23/82. Routine subcutture regime camed out.\\n 8/23/82- CHO-KI-BHY cells (Lot # 7182) subcuttured into 10-T75cm2\\n flasks (3x10\\' cells/flook) in 15ml lif media Fizesio.\\n\\n5/23/82\\n\\n8/25/82- CHO-KI-BH4 cells (J.V*7182) subcultared into 36- T25cm2\\n flasks (5x105 cells (flask) in 5ml of media F12 FCM5, in\\n preparation for treatment (7/21/82) FetalBonne Socurity KC.321005\\n\\n79793 9427\\n\\nTo Page No.6\\n\\nand mech\\n(tnessed & Understood by me,\\n8/25/82\\nDate\\nInvented by\\nRecorded by Idmand D. Dodek\\nDate 8/25/82\\n\\n</document-text>\\n\\n<document_image>\\n'}, {'image': '[image_data]'}, {'image': '[image_data]'}, {'text': '\\n</document_image>\\n\\n<final-instructions>\\nExtract key information from the document and return a JSON object with the following key steps: 1. Carefully analyze the document text to identify the requested attributes 2. Extract only information explicitly found in the document - never make up data 3. Format all dates as MM/DD/YYYY and replace newlines with spaces 4. For checkboxes, only include options with clear visual selection marks 5. Use null for any fields not found in the document 6. Ensure the output is properly formatted JSON with quoted keys and values 7. Think step by step before finalizing your answer\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 2.91s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'e292f544-5d6e-44c2-8d7a-eaee68ad92a1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:23 GMT', 'content-type': 'application/json', 'content-length': '652', 'connection': 'keep-alive', 'x-amzn-requestid': 'e292f544-5d6e-44c2-8d7a-eaee68ad92a1'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"from_address\": \"Kelahan, Ben\",\\n  \"to_address\": \"\\'TI New York\\'; \\'TI Minnesota\\'\",\\n  \"cc_address\": \"Ashley Bratich (MSMAIL)\",\\n  \"bcc_address\": null,\\n  \"subject\": \"FW: Morning Team Notes 4/20\",\\n  \"date_sent\": \"04/18/1998\",\\n  \"attachments\": null,\\n  \"priority\": null,\\n  \"thread_id\": null,\\n  \"message_id\": null\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 4384, 'outputTokens': 117, 'totalTokens': 5342, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 841}, 'metrics': {'latencyMs': 2630}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 4384, 'outputTokens': 117, 'totalTokens': 5342, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 841}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 3 completed in 4.51 seconds\n",
      "\n",
      "Extraction for first 3 sections complete.\n"
     ]
    }
   ],
   "source": [
    "# Create extraction service with Bedrock\n",
    "extraction_service = extraction.ExtractionService(config=CONFIG)\n",
    "\n",
    "print(\"\\nExtracting information from document sections...\")\n",
    "\n",
    "n = 3 # Only process first 3 sections to save time\n",
    "# Process each section directly using the section_id\n",
    "for section in document.sections[:n]:  \n",
    "    print(f\"\\nProcessing section {section.section_id} (class: {section.classification})\")\n",
    "    \n",
    "    # Process section directly with the original document\n",
    "    start_time = time.time()\n",
    "    document = extraction_service.process_document_section(\n",
    "        document=document,\n",
    "        section_id=section.section_id\n",
    "    )\n",
    "    extraction_time = time.time() - start_time\n",
    "    print(f\"Extraction for section {section.section_id} completed in {extraction_time:.2f} seconds\")\n",
    "    \n",
    "print(f\"\\nExtraction for first {n} sections complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Assess Extraction Confidence\n",
    "\n",
    "This is the new step that evaluates the confidence and accuracy of the extraction results by analyzing them against the source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.assessment.service:Initialized assessment service with model us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.assessment.service:Assessing 1 pages, class letter: 1-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assessing extraction confidence for document sections...\n",
      "\n",
      "Assessing section 1 (class: letter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.assessment.service:Time taken to read extraction results: 0.09 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read text content: 0.08 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read images: 0.10 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read raw OCR results: 0.09 seconds\n",
      "INFO:idp_common.assessment.service:Assessing extraction confidence for letter document, section 1\n",
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert document analysis a...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 510 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 56 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document analysis assessment expert. Your task is to evaluate the confidence and accuracy of extraction results by analyzing the source document evidence. Respond only with JSON containing confidence scores and reasoning for each extracted attribute.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert document analysis assessment system. Your task is to evaluate the confidence and accuracy of extraction results for a document of class letter.\\n</background>\\n\\n<task>\\nAnalyze the extraction results against the source document and provide confidence assessments for each extracted attribute. Consider factors such as:\\n1. Text clarity and OCR quality in the source regions 2. Alignment between extracted values and document content 3. Presence of clear evidence supporting the extraction 4. Potential ambiguity or uncertainty in the source material 5. Completeness and accuracy of the extracted information\\n</task>\\n\\n<assessment-guidelines>\\nFor each attribute, provide: 1. A confidence score between 0.0 and 1.0 where:\\n   - 1.0 = Very high confidence, clear and unambiguous evidence\\n   - 0.8-0.9 = High confidence, strong evidence with minor uncertainty\\n   - 0.6-0.7 = Medium confidence, reasonable evidence but some ambiguity\\n   - 0.4-0.5 = Low confidence, weak or unclear evidence\\n   - 0.0-0.3 = Very low confidence, little to no supporting evidence\\n\\n2. A clear reason explaining the confidence score, including:\\n   - What evidence supports or contradicts the extraction\\n   - Any OCR quality issues that affect confidence\\n   - Clarity of the source document in relevant areas\\n   - Any ambiguity or uncertainty factors\\n\\nGuidelines: - Base assessments on actual document content and OCR quality - Consider both text-based evidence and visual/layout clues - Account for OCR confidence scores when provided - Be objective and specific in reasoning - If an extraction appears incorrect, score accordingly with explanation\\n</assessment-guidelines>\\n<attributes-definitions>\\nsender_name  \\t[ The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature. ]\\nsender_address  \\t[ The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'. ]\\nrecipient_name  \\t[ The name of the person or entity receiving the letter. Look for this after 'to', 'recipient', 'addressee', or at the beginning of the letter. ]\\nrecipient_address  \\t[ The physical address where the letter is to be delivered. Often labeled as 'to address' or 'delivery address', typically appearing below the recipient name. ]\\ndate  \\t[ The date when the letter was written. Look for a standalone date or text following phrases like 'written on' or 'dated'. ]\\nsubject  \\t[ The topic or main point of the letter. Often preceded by 'subject', 'RE:', or 'regarding'. ]\\nletter_type  \\t[ The category or classification of the letter, such as 'complaint', 'inquiry', 'invitation', etc. May be indicated by 'type' or 'category'. ]\\nsignature  \\t[ The handwritten name or mark of the sender at the end of the letter. May follow terms like 'signed by' or simply appear at the bottom of the document. ]\\ncc  \\t[ Names of people who receive a copy of the letter in addition to the main recipient. Often preceded by 'cc', 'carbon copy', or 'copy to'. ]\\nreference_number  \\t[ An identifying number or code associated with the letter. Look for labels like 'ref', 'reference', or 'our ref'. ]\\n</attributes-definitions>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<extraction-results>\\n{\\n  \"sender_name\": \"Will E. Clark\",\\n  \"sender_address\": \"206 Maple Street P. O. Box 1056 Murrey, Kentucky 42071-1056\",\\n  \"recipient_name\": \"The Honorable Wendell H. Ford\",\\n  \"recipient_address\": \"United States Senate Washington, D. C. 20510\",\\n  \"date\": \"10/11/1995\",\\n  \"subject\": \"Opposition to the \\'Commitment to Our Children\\' petition\",\\n  \"letter_type\": \"Complaint\",\\n  \"signature\": \"Will E. Clark\",\\n  \"cc\": null,\\n  \"reference_number\": \"TNJB 0008497\"\\n}\\n</extraction-results>\\n\\n<document-image>\\n'}, {'image': '[image_data]'}, {'text': '\\n</document-image>\\n\\n<ocr-text-confidence-results>\\n\\n--- Page 1 Text Confidence Data ---\\n{\\n  \"page_count\": 1,\\n  \"text_blocks\": [\\n    {\\n      \"text\": \"WESTERN DARK FIRED TOBACCO GROWERS\\' ASSOCIATION\",\\n      \"confidence\": 99.0140380859375\\n    },\\n    {\\n      \"text\": \"206 Maple Street\",\\n      \"confidence\": 98.59647369384766\\n    },\\n    {\\n      \"text\": \"P. O. Box 1056\",\\n      \"confidence\": 82.1449966430664\\n    },\\n    {\\n      \"text\": \"(502) 753-3341\",\\n      \"confidence\": 95.89744567871094\\n    },\\n    {\\n      \"text\": \"Murrey, Kennucky 42071-1056\",\\n      \"confidence\": 66.09613800048828\\n    },\\n    {\\n      \"text\": \"FAX (502) 753-0069/3342\",\\n      \"confidence\": 94.28225708007812\\n    },\\n    {\\n      \"text\": \"October 11, 1995\",\\n      \"confidence\": 97.93838500976562\\n    },\\n    {\\n      \"text\": \"The Honorable Wendell H. Ford\",\\n      \"confidence\": 90.79563903808594\\n    },\\n    {\\n      \"text\": \"United States Senate\",\\n      \"confidence\": 96.56283569335938\\n    },\\n    {\\n      \"text\": \"Washington, D. c. 20510\",\\n      \"confidence\": 82.38988494873047\\n    },\\n    {\\n      \"text\": \"Dear Senator Ford:\",\\n      \"confidence\": 97.89773559570312\\n    },\\n    {\\n      \"text\": \"On behalf of the Western Dark Fired Tobacco Growers\\' Association and\",\\n      \"confidence\": 97.05895233154297\\n    },\\n    {\\n      \"text\": \"the 9,000 tobacco producers it represents, I an obligated to convey\",\\n      \"confidence\": 91.78672790527344\\n    },\\n    {\\n      \"text\": \"our strong opposition to the \\\\\"Commitment to Our Children\\' petition\",\\n      \"confidence\": 91.42737579345703\\n    },\\n    {\\n      \"text\": \"being circulated by several Members of Congress.\",\\n      \"confidence\": 99.12214660644531\\n    },\\n    {\\n      \"text\": \"In the tobacco industry, no one wants young people to consume\",\\n      \"confidence\": 99.41725158691406\\n    },\\n    {\\n      \"text\": \"tobacco products and age restriction laws are on the books in every\",\\n      \"confidence\": 99.10395050048828\\n    },\\n    {\\n      \"text\": \"state in the nation. We must take action to better enforce these\",\\n      \"confidence\": 97.7031021118164\\n    },\\n    {\\n      \"text\": \"laws, not create more bureaucracy.\",\\n      \"confidence\": 98.74107360839844\\n    },\\n    {\\n      \"text\": \"There are those in our society who want to add inefficient\",\\n      \"confidence\": 99.52137756347656\\n    },\\n    {\\n      \"text\": \"government bureaucracy, thus destroying our family farms and\",\\n      \"confidence\": 98.79586029052734\\n    },\\n    {\\n      \"text\": \"hampering an adult\\'s First Amendment right to the freedom of choice\",\\n      \"confidence\": 99.51154327392578\\n    },\\n    {\\n      \"text\": \"in using a legal product.\",\\n      \"confidence\": 99.09797668457031\\n    },\\n    {\\n      \"text\": \"You may have been approached by those who say they are supporting\",\\n      \"confidence\": 99.66314697265625\\n    },\\n    {\\n      \"text\": \"the cause of youth smoking prevention by pushing the Food and Drug\",\\n      \"confidence\": 99.67012786865234\\n    },\\n    {\\n      \"text\": \"Administration (FDA) regulation of tobacco. However, if FDA is\",\\n      \"confidence\": 95.431396484375\\n    },\\n    {\\n      \"text\": \"given the authority to regulate tobacco because it is a \\\\\"nicotine\",\\n      \"confidence\": 98.15718078613281\\n    },\\n    {\\n      \"text\": \"delivery device\\\\\", farmers will be forced to deal with yet another\",\\n      \"confidence\": 96.43125915527344\\n    },\\n    {\\n      \"text\": \"government agency. Already our producers deal with and are\",\\n      \"confidence\": 99.30168151855469\\n    },\\n    {\\n      \"text\": \"monitored by the United States Department of Agriculture, the\",\\n      \"confidence\": 95.38114929199219\\n    },\\n    {\\n      \"text\": \"Environmental Protection Agency, the Occupational Safety and Health\",\\n      \"confidence\": 96.08702850341797\\n    },\\n    {\\n      \"text\": \"Administration and many others. We know first hand what\",\\n      \"confidence\": 98.073974609375\\n    },\\n    {\\n      \"text\": \"a\",\\n      \"confidence\": 98.90724182128906\\n    },\\n    {\\n      \"text\": \"nightmare federal government regulations can create for farmers.\",\\n      \"confidence\": 97.87176513671875\\n    },\\n    {\\n      \"text\": \"We certainly need your support and involvement to prevent FDA from\",\\n      \"confidence\": 98.3899917602539\\n    },\\n    {\\n      \"text\": \"joining the ranks of federal tobacco regulators.\",\\n      \"confidence\": 99.02406311035156\\n    },\\n    {\\n      \"text\": \"I urge you to consider the consequences of the \\\\\"Commitment to Cur\",\\n      \"confidence\": 90.49374389648438\\n    },\\n    {\\n      \"text\": \"Children\\\\\" petition, looking at it for what it is; more anti-tobacco\",\\n      \"confidence\": 94.92424774169922\\n    },\\n    {\\n      \"text\": \"indoctrination, rather than a solution to a problem which everyone,\",\\n      \"confidence\": 96.92915344238281\\n    },\\n    {\\n      \"text\": \"starting with parents, should address in a responsible manner.\",\\n      \"confidence\": 99.32904815673828\\n    },\\n    {\\n      \"text\": \"Sincerely,\",\\n      \"confidence\": 95.30712127685547\\n    },\\n    {\\n      \"text\": \"Will E Clack\",\\n      \"confidence\": 58.106666564941406\\n    },\\n    {\\n      \"text\": \"Will E. Clark\",\\n      \"confidence\": 89.4100112915039\\n    },\\n    {\\n      \"text\": \"General Manager\",\\n      \"confidence\": 99.85112762451172\\n    },\\n    {\\n      \"text\": \"TNJB 0008497\",\\n      \"confidence\": 99.62890625\\n    }\\n  ]\\n}\\n</ocr-text-confidence-results>\\n\\n<final-instructions>\\nAnalyze the extraction results against the source document and provide confidence assessments. Return a JSON object with the following structure:\\n\\n  {\\n    \"attribute_name_1\": {\\n      \"confidence_score\": 0.85,\\n      \"confidence_reason\": \"Clear text evidence found in document header with high OCR confidence (0.98). Value matches exactly.\"\\n    },\\n    \"attribute_name_2\": {\\n      \"confidence_score\": 0.65,\\n      \"confidence_reason\": \"Text is partially unclear due to poor scan quality. OCR confidence low (0.72) in this region.\"\\n    }\\n  }\\n\\nInclude assessments for ALL attributes present in the extraction results.\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 11.43s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'd182ee96-ade7-47b0-839e-c209c10771a4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:36 GMT', 'content-type': 'application/json', 'content-length': '2689', 'connection': 'keep-alive', 'x-amzn-requestid': 'd182ee96-ade7-47b0-839e-c209c10771a4'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n  \"sender_name\": {\\n    \"confidence_score\": 0.89,\\n    \"confidence_reason\": \"The sender name \\'Will E. Clark\\' is clearly stated in the document with a high OCR confidence score of 89.41. However, the handwritten signature has a lower OCR confidence of 58.11, which slightly reduces overall confidence.\"\\n  },\\n  \"sender_address\": {\\n    \"confidence_score\": 0.85,\\n    \"confidence_reason\": \"The sender address \\'206 Maple Street P. O. Box 1056 Murrey, Kentucky 42071-1056\\' is clearly stated with hig... [truncated]'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 3922, 'outputTokens': 670, 'totalTokens': 5386, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 794}, 'metrics': {'latencyMs': 11176}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 3922, 'outputTokens': 670, 'totalTokens': 5386, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 794}\n",
      "INFO:idp_common.assessment.service:Time taken for assessment: 12.30 seconds\n",
      "INFO:idp_common.assessment.service:Total assessment time for section 1: 12.97 seconds\n",
      "INFO:idp_common.assessment.service:Assessing 1 pages, class form: 2-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment for section 1 completed in 13.11 seconds\n",
      "\n",
      "Assessing section 2 (class: form)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.assessment.service:Time taken to read extraction results: 0.08 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read text content: 0.08 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read images: 0.21 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read raw OCR results: 0.08 seconds\n",
      "INFO:idp_common.assessment.service:Assessing extraction confidence for form document, section 2\n",
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert document analysis a...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 476 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 28 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document analysis assessment expert. Your task is to evaluate the confidence and accuracy of extraction results by analyzing the source document evidence. Respond only with JSON containing confidence scores and reasoning for each extracted attribute.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert document analysis assessment system. Your task is to evaluate the confidence and accuracy of extraction results for a document of class form.\\n</background>\\n\\n<task>\\nAnalyze the extraction results against the source document and provide confidence assessments for each extracted attribute. Consider factors such as:\\n1. Text clarity and OCR quality in the source regions 2. Alignment between extracted values and document content 3. Presence of clear evidence supporting the extraction 4. Potential ambiguity or uncertainty in the source material 5. Completeness and accuracy of the extracted information\\n</task>\\n\\n<assessment-guidelines>\\nFor each attribute, provide: 1. A confidence score between 0.0 and 1.0 where:\\n   - 1.0 = Very high confidence, clear and unambiguous evidence\\n   - 0.8-0.9 = High confidence, strong evidence with minor uncertainty\\n   - 0.6-0.7 = Medium confidence, reasonable evidence but some ambiguity\\n   - 0.4-0.5 = Low confidence, weak or unclear evidence\\n   - 0.0-0.3 = Very low confidence, little to no supporting evidence\\n\\n2. A clear reason explaining the confidence score, including:\\n   - What evidence supports or contradicts the extraction\\n   - Any OCR quality issues that affect confidence\\n   - Clarity of the source document in relevant areas\\n   - Any ambiguity or uncertainty factors\\n\\nGuidelines: - Base assessments on actual document content and OCR quality - Consider both text-based evidence and visual/layout clues - Account for OCR confidence scores when provided - Be objective and specific in reasoning - If an extraction appears incorrect, score accordingly with explanation\\n</assessment-guidelines>\\n<attributes-definitions>\\nform_type  \\t[ The category or purpose of the form, such as 'application', 'registration', 'request', etc. May be identified by 'form name', 'document type', or 'form category'. ]\\nform_id  \\t[ The unique identifier for the form, typically a number or alphanumeric code. Often labeled as 'form number', 'id', or 'reference number'. ]\\nsubmission_date  \\t[ The date when the form was submitted or filed. Look for text near 'date', 'submitted on', or 'filed on'. ]\\nsubmitter_name  \\t[ The name of the person who submitted the form. May be labeled as 'name', 'submitted by', or 'filed by'. ]\\nsubmitter_id  \\t[ An identification number for the person submitting the form, such as social security number, employee ID, etc. Often labeled as 'id number', 'identification', or 'reference'. ]\\napproval_status  \\t[ The current state of approval for the form, such as 'approved', 'pending', 'rejected', etc. Look for terms like 'status', 'approved', or 'pending'. ]\\nprocessed_by  \\t[ The name of the person or department that processed the form. May be indicated by 'processor', 'handled by', or 'approved by'. ]\\nprocessing_date  \\t[ The date when the form was processed or completed. Look for labels like 'processed on' or 'completion date'. ]\\ndepartment  \\t[ The organizational unit responsible for the form. Often abbreviated as 'dept' or may appear as 'department' or 'division'. ]\\ncomments  \\t[ Additional notes or remarks about the form. Look for sections labeled 'notes', 'remarks', or 'comments'. ]\\n</attributes-definitions>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<extraction-results>\\n{\\n  \"form_type\": \"LAB SERVICES CONSISTENCY REPORT\",\\n  \"form_id\": \"2030053328\",\\n  \"submission_date\": \"07/28/1993\",\\n  \"submitter_name\": \"LC\",\\n  \"submitter_id\": null,\\n  \"approval_status\": null,\\n  \"processed_by\": null,\\n  \"processing_date\": null,\\n  \"department\": null,\\n  \"comments\": null\\n}\\n</extraction-results>\\n\\n<document-image>\\n'}, {'image': '[image_data]'}, {'text': '\\n</document-image>\\n\\n<ocr-text-confidence-results>\\n\\n--- Page 2 Text Confidence Data ---\\n{\\n  \"page_count\": 1,\\n  \"text_blocks\": [\\n    {\\n      \"text\": \"LAB SERVICES CONSISTENCY REPORT\",\\n      \"confidence\": 99.98515319824219\\n    },\\n    {\\n      \"text\": \"DATE: 7/28/93\",\\n      \"confidence\": 87.74842834472656\\n    },\\n    {\\n      \"text\": \"TECHNICIAN: LC\",\\n      \"confidence\": 86.08677673339844\\n    },\\n    {\\n      \"text\": \"SHIFT: A\",\\n      \"confidence\": 99.31381225585938\\n    },\\n    {\\n      \"text\": \"Trial 8\",\\n      \"confidence\": 99.6875\\n    },\\n    {\\n      \"text\": \"LINE: 2\",\\n      \"confidence\": 99.56682586669922\\n    },\\n    {\\n      \"text\": \"AREA: 52\",\\n      \"confidence\": 99.77628326416016\\n    },\\n    {\\n      \"text\": \"SAMPLE ID: stuffbox 2\",\\n      \"confidence\": 87.08192443847656\\n    },\\n    {\\n      \"text\": \"PRODUCT UNIT CODE: 0728- ABC\",\\n      \"confidence\": 95.64971160888672\\n    },\\n    {\\n      \"text\": \"Philip Confidential Beris\",\\n      \"confidence\": 69.25442504882812\\n    },\\n    {\\n      \"text\": \"REASON FOR REQUEST: test\",\\n      \"confidence\": 98.75518035888672\\n    },\\n    {\\n      \"text\": \"REQUESTED DELIVERY TIME:\",\\n      \"confidence\": 99.75811767578125\\n    },\\n    {\\n      \"text\": \"TIME SAMPLE RECEIVED: -\",\\n      \"confidence\": 97.5489273071289\\n    },\\n    {\\n      \"text\": \"TIME ANALYSIS COMPLETED:\",\\n      \"confidence\": 99.79744720458984\\n    },\\n    {\\n      \"text\": \"DATA COMMUNICATED TO\",\\n      \"confidence\": 99.93083953857422\\n    },\\n    {\\n      \"text\": \"Gone\",\\n      \"confidence\": 67.02865600585938\\n    },\\n    {\\n      \"text\": \"AT 1105\",\\n      \"confidence\": 96.78571319580078\\n    },\\n    {\\n      \"text\": \"Person\",\\n      \"confidence\": 99.80309295654297\\n    },\\n    {\\n      \"text\": \"Time\",\\n      \"confidence\": 99.755859375\\n    },\\n    {\\n      \"text\": \"DRYING TIME\",\\n      \"confidence\": 99.95077514648438\\n    },\\n    {\\n      \"text\": \"A\",\\n      \"confidence\": 99.9609375\\n    },\\n    {\\n      \"text\": \"B\",\\n      \"confidence\": 71.7101821899414\\n    },\\n    {\\n      \"text\": \"C\",\\n      \"confidence\": 96.12384796142578\\n    },\\n    {\\n      \"text\": \"D\",\\n      \"confidence\": 99.970703125\\n    },\\n    {\\n      \"text\": \"E\",\\n      \"confidence\": 99.37519836425781\\n    },\\n    {\\n      \"text\": \"IN:\",\\n      \"confidence\": 99.88201141357422\\n    },\\n    {\\n      \"text\": \"OUT:\",\\n      \"confidence\": 99.72098541259766\\n    },\\n    {\\n      \"text\": \"SAMPLE A\",\\n      \"confidence\": 79.62183380126953\\n    },\\n    {\\n      \"text\": \"CONTAINER\",\\n      \"confidence\": 99.12308502197266\\n    },\\n    {\\n      \"text\": \"SAMPLE\",\\n      \"confidence\": 99.1954345703125\\n    },\\n    {\\n      \"text\": \"DILUTION\",\\n      \"confidence\": 98.92378997802734\\n    },\\n    {\\n      \"text\": \"DEUTED\",\\n      \"confidence\": 77.2303466796875\\n    },\\n    {\\n      \"text\": \"CONTAINER\",\\n      \"confidence\": 99.68112182617188\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.7168960571289\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.24784851074219\\n    },\\n    {\\n      \"text\": \"FACTOR\",\\n      \"confidence\": 99.95037078857422\\n    },\\n    {\\n      \"text\": \"SAMPLE\",\\n      \"confidence\": 99.43219757080078\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.82711029052734\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 97.85813903808594\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 98.87416076660156\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 91.13919067382812\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 99.51191711425781\\n    },\\n    {\\n      \"text\": \"(A-B)\",\\n      \"confidence\": 76.45555877685547\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 88.69041442871094\\n    },\\n    {\\n      \"text\": \"F\",\\n      \"confidence\": 99.72417449951172\\n    },\\n    {\\n      \"text\": \"G\",\\n      \"confidence\": 99.76243591308594\\n    },\\n    {\\n      \"text\": \"H\",\\n      \"confidence\": 99.80229949951172\\n    },\\n    {\\n      \"text\": \"I\",\\n      \"confidence\": 96.7235336303711\\n    },\\n    {\\n      \"text\": \"FILTER\",\\n      \"confidence\": 99.7217788696289\\n    },\\n    {\\n      \"text\": \"SAMPLE\",\\n      \"confidence\": 99.55257415771484\\n    },\\n    {\\n      \"text\": \"SAMPLE &\",\\n      \"confidence\": 98.78288269042969\\n    },\\n    {\\n      \"text\": \"% CONSISTENCY\",\\n      \"confidence\": 99.07276916503906\\n    },\\n    {\\n      \"text\": \"1159.3\",\\n      \"confidence\": 99.5224838256836\\n    },\\n    {\\n      \"text\": \"6\",\\n      \"confidence\": 99.93083953857422\\n    },\\n    {\\n      \"text\": \"6955.8\",\\n      \"confidence\": 98.60890197753906\\n    },\\n    {\\n      \"text\": \"PAPER\",\\n      \"confidence\": 99.51271057128906\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.2942886352539\\n    },\\n    {\\n      \"text\": \"PAPER\",\\n      \"confidence\": 98.84407043457031\\n    },\\n    {\\n      \"text\": \"H-P\",\\n      \"confidence\": 46.09871292114258\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.23080444335938\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 91.85885620117188\\n    },\\n    {\\n      \"text\": \"WEIGHT IN\",\\n      \"confidence\": 99.62821197509766\\n    },\\n    {\\n      \"text\": \"0 x D x 100\",\\n      \"confidence\": 77.9284896850586\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 84.21556091308594\\n    },\\n    {\\n      \"text\": \"GRAMS\",\\n      \"confidence\": 97.23991394042969\\n    },\\n    {\\n      \"text\": \"WET\",\\n      \"confidence\": 99.63229370117188\\n    },\\n    {\\n      \"text\": \"DRY\",\\n      \"confidence\": 99.990234375\\n    },\\n    {\\n      \"text\": \"CONSISTENCY\",\\n      \"confidence\": 99.9609375\\n    },\\n    {\\n      \"text\": \"SAMPLE # 10\",\\n      \"confidence\": 74.76761627197266\\n    },\\n    {\\n      \"text\": \"2853\",\\n      \"confidence\": 60.141902923583984\\n    },\\n    {\\n      \"text\": \"84568\",\\n      \"confidence\": 66.0927505493164\\n    },\\n    {\\n      \"text\": \"3.366\",\\n      \"confidence\": 85.69754028320312\\n    },\\n    {\\n      \"text\": \"3.64\",\\n      \"confidence\": 98.439697265625\\n    },\\n    {\\n      \"text\": \"AVERAGE: 3.68\",\\n      \"confidence\": 97.50428009033203\\n    },\\n    {\\n      \"text\": \"SAMPLE #711\",\\n      \"confidence\": 76.51227569580078\\n    },\\n    {\\n      \"text\": \"2.645\",\\n      \"confidence\": 91.78152465820312\\n    },\\n    {\\n      \"text\": \"79.235\",\\n      \"confidence\": 94.26478576660156\\n    },\\n    {\\n      \"text\": \"3123\",\\n      \"confidence\": 64.53105163574219\\n    },\\n    {\\n      \"text\": \"3.62\",\\n      \"confidence\": 96.78013610839844\\n    },\\n    {\\n      \"text\": \"RANGE: 15\",\\n      \"confidence\": 96.2978286743164\\n    },\\n    {\\n      \"text\": \"SAMPLE #$ 12\",\\n      \"confidence\": 64.28671264648438\\n    },\\n    {\\n      \"text\": \"2.847\",\\n      \"confidence\": 79.80169677734375\\n    },\\n    {\\n      \"text\": \"89.776\",\\n      \"confidence\": 96.50929260253906\\n    },\\n    {\\n      \"text\": \"3.411\",\\n      \"confidence\": 93.58497619628906\\n    },\\n    {\\n      \"text\": \"3.77\",\\n      \"confidence\": 81.73688507080078\\n    },\\n    {\\n      \"text\": \"METER READING:\",\\n      \"confidence\": 97.74951934814453\\n    },\\n    {\\n      \"text\": \"COMMENTS:\",\\n      \"confidence\": 98.80421447753906\\n    },\\n    {\\n      \"text\": \"ACONSIST WID\",\\n      \"confidence\": 24.416654586791992\\n    },\\n    {\\n      \"text\": \"2030053328\",\\n      \"confidence\": 99.453125\\n    }\\n  ]\\n}\\n</ocr-text-confidence-results>\\n\\n<final-instructions>\\nAnalyze the extraction results against the source document and provide confidence assessments. Return a JSON object with the following structure:\\n\\n  {\\n    \"attribute_name_1\": {\\n      \"confidence_score\": 0.85,\\n      \"confidence_reason\": \"Clear text evidence found in document header with high OCR confidence (0.98). Value matches exactly.\"\\n    },\\n    \"attribute_name_2\": {\\n      \"confidence_score\": 0.65,\\n      \"confidence_reason\": \"Text is partially unclear due to poor scan quality. OCR confidence low (0.72) in this region.\"\\n    }\\n  }\\n\\nInclude assessments for ALL attributes present in the extraction results.\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 8.97s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'ae179599-e689-4a32-8048-8b9488d53d12', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:46:47 GMT', 'content-type': 'application/json', 'content-length': '2390', 'connection': 'keep-alive', 'x-amzn-requestid': 'ae179599-e689-4a32-8048-8b9488d53d12'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n  \"form_type\": {\\n    \"confidence_score\": 1.0,\\n    \"confidence_reason\": \"The form type \\'LAB SERVICES CONSISTENCY REPORT\\' is clearly stated at the top of the document with very high OCR confidence (99.98515319824219).\"\\n  },\\n  \"form_id\": {\\n    \"confidence_score\": 1.0,\\n    \"confidence_reason\": \"The form ID \\'2030053328\\' is clearly visible at the bottom of the document with very high OCR confidence (99.453125).\"\\n  },\\n  \"submission_date\": {\\n    \"confidence_score\": 0.88,\\n    \"confidence_reason... [truncated]'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 5121, 'outputTokens': 571, 'totalTokens': 6478, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 786}, 'metrics': {'latencyMs': 8759}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 5121, 'outputTokens': 571, 'totalTokens': 6478, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 786}\n",
      "INFO:idp_common.assessment.service:Time taken for assessment: 10.04 seconds\n",
      "INFO:idp_common.assessment.service:Total assessment time for section 2: 10.82 seconds\n",
      "INFO:idp_common.assessment.service:Assessing 2 pages, class email: 3-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment for section 2 completed in 10.96 seconds\n",
      "\n",
      "Assessing section 3 (class: email)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.assessment.service:Time taken to read extraction results: 0.08 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read text content: 0.16 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read images: 0.39 seconds\n",
      "INFO:idp_common.assessment.service:Time taken to read raw OCR results: 0.17 seconds\n",
      "INFO:idp_common.assessment.service:Assessing extraction confidence for email document, section 3\n",
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: <background>\n",
      "You are an expert document analysis a...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 454 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 36 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Applied cachePoint processing for supported model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/7:\n",
      "INFO:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "INFO:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1, 'maxTokens': 4096}\n",
      "INFO:idp_common.bedrock.client:  - system: [{'text': 'You are a document analysis assessment expert. Your task is to evaluate the confidence and accuracy of extraction results by analyzing the source document evidence. Respond only with JSON containing confidence scores and reasoning for each extracted attribute.'}]\n",
      "INFO:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"<background>\\nYou are an expert document analysis assessment system. Your task is to evaluate the confidence and accuracy of extraction results for a document of class email.\\n</background>\\n\\n<task>\\nAnalyze the extraction results against the source document and provide confidence assessments for each extracted attribute. Consider factors such as:\\n1. Text clarity and OCR quality in the source regions 2. Alignment between extracted values and document content 3. Presence of clear evidence supporting the extraction 4. Potential ambiguity or uncertainty in the source material 5. Completeness and accuracy of the extracted information\\n</task>\\n\\n<assessment-guidelines>\\nFor each attribute, provide: 1. A confidence score between 0.0 and 1.0 where:\\n   - 1.0 = Very high confidence, clear and unambiguous evidence\\n   - 0.8-0.9 = High confidence, strong evidence with minor uncertainty\\n   - 0.6-0.7 = Medium confidence, reasonable evidence but some ambiguity\\n   - 0.4-0.5 = Low confidence, weak or unclear evidence\\n   - 0.0-0.3 = Very low confidence, little to no supporting evidence\\n\\n2. A clear reason explaining the confidence score, including:\\n   - What evidence supports or contradicts the extraction\\n   - Any OCR quality issues that affect confidence\\n   - Clarity of the source document in relevant areas\\n   - Any ambiguity or uncertainty factors\\n\\nGuidelines: - Base assessments on actual document content and OCR quality - Consider both text-based evidence and visual/layout clues - Account for OCR confidence scores when provided - Be objective and specific in reasoning - If an extraction appears incorrect, score accordingly with explanation\\n</assessment-guidelines>\\n<attributes-definitions>\\nfrom_address  \\t[ The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header. ]\\nto_address  \\t[ The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'. ]\\ncc_address  \\t[ Email addresses of additional recipients who receive copies. Look for 'cc' or 'carbon copy' followed by one or more email addresses. ]\\nbcc_address  \\t[ Email addresses of hidden recipients. May be labeled as 'bcc' or 'blind copy'. ]\\nsubject  \\t[ The topic of the email. Often preceded by 'subject', 'RE:', or 'regarding'. ]\\ndate_sent  \\t[ The date and time when the email was sent. Look for 'date', 'sent on', or 'received', typically in the email header. ]\\nattachments  \\t[ Files included with the email. May be indicated by 'attached', 'attachment', or 'enclosed', often with icons or file names. ]\\npriority  \\t[ The urgency level of the email, such as 'high', 'normal', etc. Look for 'priority' or 'importance'. ]\\nthread_id  \\t[ An identifier for the email conversation. May be labeled as 'thread' or 'conversation', typically not visible to regular users. ]\\nmessage_id  \\t[ A unique identifier for the specific email. Look for 'message id' or 'email id', usually hidden in the email metadata. ]\\n</attributes-definitions>\\n\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '\\n\\n<extraction-results>\\n{\\n  \"from_address\": \"Kelahan, Ben\",\\n  \"to_address\": \"\\'TI New York\\'; \\'TI Minnesota\\'\",\\n  \"cc_address\": \"Ashley Bratich (MSMAIL)\",\\n  \"bcc_address\": null,\\n  \"subject\": \"FW: Morning Team Notes 4/20\",\\n  \"date_sent\": \"04/18/1998\",\\n  \"attachments\": null,\\n  \"priority\": null,\\n  \"thread_id\": null,\\n  \"message_id\": null\\n}\\n</extraction-results>\\n\\n<document-image>\\n'}, {'image': '[image_data]'}, {'image': '[image_data]'}, {'text': '\\n</document-image>\\n\\n<ocr-text-confidence-results>\\n\\n--- Page 3 Text Confidence Data ---\\n{\\n  \"page_count\": 1,\\n  \"text_blocks\": [\\n    {\\n      \"text\": \"Ashley Bratich\",\\n      \"confidence\": 99.82830047607422\\n    },\\n    {\\n      \"text\": \"From:\",\\n      \"confidence\": 99.89098358154297\\n    },\\n    {\\n      \"text\": \"Kelahan, Ben\",\\n      \"confidence\": 95.22291564941406\\n    },\\n    {\\n      \"text\": \"To:\",\\n      \"confidence\": 99.89098358154297\\n    },\\n    {\\n      \"text\": \"TI New York\\'; \\\\\"TI Minnesota\\'\",\\n      \"confidence\": 64.51510620117188\\n    },\\n    {\\n      \"text\": \"Ce:\",\\n      \"confidence\": 69.09976959228516\\n    },\\n    {\\n      \"text\": \"Ashley Bratich (MSMAIL)\",\\n      \"confidence\": 99.0284194946289\\n    },\\n    {\\n      \"text\": \"Subject:\",\\n      \"confidence\": 99.69168090820312\\n    },\\n    {\\n      \"text\": \"FW: Morning Team Notes 4/20\",\\n      \"confidence\": 99.73672485351562\\n    },\\n    {\\n      \"text\": \"Date:\",\\n      \"confidence\": 99.89098358154297\\n    },\\n    {\\n      \"text\": \"Saturday, April 18, 1998 2:09PM\",\\n      \"confidence\": 89.88711547851562\\n    },\\n    {\\n      \"text\": \"Original Message\",\\n      \"confidence\": 98.46649932861328\\n    },\\n    {\\n      \"text\": \"From:\",\\n      \"confidence\": 99.81126403808594\\n    },\\n    {\\n      \"text\": \"Byron Nelson [SMTP:bnelson@wka.com]\",\\n      \"confidence\": 79.68218231201172\\n    },\\n    {\\n      \"text\": \"Sent:\",\\n      \"confidence\": 98.77490997314453\\n    },\\n    {\\n      \"text\": \"Friday, April 17. 1998 5:25 PM\",\\n      \"confidence\": 92.85880279541016\\n    },\\n    {\\n      \"text\": \"To:\",\\n      \"confidence\": 99.88121795654297\\n    },\\n    {\\n      \"text\": \"Judy Albert: Carolyn: Jackie Cohen (AWMA): Frank: Goody; Henry; Hollant; Chris Holt; Hurst: Jim:\",\\n      \"confidence\": 82.82488250732422\\n    },\\n    {\\n      \"text\": \"Joe; John; Benjamin Kelahan; Cheryl Klein: Walt Klein; Lbeckwith; Rob Meyne; Mkatz; Morrow; Powers;\",\\n      \"confidence\": 87.07151794433594\\n    },\\n    {\\n      \"text\": \"Randy; Roger; Ron; Shorep; Steve Strawsburg: Suggsm; Matthew Tilley; whitey\",\\n      \"confidence\": 83.4385986328125\\n    },\\n    {\\n      \"text\": \"Co:\",\\n      \"confidence\": 91.0632553100586\\n    },\\n    {\\n      \"text\": \"Bob Fackler; Bob Stone\",\\n      \"confidence\": 90.26586151123047\\n    },\\n    {\\n      \"text\": \"Subject:\",\\n      \"confidence\": 94.68968963623047\\n    },\\n    {\\n      \"text\": \"Morning Team Notes 4/20\",\\n      \"confidence\": 99.7766342163086\\n    },\\n    {\\n      \"text\": \"Falmouth, MA - On 4/15, town meeting representatives defeated by a 84-77\",\\n      \"confidence\": 95.59353637695312\\n    },\\n    {\\n      \"text\": \"vote a warrent article calling for a 100 percent ban on smoking in\",\\n      \"confidence\": 93.2069091796875\\n    },\\n    {\\n      \"text\": \"restaurants. On 4/16, a motion to reconsider the vote was soundly rejected\",\\n      \"confidence\": 97.59335327148438\\n    },\\n    {\\n      \"text\": \"1612\",\\n      \"confidence\": 25.467754364013672\\n    },\\n    {\\n      \"text\": \"104-49. The restaurant owner\\'s moderate alternative was not considered\",\\n      \"confidence\": 98.82974243164062\\n    },\\n    {\\n      \"text\": \"because the town counsel found the article to be unconstitutional.\",\\n      \"confidence\": 96.66444396972656\\n    },\\n    {\\n      \"text\": \"Waseca County, MN On 4/7, the county commissioners once again tabled\",\\n      \"confidence\": 94.14662170410156\\n    },\\n    {\\n      \"text\": \"consideration of a new tobacco retailing ordinance. Waseca is the 11th\",\\n      \"confidence\": 96.53196716308594\\n    },\\n    {\\n      \"text\": \"Minnesota community to put the issue on hold.\",\\n      \"confidence\": 99.75379180908203\\n    },\\n    {\\n      \"text\": \"Wadena County, MN - In mid-March, the county commissioners tabled\",\\n      \"confidence\": 94.34452819824219\\n    },\\n    {\\n      \"text\": \"consideration of a new tobacco retailing ordinance until 4/23. At that time,\",\\n      \"confidence\": 97.7909927368164\\n    },\\n    {\\n      \"text\": \"they will take up a model ordinance that mirrors the state law. Bob Fackler\",\\n      \"confidence\": 98.6639404296875\\n    },\\n    {\\n      \"text\": \"requests calls to retailers to alert them to attend.\",\\n      \"confidence\": 98.02072143554688\\n    },\\n    {\\n      \"text\": \"Page 1\",\\n      \"confidence\": 97.56776428222656\\n    },\\n    {\\n      \"text\": \"TI1716-0284\",\\n      \"confidence\": 90.76470947265625\\n    }\\n  ]\\n}\\n--- Page 4 Text Confidence Data ---\\n{\\n  \"page_count\": 1,\\n  \"text_blocks\": [\\n    {\\n      \"text\": \"LE CHOIHGPAT Mulation assay- Alyodal 401F Book No. 354\",\\n      \"confidence\": 71.34282684326172\\n    },\\n    {\\n      \"text\": \"in Page No. 85,08.343\",\\n      \"confidence\": 72.09856414794922\\n    },\\n    {\\n      \"text\": \"I lyectives To measure the ability of a test substance to induse matation\",\\n      \"confidence\": 84.44722747802734\\n    },\\n    {\\n      \"text\": \"at the hypoxamhine gurnine phosphoubaryl transferase (haprt) loan\",\\n      \"confidence\": 51.9123420715332\\n    },\\n    {\\n      \"text\": \"in Chinese Hamster Overy (CHO) cells on de basis that the presemption\",\\n      \"confidence\": 83.8499526977539\\n    },\\n    {\\n      \"text\": \"mutants. by visture of the loss of the HGPRT activity are unabe\",\\n      \"confidence\": 86.83946990966797\\n    },\\n    {\\n      \"text\": \"to convert purine analogs, such as G. throgramine (6-ta) to\",\\n      \"confidence\": 76.54441833496094\\n    },\\n    {\\n      \"text\": \"toxic metabolities and hence escape their lethal effects, which\",\\n      \"confidence\": 86.0899658203125\\n    },\\n    {\\n      \"text\": \"is liowever, excountered by the wild type cells.\",\\n      \"confidence\": 83.00936889648438\\n    },\\n    {\\n      \"text\": \"Nativials and Methods: Refer to Standard Operating Procedure PH314\",\\n      \"confidence\": 79.037109375\\n    },\\n    {\\n      \"text\": \"Spensor: american Cyanamid Company\",\\n      \"confidence\": 67.2572021484375\\n    },\\n    {\\n      \"text\": \"Test Citicle Glyoxal 40 LF\",\\n      \"confidence\": 67.31640625\\n    },\\n    {\\n      \"text\": \"Description clear liquid\",\\n      \"confidence\": 84.14288330078125\\n    },\\n    {\\n      \"text\": \"Date Preliminary Cytolopicity Instrated 6/3/82\",\\n      \"confidence\": 78.83840942382812\\n    },\\n    {\\n      \"text\": \"Date CHOIHGART Forward Gene Mentation Assay Instrated 8/26/52\",\\n      \"confidence\": 56.635101318359375\\n    },\\n    {\\n      \"text\": \"CHO-KI-BH4 Joy\\\\\" 7182 received from Oak Ridge national Toboratoris 7/1/2\",\\n      \"confidence\": 74.12544250488281\\n    },\\n    {\\n      \"text\": \"Routine subcuttines were done every Friday (a.m.) and Monday (p.m.),\",\\n      \"confidence\": 86.4303207397461\\n    },\\n    {\\n      \"text\": \"where 1x105 cells were subcultived into each of 3- 75cm2 flasts\",\\n      \"confidence\": 80.13819122314453\\n    },\\n    {\\n      \"text\": \"containing is ml of media FizFesio. CHO-KI-BHY aminoption\",\\n      \"confidence\": 67.93151092529297\\n    },\\n    {\\n      \"text\": \"treated 7/23/82. Routine subcutture regime camed out.\",\\n      \"confidence\": 76.1401596069336\\n    },\\n    {\\n      \"text\": \"8/23/82- CHO-KI-BHY cells (Lot # 7182) subcuttured into 10-T75cm2\",\\n      \"confidence\": 66.65303802490234\\n    },\\n    {\\n      \"text\": \"flasks (3x10\\' cells/flook) in 15ml lif media Fizesio.\",\\n      \"confidence\": 57.306514739990234\\n    },\\n    {\\n      \"text\": \"5/23/82\",\\n      \"confidence\": 80.59709930419922\\n    },\\n    {\\n      \"text\": \"8/25/82- CHO-KI-BH4 cells (J.V*7182) subcultared into 36- T25cm2\",\\n      \"confidence\": 71.19867706298828\\n    },\\n    {\\n      \"text\": \"flasks (5x105 cells (flask) in 5ml of media F12 FCM5, in\",\\n      \"confidence\": 76.68033599853516\\n    },\\n    {\\n      \"text\": \"preparation for treatment (7/21/82) FetalBonne Socurity KC.321005\",\\n      \"confidence\": 41.64452362060547\\n    },\\n    {\\n      \"text\": \"79793 9427\",\\n      \"confidence\": 52.980506896972656\\n    },\\n    {\\n      \"text\": \"To Page No.6\",\\n      \"confidence\": 86.21060180664062\\n    },\\n    {\\n      \"text\": \"(tnessed & Understood by me,\",\\n      \"confidence\": 89.44084930419922\\n    },\\n    {\\n      \"text\": \"Date\",\\n      \"confidence\": 99.55895233154297\\n    },\\n    {\\n      \"text\": \"Invented by\",\\n      \"confidence\": 98.81895446777344\\n    },\\n    {\\n      \"text\": \"Date\",\\n      \"confidence\": 99.6875\\n    },\\n    {\\n      \"text\": \"and mech\",\\n      \"confidence\": 29.7672176361084\\n    },\\n    {\\n      \"text\": \"8/25/82\",\\n      \"confidence\": 91.4317626953125\\n    },\\n    {\\n      \"text\": \"Recorded by Idmand D. Dodek\",\\n      \"confidence\": 62.3402099609375\\n    },\\n    {\\n      \"text\": \"8/25/82\",\\n      \"confidence\": 96.90310668945312\\n    }\\n  ]\\n}\\n</ocr-text-confidence-results>\\n\\n<final-instructions>\\nAnalyze the extraction results against the source document and provide confidence assessments. Return a JSON object with the following structure:\\n\\n  {\\n    \"attribute_name_1\": {\\n      \"confidence_score\": 0.85,\\n      \"confidence_reason\": \"Clear text evidence found in document header with high OCR confidence (0.98). Value matches exactly.\"\\n    },\\n    \"attribute_name_2\": {\\n      \"confidence_score\": 0.65,\\n      \"confidence_reason\": \"Text is partially unclear due to poor scan quality. OCR confidence low (0.72) in this region.\"\\n    }\\n  }\\n\\nInclude assessments for ALL attributes present in the extraction results.\\n</final-instructions>'}]}]\n",
      "INFO:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 21.06s\n",
      "DEBUG:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '4ed32b19-5a8d-41d1-8af8-caa641f9453c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 09 Jul 2025 13:47:10 GMT', 'content-type': 'application/json', 'content-length': '2467', 'connection': 'keep-alive', 'x-amzn-requestid': '4ed32b19-5a8d-41d1-8af8-caa641f9453c'}, 'RetryAttempts': 4}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n  \"from_address\": {\\n    \"confidence_score\": 0.95,\\n    \"confidence_reason\": \"The \\'from\\' address \\'Kelahan, Ben\\' is clearly indicated in the document with a high OCR confidence score of 95.22%.\"\\n  },\\n  \"to_address\": {\\n    \"confidence_score\": 0.65,\\n    \"confidence_reason\": \"The \\'to\\' addresses \\'TI New York\\'; \\'TI Minnesota\\' are indicated, but the OCR confidence is lower at 64.52%, suggesting some ambiguity or potential error in extraction.\"\\n  },\\n  \"cc_address\": {\\n    \"confidence_score\": 0.99... [truncated]'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 6988, 'outputTokens': 570, 'totalTokens': 8292, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 734}, 'metrics': {'latencyMs': 8014}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 6988, 'outputTokens': 570, 'totalTokens': 8292, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 734}\n",
      "INFO:idp_common.assessment.service:Time taken for assessment: 22.14 seconds\n",
      "INFO:idp_common.assessment.service:Total assessment time for section 3: 23.25 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment for section 3 completed in 23.39 seconds\n",
      "\n",
      "Assessment for first 3 sections complete.\n"
     ]
    }
   ],
   "source": [
    "# Create assessment service with Bedrock\n",
    "assessment_service = assessment.AssessmentService(config=CONFIG)\n",
    "\n",
    "print(\"\\nAssessing extraction confidence for document sections...\")\n",
    "\n",
    "# Process each section that has extraction results\n",
    "for section in document.sections[:n]:  \n",
    "    if section.extraction_result_uri:\n",
    "        print(f\"\\nAssessing section {section.section_id} (class: {section.classification})\")\n",
    "        \n",
    "        # Assess the section\n",
    "        start_time = time.time()\n",
    "        document = assessment_service.process_document_section(\n",
    "            document=document,\n",
    "            section_id=section.section_id\n",
    "        )\n",
    "        assessment_time = time.time() - start_time\n",
    "        print(f\"Assessment for section {section.section_id} completed in {assessment_time:.2f} seconds\")\n",
    "    else:\n",
    "        print(f\"\\nSkipping section {section.section_id} - no extraction results to assess\")\n",
    "        \n",
    "print(f\"\\nAssessment for first {n} sections complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Display Assessment Results\n",
    "\n",
    "Let's examine the assessment results that have been added to the extraction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assessment Results:\n",
      "===================\n",
      "\n",
      "Section 1 (letter):\n",
      "  Extraction Results:\n",
      "    sender_name: Will E. Clark\n",
      "    sender_address: 206 Maple Street P. O. Box 1056 Murrey, Kentucky 42071-1056\n",
      "    recipient_name: The Honorable Wendell H. Ford\n",
      "    recipient_address: United States Senate Washington, D. C. 20510\n",
      "    date: 10/11/1995\n",
      "    subject: Opposition to the 'Commitment to Our Children' petition\n",
      "    letter_type: Complaint\n",
      "    signature: Will E. Clark\n",
      "    cc: None\n",
      "    reference_number: TNJB 0008497\n",
      "  Assessment Results:\n",
      "    sender_name:\n",
      "      Confidence Score: 0.89\n",
      "      Reason: The sender name 'Will E. Clark' is clearly stated in the document with a high OCR confidence score of 89.41. However, the handwritten signature has a lower OCR confidence of 58.11, which slightly reduces overall confidence.\n",
      "    sender_address:\n",
      "      Confidence Score: 0.85\n",
      "      Reason: The sender address '206 Maple Street P. O. Box 1056 Murrey, Kentucky 42071-1056' is clearly stated with high OCR confidence scores for most parts, except for 'Murrey, Kennucky 42071-1056' which has a lower score of 66.10.\n",
      "    recipient_name:\n",
      "      Confidence Score: 0.91\n",
      "      Reason: The recipient name 'The Honorable Wendell H. Ford' is clearly stated with a high OCR confidence score of 90.80.\n",
      "    recipient_address:\n",
      "      Confidence Score: 0.83\n",
      "      Reason: The recipient address 'United States Senate Washington, D. C. 20510' is clearly stated with high OCR confidence scores, though 'Washington, D. c. 20510' has a slightly lower score of 82.39.\n",
      "    date:\n",
      "      Confidence Score: 0.98\n",
      "      Reason: The date 'October 11, 1995' is clearly stated with a very high OCR confidence score of 97.94.\n",
      "    subject:\n",
      "      Confidence Score: 0.91\n",
      "      Reason: The subject 'Opposition to the 'Commitment to Our Children' petition' is clearly stated with high OCR confidence scores.\n",
      "    letter_type:\n",
      "      Confidence Score: 0.85\n",
      "      Reason: The letter type 'Complaint' is inferred from the content, which expresses strong opposition to a petition. The content is clear, but the attribute is not explicitly labeled, hence a slightly lower confidence score.\n",
      "    signature:\n",
      "      Confidence Score: 0.89\n",
      "      Reason: The signature 'Will E. Clark' is clearly stated with a high OCR confidence score of 89.41.\n",
      "    cc:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No 'cc' field is present in the document, hence the confidence score is 0.\n",
      "    reference_number:\n",
      "      Confidence Score: 0.99\n",
      "      Reason: The reference number 'TNJB 0008497' is clearly stated with a very high OCR confidence score of 99.63.\n",
      "\n",
      "Section 2 (form):\n",
      "  Extraction Results:\n",
      "    form_type: LAB SERVICES CONSISTENCY REPORT\n",
      "    form_id: 2030053328\n",
      "    submission_date: 07/28/1993\n",
      "    submitter_name: LC\n",
      "    submitter_id: None\n",
      "    approval_status: None\n",
      "    processed_by: None\n",
      "    processing_date: None\n",
      "    department: None\n",
      "    comments: None\n",
      "  Assessment Results:\n",
      "    form_type:\n",
      "      Confidence Score: 1.0\n",
      "      Reason: The form type 'LAB SERVICES CONSISTENCY REPORT' is clearly stated at the top of the document with very high OCR confidence (99.98515319824219).\n",
      "    form_id:\n",
      "      Confidence Score: 1.0\n",
      "      Reason: The form ID '2030053328' is clearly visible at the bottom of the document with very high OCR confidence (99.453125).\n",
      "    submission_date:\n",
      "      Confidence Score: 0.88\n",
      "      Reason: The submission date '07/28/93' is present in the document with a high OCR confidence (87.74842834472656). The format matches the extracted value, though the year is abbreviated.\n",
      "    submitter_name:\n",
      "      Confidence Score: 0.86\n",
      "      Reason: The submitter name 'LC' is indicated under 'TECHNICIAN:' with a high OCR confidence (86.08677673339844). The initials match the extracted value.\n",
      "    submitter_id:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No submitter ID is provided in the document, hence the extraction result is null.\n",
      "    approval_status:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: There is no indication of approval status in the document, hence the extraction result is null.\n",
      "    processed_by:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: There is no information about who processed the form in the document, hence the extraction result is null.\n",
      "    processing_date:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: There is no processing date indicated in the document, hence the extraction result is null.\n",
      "    department:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: There is no department information provided in the document, hence the extraction result is null.\n",
      "    comments:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: The comments section is blank in the document, hence the extraction result is null.\n",
      "\n",
      "Section 3 (email):\n",
      "  Extraction Results:\n",
      "    from_address: Kelahan, Ben\n",
      "    to_address: 'TI New York'; 'TI Minnesota'\n",
      "    cc_address: Ashley Bratich (MSMAIL)\n",
      "    bcc_address: None\n",
      "    subject: FW: Morning Team Notes 4/20\n",
      "    date_sent: 04/18/1998\n",
      "    attachments: None\n",
      "    priority: None\n",
      "    thread_id: None\n",
      "    message_id: None\n",
      "  Assessment Results:\n",
      "    from_address:\n",
      "      Confidence Score: 0.95\n",
      "      Reason: The 'from' address 'Kelahan, Ben' is clearly indicated in the document with a high OCR confidence score of 95.22%.\n",
      "    to_address:\n",
      "      Confidence Score: 0.65\n",
      "      Reason: The 'to' addresses 'TI New York'; 'TI Minnesota' are indicated, but the OCR confidence is lower at 64.52%, suggesting some ambiguity or potential error in extraction.\n",
      "    cc_address:\n",
      "      Confidence Score: 0.99\n",
      "      Reason: The 'cc' address 'Ashley Bratich (MSMAIL)' is clearly indicated with a very high OCR confidence score of 99.03%.\n",
      "    bcc_address:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No 'bcc' address is indicated in the document, and the extraction result is null, which aligns with the document content.\n",
      "    subject:\n",
      "      Confidence Score: 0.99\n",
      "      Reason: The subject 'FW: Morning Team Notes 4/20' is clearly indicated with a very high OCR confidence score of 99.74%.\n",
      "    date_sent:\n",
      "      Confidence Score: 0.9\n",
      "      Reason: The date '04/18/1998' is indicated with a high OCR confidence score of 89.89%. The format is slightly different but the date matches.\n",
      "    attachments:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No attachments are indicated in the document, and the extraction result is null, which aligns with the document content.\n",
      "    priority:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No priority is indicated in the document, and the extraction result is null, which aligns with the document content.\n",
      "    thread_id:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No thread ID is indicated in the document, and the extraction result is null, which aligns with the document content.\n",
      "    message_id:\n",
      "      Confidence Score: 0.0\n",
      "      Reason: No message ID is indicated in the document, and the extraction result is null, which aligns with the document content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAssessment Results:\")\n",
    "print(\"===================\\n\")\n",
    "\n",
    "for section in document.sections[:n]:\n",
    "    if section.extraction_result_uri:\n",
    "        print(f\"Section {section.section_id} ({section.classification}):\")\n",
    "        \n",
    "        # Load the updated extraction results with assessment\n",
    "        extraction_data = load_json_from_s3(section.extraction_result_uri)\n",
    "        \n",
    "        # Display the inference results\n",
    "        print(f\"  Extraction Results:\")\n",
    "        inference_result = extraction_data.get('inference_result', {})\n",
    "        for attr_name, attr_value in inference_result.items():\n",
    "            print(f\"    {attr_name}: {attr_value}\")\n",
    "        \n",
    "        # Display the assessment results\n",
    "        explainability_info = extraction_data.get('explainability_info', [])\n",
    "        if explainability_info:\n",
    "            print(f\"  Assessment Results:\")\n",
    "            for attr_name, assessment in explainability_info[0].items():\n",
    "                confidence_score = assessment.get('confidence_score', 'N/A')\n",
    "                confidence_reason = assessment.get('confidence_reason', 'N/A')\n",
    "                print(f\"    {attr_name}:\")\n",
    "                print(f\"      Confidence Score: {confidence_score}\")\n",
    "                print(f\"      Reason: {confidence_reason}\")\n",
    "        else:\n",
    "            print(f\"  No assessment results found\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Document Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Document State:\n",
      "Document ID: rvl-cdip-package-assessment\n",
      "Status: COMPLETED\n",
      "Number of pages: 10\n",
      "Number of sections: 8\n",
      "\n",
      "=== Assessment Feature Summary ===\n",
      "✅ OCR Processing - Convert PDF to text and images\n",
      "✅ Document Classification - Identify document types\n",
      "✅ Information Extraction - Extract structured data\n",
      "✅ Assessment - Evaluate extraction confidence\n",
      "\n",
      "The assessment feature provides:\n",
      "- Confidence scores (0.0 to 1.0) for each extracted attribute\n",
      "- Detailed reasoning explaining the confidence level\n",
      "- Analysis of OCR quality and document clarity\n",
      "- Identification of ambiguous or uncertain extractions\n",
      "- Integration with existing extraction results\n"
     ]
    }
   ],
   "source": [
    "# Update document status to COMPLETED\n",
    "document.status = Status.COMPLETED\n",
    "\n",
    "# Display final document state\n",
    "print(\"Final Document State:\")\n",
    "print(f\"Document ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "print(f\"Number of sections: {len(document.sections)}\")\n",
    "\n",
    "print(\"\\n=== Assessment Feature Summary ===\")\n",
    "print(\"✅ OCR Processing - Convert PDF to text and images\")\n",
    "print(\"✅ Document Classification - Identify document types\")\n",
    "print(\"✅ Information Extraction - Extract structured data\")\n",
    "print(\"✅ Assessment - Evaluate extraction confidence\")\n",
    "print(\"\\nThe assessment feature provides:\")\n",
    "print(\"- Confidence scores (0.0 to 1.0) for each extracted attribute\")\n",
    "print(\"- Detailed reasoning explaining the confidence level\")\n",
    "print(\"- Analysis of OCR quality and document clarity\")\n",
    "print(\"- Identification of ambiguous or uncertain extractions\")\n",
    "print(\"- Integration with existing extraction results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the enhanced end-to-end processing flow with the new **Assessment Service**:\n",
    "\n",
    "1. **Document Creation** - Initialize a Document object with input/output locations\n",
    "2. **OCR Processing** - Convert PDF to text using AWS Textract via OcrService\n",
    "3. **Classification** - Identify document types and sections using Bedrock via ClassificationService\n",
    "4. **Extraction** - Extract structured information using Bedrock via ExtractionService\n",
    "5. **Assessment** - Evaluate extraction confidence using Bedrock via AssessmentService ✨ **NEW**\n",
    "6. **Document Model** - Document object is consistently used between all services\n",
    "7. **Result Storage** - Assessment results are stored alongside extraction results in S3\n",
    "\n",
    "### Key Benefits of the Assessment Service:\n",
    "\n",
    "1. **Explainability** - Provides confidence scores and reasoning for each extracted attribute\n",
    "2. **Quality Control** - Identifies extractions that may need human review\n",
    "3. **OCR Analysis** - Considers OCR quality and document clarity in confidence scoring\n",
    "4. **Integration** - Seamlessly integrates with existing extraction workflows\n",
    "5. **Flexibility** - Configurable prompts and models for different assessment strategies\n",
    "6. **Multimodal** - Uses both text and image content for comprehensive assessment\n",
    "\n",
    "### Assessment Output Structure:\n",
    "\n",
    "The assessment service appends `explainability_info` to existing extraction results:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"document_class\": {\"type\": \"letter\"},\n",
    "  \"inference_result\": {\n",
    "    \"sender_name\": \"John Doe\",\n",
    "    \"sender_address\": \"123 Main St\"\n",
    "  },\n",
    "  \"explainability_info\": {\n",
    "    \"sender_name\": {\n",
    "      \"confidence_score\": 0.95,\n",
    "      \"confidence_reason\": \"Clear text found in document header with high OCR confidence\"\n",
    "    },\n",
    "    \"sender_address\": {\n",
    "      \"confidence_score\": 0.75,\n",
    "      \"confidence_reason\": \"Address partially visible but some characters unclear\"\n",
    "    }\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"extraction_time_seconds\": 2.3,\n",
    "    \"assessment_time_seconds\": 1.8\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This assessment capability enables more robust document processing workflows with built-in quality control and explainability features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
