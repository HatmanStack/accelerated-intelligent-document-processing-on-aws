{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Document Processing with IDP Common Package\n",
    "\n",
    "This notebook demonstrates how to process a document using the modular Document-based approach with:\n",
    "\n",
    "1. OCR Service - Convert a PDF document to text using AWS Textract\n",
    "2. Classification Service - Classify document pages into sections using Bedrock\n",
    "3. Extraction Service - Extract structured information from sections using Bedrock\n",
    "\n",
    "Each step uses the unified Document object model for data flow and consistency.\n",
    "\n",
    "> **Note**: This notebook uses real AWS services including S3, Textract, and Bedrock. You need valid AWS credentials with appropriate permissions to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "The IDP common package supports granular installation through extras. You can install:\n",
    "- `[core]` - Just core functionality \n",
    "- `[ocr]` - OCR service with Textract dependencies\n",
    "- `[classification]` - Classification service dependencies\n",
    "- `[extraction]` - Extraction service dependencies\n",
    "- `[image]` - Image processing dependencies\n",
    "- `[all]` - All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install common dependencies\n",
    "%pip install -q boto3 PyMuPDF\n",
    "\n",
    "# Install the IDP common package with all components\n",
    "%pip install -q \"../lib/idp_common_pkg[all]\"\n",
    "\n",
    "# Note: We can also install specific components like:\n",
    "# %pip install -q \"../lib/idp_common_pkg[ocr,classification,extraction]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup:\n",
      "METRIC_NAMESPACE: IDP-Notebook-Example\n",
      "AWS_REGION: us-west-2\n",
      "Input bucket: idp-example-input-912625584728-us-west-2\n",
      "Output bucket: idp-example-output-912625584728-us-west-2\n",
      "SAMPLE_PDF_PATH: ../samples/rvl_cdip_package.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Notebook-Example'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "os.environ['CONFIGURATION_TABLE_NAME'] = 'mock-config-table'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Define sample PDF path \n",
    "SAMPLE_PDF_PATH = \"../samples/rvl_cdip_package.pdf\"\n",
    "\n",
    "# Create unique bucket names based on account ID and region\n",
    "input_bucket_name = f\"idp-example-input-{account_id}-{region}\"\n",
    "output_bucket_name = f\"idp-example-output-{account_id}-{region}\"\n",
    "\n",
    "# Import base libraries\n",
    "from idp_common.models import Document, Status, Page, Section\n",
    "from idp_common import ocr, classification, extraction, get_config, metrics\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"METRIC_NAMESPACE: {os.environ.get('METRIC_NAMESPACE')}\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"Input bucket: {input_bucket_name}\")\n",
    "print(f\"Output bucket: {output_bucket_name}\")\n",
    "print(f\"SAMPLE_PDF_PATH: {SAMPLE_PDF_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up Mock Configuration\n",
    "\n",
    "Create a configuration for the IDP services that would normally come from DynamoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mocked configuration created for IDP services\n"
     ]
    }
   ],
   "source": [
    "# Import the IDP common module\n",
    "import sys\n",
    "from idp_common import get_config\n",
    "\n",
    "# Sample configuration that mimics what would be in DynamoDB\n",
    "MOCK_CONFIG = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "        \"name\": \"letter\",\n",
    "        \"description\": \"A formal written message that is typically sent from one person to another\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"sender_name\",\n",
    "            \"description\": \"The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"sender_address\",\n",
    "            \"description\": \"The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"recipient_name\",\n",
    "            \"description\": \"The name of the person or entity receiving the letter. Look for this after 'to', 'recipient', 'addressee', or at the beginning of the letter.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"recipient_address\",\n",
    "            \"description\": \"The physical address where the letter is to be delivered. Often labeled as 'to address' or 'delivery address', typically appearing below the recipient name.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"date\",\n",
    "            \"description\": \"The date when the letter was written. Look for a standalone date or text following phrases like 'written on' or 'dated'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"subject\",\n",
    "            \"description\": \"The topic or main point of the letter. Often preceded by 'subject', 'RE:', or 'regarding'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"letter_type\",\n",
    "            \"description\": \"The category or classification of the letter, such as 'complaint', 'inquiry', 'invitation', etc. May be indicated by 'type' or 'category'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"signature\",\n",
    "            \"description\": \"The handwritten name or mark of the sender at the end of the letter. May follow terms like 'signed by' or simply appear at the bottom of the document.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"cc\",\n",
    "            \"description\": \"Names of people who receive a copy of the letter in addition to the main recipient. Often preceded by 'cc', 'carbon copy', or 'copy to'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"reference_number\",\n",
    "            \"description\": \"An identifying number or code associated with the letter. Look for labels like 'ref', 'reference', or 'our ref'.\"\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"email\",\n",
    "        \"description\": \"An electronic message sent from one person to another over a computer network\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"from_address\",\n",
    "            \"description\": \"The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"to_address\",\n",
    "            \"description\": \"The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"cc_address\",\n",
    "            \"description\": \"Email addresses of additional recipients who receive copies. Look for 'cc' or 'carbon copy' followed by one or more email addresses.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"bcc_address\",\n",
    "            \"description\": \"Email addresses of hidden recipients. May be labeled as 'bcc' or 'blind copy'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"subject\",\n",
    "            \"description\": \"The topic of the email. Often preceded by 'subject', 'RE:', or 'regarding'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"date_sent\",\n",
    "            \"description\": \"The date and time when the email was sent. Look for 'date', 'sent on', or 'received', typically in the email header.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"attachments\",\n",
    "            \"description\": \"Files included with the email. May be indicated by 'attached', 'attachment', or 'enclosed', often with icons or file names.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"priority\",\n",
    "            \"description\": \"The urgency level of the email, such as 'high', 'normal', etc. Look for 'priority' or 'importance'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"thread_id\",\n",
    "            \"description\": \"An identifier for the email conversation. May be labeled as 'thread' or 'conversation', typically not visible to regular users.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"message_id\",\n",
    "            \"description\": \"A unique identifier for the specific email. Look for 'message id' or 'email id', usually hidden in the email metadata.\"\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"generic\",\n",
    "        \"description\": \"A general document type that doesn't fit into other specific categories\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"document_type\",\n",
    "            \"description\": \"The classification or category of the document. Look for terms like 'type', 'category', or 'class' that indicate what kind of document this is.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"document_date\",\n",
    "            \"description\": \"The date when the document was created. May be labeled as 'date', 'created on', or 'issued on'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"title\",\n",
    "            \"description\": \"The name or heading of the document. Often appears prominently at the beginning, may be labeled as 'title', 'heading', or 'subject'.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"content_summary\",\n",
    "            \"description\": \"A brief description of the document's contents. Look for 'summary', 'abstract', or 'overview', typically appearing early in the document.\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"comments\",\n",
    "            \"description\": \"Additional notes or remarks about the document. Look for sections labeled 'notes', 'remarks', or 'comments'.\"\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "  \"classification\": {\n",
    "    \"temperature\": \"0\",\n",
    "    \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "    \"system_prompt\": \"You are a document classification system that analyzes business documents, forms, and publications. Your sole task is to classify documents based on their visual layout and textual content. You must:\\n\\n1. Output only a JSON object containing a single \\\"class\\\" field with the classification label\\n2. Use exactly one of the predefined categories, using the exact spelling and case provided\\n3. Never include explanations, reasoning, or additional text in your response\\n4. Respond with nothing but the JSON containing the classification\\n\\nExample correct response:\\n{\\\"class\\\": \\\"letter\\\"}\\n\",\n",
    "    \"top_k\": \"200\",\n",
    "    \"task_prompt\": \"Classify this document into exactly one of these RVL-CDIP categories:\\n\\n{CLASS_NAMES_AND_DESCRIPTIONS}\\n\\nRespond only with a JSON object containing the class label. For example: {{\\\"class\\\": \\\"letter\\\"}}\\n\\n<document_ocr_data>\\n{DOCUMENT_TEXT}\\n</document_ocr_data>\\n\"\n",
    "  },\n",
    "  \"extraction\": {\n",
    "    \"temperature\": \"0\",\n",
    "    \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "    \"system_prompt\": \"You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\\n\",\n",
    "    \"top_k\": \"200\",\n",
    "    \"task_prompt\": \"<background>\\nYou are an expert in business document analysis and information extraction. \\nYou can understand and extract key information from business documents classified as type \\n{DOCUMENT_CLASS}.\\n</background>\\n<document_ocr_data>\\n{DOCUMENT_TEXT}\\n</document_ocr_data>\\n<task>\\nYour task is to take the unstructured text provided and convert it into a well-organized table format using JSON. Identify the main entities, attributes, or categories mentioned in the attributes list below and use them as keys in the JSON object. \\nThen, extract the relevant information from the text and populate the corresponding values in the JSON object. \\nGuidelines:\\nEnsure that the data is accurately represented and properly formatted within the JSON structure\\nInclude double quotes around all keys and values\\nDo not make up data - only extract information explicitly found in the document\\nDo not use /n for new lines, use a space instead\\nIf a field is not found or if unsure, return null\\nAll dates should be in MM/DD/YYYY format\\nDo not perform calculations or summations unless totals are explicitly given\\nIf an alias is not found in the document, return null\\nHere are the attributes you should extract:\\n<attributes>\\n{ATTRIBUTE_NAMES_AND_DESCRIPTIONS}\\n</attributes>\\n</task>\\n\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create a module-level attribute for the mock config\n",
    "sys.modules['idp_common'].mock_config = MOCK_CONFIG\n",
    "\n",
    "# Mock the get_config function\n",
    "def mock_get_config(*args, **kwargs):\n",
    "    return sys.modules['idp_common'].mock_config\n",
    "\n",
    "# Apply the patch to the module\n",
    "sys.modules['idp_common'].get_config = mock_get_config\n",
    "\n",
    "print(\"Mocked configuration created for IDP services\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up S3 Buckets and Upload Sample File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket idp-example-input-912625584728-us-west-2 already exists\n",
      "Bucket idp-example-output-912625584728-us-west-2 already exists\n",
      "Uploaded sample file to: s3://idp-example-input-912625584728-us-west-2/sample.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure both buckets exist\n",
    "ensure_bucket_exists(input_bucket_name)\n",
    "ensure_bucket_exists(output_bucket_name)\n",
    "\n",
    "# Upload the sample file to S3\n",
    "sample_file_key = \"sample.pdf\"\n",
    "with open(SAMPLE_PDF_PATH, 'rb') as file_data:\n",
    "    s3_client.upload_fileobj(file_data, input_bucket_name, sample_file_key)\n",
    "\n",
    "print(f\"Uploaded sample file to: s3://{input_bucket_name}/{sample_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Document and Process with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created document with ID: doc-insurance-package\n",
      "Status: QUEUED\n",
      "\n",
      "Processing document with OCR...\n",
      "OCR processing completed in 6.63 seconds\n",
      "Document status: OCR_COMPLETED\n",
      "Number of pages processed: 10\n",
      "\n",
      "Processed pages:\n",
      "Page 10:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/10/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/10/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/10/result.json\n",
      "Page 5:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/5/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/5/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/5/result.json\n",
      "Page 3:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/3/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/3/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/3/result.json\n",
      "Page 2:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/2/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/2/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/2/result.json\n",
      "Page 9:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/9/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/9/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/9/result.json\n",
      "Page 7:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/7/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/7/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/7/result.json\n",
      "Page 1:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/1/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/1/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/1/result.json\n",
      "Page 8:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/8/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/8/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/8/result.json\n",
      "Page 6:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/6/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/6/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/6/result.json\n",
      "Page 4:\n",
      "  Image URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/4/image.jpg\n",
      "  Raw Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/4/rawText.json\n",
      "  Parsed Text URI: s3://idp-example-output-912625584728-us-west-2/sample.pdf/pages/4/result.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new Document\n",
    "document = Document(\n",
    "    id=\"doc-insurance-package\",\n",
    "    input_bucket=input_bucket_name,\n",
    "    input_key=sample_file_key,\n",
    "    output_bucket=output_bucket_name,\n",
    "    status=Status.QUEUED\n",
    ")\n",
    "\n",
    "print(f\"Created document with ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "\n",
    "# Create OCR service with real Textract\n",
    "ocr_service = ocr.OcrService(\n",
    "    region=region,\n",
    "    enhanced_features=True  # Enable tables and forms\n",
    ")\n",
    "\n",
    "# Process document with OCR\n",
    "print(\"\\nProcessing document with OCR...\")\n",
    "start_time = time.time()\n",
    "document = ocr_service.process_document(document)\n",
    "ocr_time = time.time() - start_time\n",
    "\n",
    "print(f\"OCR processing completed in {ocr_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of pages processed: {document.num_pages}\")\n",
    "\n",
    "# Show pages information\n",
    "print(\"\\nProcessed pages:\")\n",
    "for page_id, page in document.pages.items():\n",
    "    print(f\"Page {page_id}:\")\n",
    "    print(f\"  Image URI: {page.image_uri}\")\n",
    "    print(f\"  Raw Text URI: {page.raw_text_uri}\")\n",
    "    print(f\"  Parsed Text URI: {page.parsed_text_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classify the Document with Bedrock Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.17s\n",
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.05s\n",
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.07s\n",
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.40s\n",
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.28s\n",
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.10s\n",
      "Bedrock throttling occurred (attempt 2/8). Error: Too many requests, please wait before trying again.. Backing off for 8.54s\n",
      "Bedrock throttling occurred (attempt 2/8). Error: Too many requests, please wait before trying again.. Backing off for 8.01s\n",
      "Bedrock throttling occurred (attempt 2/8). Error: Too many requests, please wait before trying again.. Backing off for 8.31s\n",
      "Bedrock throttling occurred (attempt 2/8). Error: Too many requests, please wait before trying again.. Backing off for 8.42s\n",
      "Bedrock throttling occurred (attempt 2/8). Error: Too many requests, please wait before trying again.. Backing off for 8.39s\n",
      "Bedrock throttling occurred (attempt 3/8). Error: Too many requests, please wait before trying again.. Backing off for 17.36s\n",
      "Bedrock throttling occurred (attempt 3/8). Error: Too many requests, please wait before trying again.. Backing off for 17.07s\n",
      "Bedrock throttling occurred (attempt 3/8). Error: Too many requests, please wait before trying again.. Backing off for 17.12s\n",
      "Bedrock throttling occurred (attempt 3/8). Error: Too many requests, please wait before trying again.. Backing off for 16.45s\n",
      "Bedrock throttling occurred (attempt 4/8). Error: Too many requests, please wait before trying again.. Backing off for 33.75s\n",
      "Bedrock throttling occurred (attempt 4/8). Error: Too many requests, please wait before trying again.. Backing off for 32.87s\n",
      "Unknown document type 'invoice' for page 5, valid types are: letter, generic, email\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed in 102.48 seconds\n",
      "Document status: CLASSIFIED\n",
      "\n",
      "Page classification results:\n",
      "Page 10: letter (confidence: 1.00)\n",
      "Page 5: invoice (confidence: 1.00)\n",
      "Page 3: email (confidence: 1.00)\n",
      "Page 2: generic (confidence: 1.00)\n",
      "Page 9: generic (confidence: 1.00)\n",
      "Page 7: generic (confidence: 1.00)\n",
      "Page 1: letter (confidence: 1.00)\n",
      "Page 8: generic (confidence: 1.00)\n",
      "Page 6: generic (confidence: 1.00)\n",
      "Page 4: generic (confidence: 1.00)\n",
      "\n",
      "Sections detected:\n",
      "Section 1: letter\n",
      "  Pages: ['1']\n",
      "  Confidence: 1.00\n",
      "Section 2: generic\n",
      "  Pages: ['2']\n",
      "  Confidence: 1.00\n",
      "Section 3: email\n",
      "  Pages: ['3']\n",
      "  Confidence: 1.00\n",
      "Section 4: generic\n",
      "  Pages: ['4']\n",
      "  Confidence: 1.00\n",
      "Section 5: invoice\n",
      "  Pages: ['5']\n",
      "  Confidence: 1.00\n",
      "Section 6: generic\n",
      "  Pages: ['6', '7', '8', '9']\n",
      "  Confidence: 1.00\n",
      "Section 7: letter\n",
      "  Pages: ['10']\n",
      "  Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Create classification service with Bedrock backend\n",
    "classification_service = classification.ClassificationService(\n",
    "    config=get_config(),\n",
    "    backend=\"bedrock\"  # Using real Bedrock backend\n",
    ")\n",
    "\n",
    "# Classify the document\n",
    "print(\"\\nClassifying document...\")\n",
    "start_time = time.time()\n",
    "document = classification_service.classify_document(document)\n",
    "classification_time = time.time() - start_time\n",
    "\n",
    "print(f\"Classification completed in {classification_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "\n",
    "# Show classification results\n",
    "print(\"\\nPage classification results:\")\n",
    "for page_id, page in document.pages.items():\n",
    "    print(f\"Page {page_id}: {page.classification} (confidence: {page.confidence:.2f})\")\n",
    "\n",
    "print(\"\\nSections detected:\")\n",
    "for section in document.sections:\n",
    "    print(f\"Section {section.section_id}: {section.classification}\")\n",
    "    print(f\"  Pages: {section.page_ids}\")\n",
    "    print(f\"  Confidence: {section.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Information from Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting information from document sections...\n",
      "\n",
      "Processing section 1 (class: letter)\n",
      "Extraction completed in 6.46 seconds\n",
      "Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/1/result.json\n",
      "Processed 1 sections\n",
      "\n",
      "Processing section 2 (class: generic)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bedrock throttling occurred (attempt 1/8). Error: Too many requests, please wait before trying again.. Backing off for 4.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed in 17.61 seconds\n",
      "Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/2/result.json\n",
      "Processed 2 sections\n",
      "\n",
      "Processing section 3 (class: email)\n",
      "Extraction completed in 15.86 seconds\n",
      "Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/3/result.json\n",
      "Processed 3 sections\n",
      "\n",
      "Extraction for max 3 sections complete.\n",
      "\n",
      "Extraction for all sections complete.\n"
     ]
    }
   ],
   "source": [
    "# Create extraction service with real Bedrock\n",
    "extraction_service = extraction.ExtractionService(config=get_config())\n",
    "\n",
    "print(\"\\nExtracting information from document sections...\")\n",
    "\n",
    "# Create individual document for each section (following our pattern for Lambda functions)\n",
    "extracted_results = {}\n",
    "\n",
    "n=0\n",
    "for section in document.sections:\n",
    "    print(f\"\\nProcessing section {section.section_id} (class: {section.classification})\")\n",
    "    \n",
    "    # Create a section-specific document\n",
    "    section_document = Document(\n",
    "        id=document.id,\n",
    "        input_bucket=document.input_bucket,\n",
    "        input_key=document.input_key,\n",
    "        output_bucket=document.output_bucket,\n",
    "        status=document.status,\n",
    "        sections=[section]\n",
    "    )\n",
    "    \n",
    "    # Add only pages needed for this section\n",
    "    needed_pages = {}\n",
    "    for page_id in section.page_ids:\n",
    "        if page_id in document.pages:\n",
    "            needed_pages[page_id] = document.pages[page_id]\n",
    "    section_document.pages = needed_pages\n",
    "    \n",
    "    # Process section\n",
    "    start_time = time.time()\n",
    "    section_document = extraction_service.process_document_section(\n",
    "        document=section_document,\n",
    "        section_id=section.section_id\n",
    "    )\n",
    "    extraction_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Extraction completed in {extraction_time:.2f} seconds\")\n",
    "    \n",
    "    # Get the updated section\n",
    "    updated_section = section_document.sections[0]\n",
    "    print(f\"Extraction result URI: {updated_section.extraction_result_uri}\")\n",
    "    \n",
    "    # Store results for later use\n",
    "    extracted_results[section.section_id] = {\n",
    "        \"section\": updated_section,\n",
    "        \"result_uri\": updated_section.extraction_result_uri\n",
    "    }\n",
    "    n += 1\n",
    "    print(f\"Processed {n} sections\")\n",
    "    if n >= 3:\n",
    "        print(\"\\nExtraction for max 3 sections complete.\")\n",
    "        break\n",
    "\n",
    "print(\"\\nExtraction for all sections complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Extraction Results from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading extraction results from S3...\n",
      "\n",
      "Results for section 1 (class: letter)\n",
      "S3 URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/1/result.json\n",
      "Extracted attributes:\n",
      "  sender_name: Will E. Clark\n",
      "  sender_address: 206 Maple Street, P.O. Box 1056, Murray, Kentucky 42071-1056\n",
      "  recipient_name: The Honorable Wendell H. Ford\n",
      "  recipient_address: United States Senate, Washington, D. C. 20510\n",
      "  date: 10/31/1995\n",
      "  subject: Opposition to the 'Commitment to Our Children' petition\n",
      "  letter_type: None\n",
      "  signature: Will E. Clark\n",
      "  cc: None\n",
      "  reference_number: TNJB 0008497\n",
      "\n",
      "Results for section 2 (class: generic)\n",
      "S3 URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/2/result.json\n",
      "Extracted attributes:\n",
      "  document_type: LAB SERVICES CONSISTENCY REPORT\n",
      "  document_date: 07/28/1993\n",
      "  title: LAB SERVICES CONSISTENCY REPORT\n",
      "  content_summary: None\n",
      "  comments: None\n",
      "\n",
      "Results for section 3 (class: email)\n",
      "S3 URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/3/result.json\n",
      "Extracted attributes:\n",
      "  from_address: Kelahan, Ben\n",
      "  to_address: 'TI New York'; 'TI Minnesota'\n",
      "  cc_address: Ashley Bratich (MSMAIL)\n",
      "  bcc_address: None\n",
      "  subject: FW: Morning Team Notes 4/20\n",
      "  date_sent: 04/18/1998\n",
      "  attachments: None\n",
      "  priority: None\n",
      "  thread_id: None\n",
      "  message_id: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to parse S3 URIs\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "# Helper function to load JSON from S3\n",
    "def load_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(content)\n",
    "\n",
    "print(\"Loading extraction results from S3...\\n\")\n",
    "\n",
    "for section_id, data in extracted_results.items():\n",
    "    # Load the extraction results from S3\n",
    "    uri = data['result_uri']\n",
    "    try:\n",
    "        result_data = load_json_from_s3(uri)\n",
    "        \n",
    "        # Extract the inference results\n",
    "        if \"inference_result\" in result_data:\n",
    "            extraction_results = result_data[\"inference_result\"]\n",
    "        else:\n",
    "            extraction_results = result_data\n",
    "            \n",
    "        # Print out section and extraction results\n",
    "        print(f\"Results for section {section_id} (class: {data['section'].classification})\")\n",
    "        print(f\"S3 URI: {uri}\")\n",
    "        print(\"Extracted attributes:\")\n",
    "        for key, value in extraction_results.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results from {uri}: {str(e)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Document Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Document State:\n",
      "Document ID: doc-insurance-package\n",
      "Status: PROCESSED\n",
      "Number of pages: 10\n",
      "Number of sections: 7\n",
      "\n",
      "Section summary:\n",
      "  Section 1: letter\n",
      "    Pages: ['1']\n",
      "    Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/1/result.json\n",
      "  Section 2: generic\n",
      "    Pages: ['2']\n",
      "    Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/2/result.json\n",
      "  Section 3: email\n",
      "    Pages: ['3']\n",
      "    Extraction result URI: s3://idp-example-output-912625584728-us-west-2/insurance_package.pdf/sections/3/result.json\n",
      "  Section 4: generic\n",
      "    Pages: ['4']\n",
      "    Extraction result URI: None\n",
      "  Section 5: invoice\n",
      "    Pages: ['5']\n",
      "    Extraction result URI: None\n",
      "  Section 6: generic\n",
      "    Pages: ['6', '7', '8', '9']\n",
      "    Extraction result URI: None\n",
      "  Section 7: memorandum\n",
      "    Pages: ['10']\n",
      "    Extraction result URI: None\n",
      "\n",
      "Document can be serialized to JSON:\n",
      "{\n",
      "  \"id\": \"doc-insurance-package\",\n",
      "  \"input_bucket\": \"idp-example-input-912625584728-us-west-2\",\n",
      "  \"input_key\": \"insurance_package.pdf\",\n",
      "  \"output_bucket\": \"idp-example-output-912625584728-us-west-2\",\n",
      "  \"status\": \"PROCESSED\",\n",
      "  \"queued_time\": null,\n",
      "  \"start_time\": null,\n",
      "  \"completion_time\": null,\n",
      "  \"workflow_execution_arn\": null,\n",
      "  \"num_pages\": 10,\n",
      "  \"evaluation_report_uri\": null,\n",
      "  \"errors\": [],\n",
      "  \"metering\": {\n",
      "    \"textract/analyze_document\": {\n",
      "      \"pages\": 10\n",
      "    },\n",
      "    \"bedrock/us.amazon.n...\n",
      "(truncated for display)\n"
     ]
    }
   ],
   "source": [
    "# Update document status to PROCESSED\n",
    "document.status = Status.PROCESSED\n",
    "\n",
    "# Update document sections with extraction results\n",
    "for section_id, data in extracted_results.items():\n",
    "    # Find section in document\n",
    "    for i, section in enumerate(document.sections):\n",
    "        if section.section_id == section_id:\n",
    "            document.sections[i] = data['section']\n",
    "\n",
    "# Display final document state\n",
    "print(\"Final Document State:\")\n",
    "print(f\"Document ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "print(f\"Number of sections: {len(document.sections)}\")\n",
    "\n",
    "print(\"\\nSection summary:\")\n",
    "for section in document.sections:\n",
    "    print(f\"  Section {section.section_id}: {section.classification}\")\n",
    "    print(f\"    Pages: {section.page_ids}\")\n",
    "    print(f\"    Extraction result URI: {section.extraction_result_uri}\")\n",
    "\n",
    "# Show document serialization capabilities\n",
    "print(\"\\nDocument can be serialized to JSON:\")\n",
    "document_dict = document.to_dict()\n",
    "document_json = json.dumps(document_dict, indent=2)[:500]  # Truncate for display\n",
    "print(f\"{document_json}...\")\n",
    "print(\"(truncated for display)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Clean Up (Optional)\n",
    "\n",
    "If you want to clean up the resources created during this demo, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete objects in a bucket\n",
    "def delete_bucket_objects(bucket_name):\n",
    "    try:\n",
    "        # List all objects in the bucket\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            delete_keys = {'Objects': [{'Key': obj['Key']} for obj in response['Contents']]}\n",
    "            s3_client.delete_objects(Bucket=bucket_name, Delete=delete_keys)\n",
    "            print(f\"Deleted all objects in bucket {bucket_name}\")\n",
    "        else:\n",
    "            print(f\"Bucket {bucket_name} is already empty\")\n",
    "            \n",
    "        # Delete bucket\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Deleted bucket {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up bucket {bucket_name}: {str(e)}\")\n",
    "\n",
    "# Uncomment the following lines to delete the buckets\n",
    "# print(\"Cleaning up resources...\")\n",
    "# delete_bucket_objects(input_bucket_name)\n",
    "# delete_bucket_objects(output_bucket_name)\n",
    "# print(\"Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the end-to-end processing flow using real AWS services and the unified Document model:\n",
    "\n",
    "1. **Document Creation** - Initialize a Document object with input/output locations\n",
    "2. **OCR Processing** - Convert PDF to text using AWS Textract via OcrService\n",
    "3. **Classification** - Identify document types and sections with Claude via ClassificationService\n",
    "4. **Extraction** - Extract structured information with Claude via ExtractionService\n",
    "5. **Document Model** - Document object is consistently used between all services\n",
    "6. **Result Storage** - Extraction results are stored in S3 with URIs tracked in the Document\n",
    "\n",
    "Key benefits of this approach:\n",
    "\n",
    "1. **Modularity** - Each service has a clear responsibility\n",
    "2. **Consistency** - Same data model flows through the entire pipeline\n",
    "3. **Performance** - Focused document pattern reduces resource usage\n",
    "4. **Flexibility** - Support for multiple backends (Bedrock, SageMaker)\n",
    "5. **Maintainability** - Standardized patterns across services\n",
    "\n",
    "This example uses a real workflow with:\n",
    "1. Real S3 buckets (created specifically for this demo)\n",
    "2. Real AWS Textract OCR processing\n",
    "3. Real Claude 3 Sonnet inferencing via Bedrock\n",
    "4. A real document sample (insurance_package.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the end-to-end processing flow using the unified Document model:\n",
    "\n",
    "1. **Document Creation** - Initialize a Document object with input/output locations\n",
    "2. **OCR Processing** - Convert PDF to text using OcrService\n",
    "3. **Classification** - Identify document types and sections with ClassificationService\n",
    "4. **Extraction** - Extract structured information with ExtractionService\n",
    "5. **Document Model** - Document object is consistently used between all services\n",
    "6. **Result Storage** - Extraction results are stored in S3 with URIs tracked in the Document\n",
    "\n",
    "Key benefits of this approach:\n",
    "\n",
    "1. **Modularity** - Each service has a clear responsibility\n",
    "2. **Consistency** - Same data model flows through the entire pipeline\n",
    "3. **Performance** - Focused document pattern reduces resource usage\n",
    "4. **Flexibility** - Support for multiple backends (Bedrock, SageMaker)\n",
    "5. **Maintainability** - Standardized patterns across services\n",
    "\n",
    "To use in a real environment, you would need:\n",
    "1. Valid AWS credentials\n",
    "2. Access to required AWS services (S3, Bedrock, etc.)\n",
    "3. Configuration stored in DynamoDB\n",
    "4. Real document files in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Simulate Loading the Extraction Results from S3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
