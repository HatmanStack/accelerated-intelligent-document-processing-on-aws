{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteria Validation Testing Notebook\n",
    "\n",
    "This notebook demonstrates how to use the criteria validation module for healthcare/insurance prior authorization validation.\n",
    "\n",
    "The criteria validation module:\n",
    "1. Processes user history documents from S3\n",
    "2. Validates them against configurable criteria questions\n",
    "3. Generates recommendations (Pass/Fail/Information Not Found)\n",
    "4. Supports async processing with rate limiting\n",
    "5. Tracks costs and metering data\n",
    "\n",
    "> **Note**: This notebook uses AWS services including S3 and Bedrock. You need valid AWS credentials with appropriate permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOTDIR=\"../\"\n",
    "\n",
    "# First uninstall existing package\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package including criteria validation\n",
    "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[all]\"\n",
    "\n",
    "# Install additional dependencies including nest_asyncio for Jupyter async support\n",
    "%pip install -q pydantic nest_asyncio\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import datetime\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Fix for Jupyter async event loop conflicts\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import criteria validation module\n",
    "from idp_common.criteria_validation import CriteriaValidationService, CriteriaValidationResult\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger('idp_common.criteria_validation').setLevel(logging.DEBUG)\n",
    "logging.getLogger('idp_common.bedrock').setLevel(logging.INFO)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-CriteriaValidation-Test'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Create unique bucket names\n",
    "user_history_bucket = os.getenv(\"CRITERIA_USER_HISTORY_BUCKET\", f\"criteria-validation-user-history-{account_id}-{region}\")\n",
    "criteria_bucket = os.getenv(\"CRITERIA_BUCKET\", f\"criteria-validation-criteria-{account_id}-{region}\")\n",
    "output_bucket = os.getenv(\"CRITERIA_OUTPUT_BUCKET\", f\"criteria-validation-output-{account_id}-{region}\")\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"User History bucket: {user_history_bucket}\")\n",
    "print(f\"Criteria bucket: {criteria_bucket}\")\n",
    "print(f\"Output bucket: {output_bucket}\")\n",
    "print(\"\\nâœ… Async event loop patched for Jupyter compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up S3 Buckets and Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to create bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure all buckets exist\n",
    "ensure_bucket_exists(user_history_bucket)\n",
    "ensure_bucket_exists(criteria_bucket)\n",
    "ensure_bucket_exists(output_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample user history\n",
    "sample_user_history = \"\"\"Patient: John Doe\n",
    "Date: 2024-01-15\n",
    "\n",
    "Medical History:\n",
    "The patient has been diagnosed with rheumatoid arthritis (RA) and has failed treatment with methotrexate and two TNF inhibitors. \n",
    "The treating physician, Dr. Sarah Johnson, has recommended starting immunotherapy with infliximab.\n",
    "\n",
    "Treatment Plan:\n",
    "- Infliximab will be administered at the infusion center under direct supervision of trained medical staff\n",
    "- The facility is equipped with emergency response equipment including epinephrine for anaphylaxis treatment\n",
    "- Initial dose: 3 mg/kg at 0, 2, and 6 weeks, then every 8 weeks\n",
    "- Pre-medication with antihistamines and corticosteroids as per protocol\n",
    "\n",
    "Facility Information:\n",
    "The treatment will be provided at Memorial Hospital Infusion Center, which has 24/7 emergency support and trained nursing staff.\n",
    "\"\"\"\n",
    "\n",
    "# Create sample criteria\n",
    "sample_criteria = {\n",
    "    \"criteria\": [\n",
    "        \"Will the immunotherapy be administered under the supervision of an appropriately trained physician?\",\n",
    "        \"Is the facility equipped to treat anaphylaxis?\",\n",
    "        \"Has the physician determined an appropriate dosage regimen and progression schedule?\",\n",
    "        \"Are there adequate safety protocols in place for infusion reactions?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Upload sample data\n",
    "request_id = \"TEST-\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "request_prefix = \"Prior-Auth\"\n",
    "\n",
    "# Upload user history\n",
    "user_history_key = f\"{request_prefix}-{request_id}/extracted_text/patient_history.txt\"\n",
    "s3_client.put_object(\n",
    "    Bucket=user_history_bucket,\n",
    "    Key=user_history_key,\n",
    "    Body=sample_user_history.encode('utf-8')\n",
    ")\n",
    "print(f\"Uploaded user history to: s3://{user_history_bucket}/{user_history_key}\")\n",
    "\n",
    "# Upload criteria\n",
    "criteria_key = \"administration_requirements.json\"\n",
    "s3_client.put_object(\n",
    "    Bucket=criteria_bucket,\n",
    "    Key=criteria_key,\n",
    "    Body=json.dumps(sample_criteria).encode('utf-8')\n",
    ")\n",
    "print(f\"Uploaded criteria to: s3://{criteria_bucket}/{criteria_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Criteria Validation Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for criteria validation\n",
    "validation_config = {\n",
    "    # Model configuration\n",
    "    \"model_id\": \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 20,\n",
    "    \"top_p\": 0.01,\n",
    "    \"max_tokens\": 4096,\n",
    "    \n",
    "    # Bucket configuration\n",
    "    \"request_bucket\": user_history_bucket,\n",
    "    \"request_history_prefix\": request_prefix,\n",
    "    \"criteria_bucket\": criteria_bucket,\n",
    "    \"output_bucket\": output_bucket,\n",
    "    \n",
    "    # Criteria types to validate\n",
    "    \"criteria_types\": [\"administration_requirements\"],\n",
    "    \n",
    "    # Recommendation options\n",
    "    \"recommendation_options\": \"\"\"Pass: The requirement criteria are fully met.\n",
    "Fail: The requirement is partially met or requires additional information.\n",
    "Information Not Found: No relevant data exists in the user history.\"\"\",\n",
    "    \n",
    "    # Prompts from original system\n",
    "    \"system_prompt\": \"\"\"You are a specialized insurance evaluator tasked with determining the eligibility of insurance coverage based on a patient's user history and a set of criterias. \n",
    "Each evaluation should be supported by precise reasoning, with citations from the user history where applicable.\"\"\",\n",
    "    \n",
    "    \"task_prompt\": \"\"\"Consider the patients user history inforamtion provided insided <user_history></user_history> XML tags.\n",
    "\n",
    "<user_history>\n",
    " <source_filepath>\n",
    " {source_filepath}\n",
    " </source_filepath>\n",
    "\n",
    " <content>\n",
    " {content}\n",
    " </content>\n",
    "</user_history>\n",
    "\n",
    "<criteria>\n",
    "<criteria_type>\n",
    "{criteria_type}\n",
    "</criteria_type>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "</criteria>\n",
    "\n",
    "<instruction>\n",
    "Evaluate the patient's insurance eligibility for each question provided insided <question></question> XML tags  and patients user history information provided inside <user_history></user_history> XML tags. \n",
    "\n",
    "Your Task:\n",
    "\n",
    "For each question, provide:\n",
    "\n",
    "Decision: Carefully review each requirement in the context of the patient's user history to decide if it is \"Pass,\" \"Fail,\" or \"Information Not Found\" and select one of the following options:\n",
    "\n",
    "{recommendation_options}\n",
    "\n",
    "Reasoning: Provide a brief explanation for the decision, highlighting any relevant details or absence of data.\n",
    "Citations: When applicable, cite specific sections of the user history (e.g., page numbers, sections, S3 URI) that support your decision.\n",
    "\n",
    "Json Response format:\n",
    "{{\n",
    " \"criteria_type\" : \"question/criteria type mentioned inside <criteria_type></criteria_type> XML tags\"\n",
    " \"source_file\" : [\"list of source_filepath that supports the recommendation\"]\n",
    " \"question\" : \"question Description\"\n",
    " \"Recommendation\" : \"This should be one of the following: Pass, Fail, or Information Not Found\"\n",
    " \"Reasoning\" : \"Provide a thorough explanation, reasoning, and any citations from the source_file in a Single  paragraph explanation without line breaks\"\n",
    "}}\n",
    "All fields must be included in the JSON response, even if some values are unavailable (leave them as empty strings if necessary).\n",
    "Ensure that the output is a valid JSON object and strictly adheres to the format provided above.\n",
    "criteria_type must be included as a field within the JSON and not as the primary key.\n",
    "The reasoning field must include detailed explanations and citations to support the decision.\n",
    "\n",
    "</instruction>\n",
    "\n",
    "Follow instructions provided inside <instruction></instruction> XML tags. \n",
    "Provide the output in a Json format inside <response></response> XML tags. Do not include any space after <response> tag and before </response> tag.\"\"\",\n",
    "    \n",
    "    # Async processing configuration\n",
    "    \"criteria_validation\": {\n",
    "        \"semaphore\": 3,  # Concurrent request limit\n",
    "        \"max_chunk_size\": 180000,  # Max tokens per chunk\n",
    "        \"token_size\": 4,  # Average chars per token\n",
    "        \"overlap_percentage\": 10,  # Chunk overlap %\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuration created for criteria validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Criteria Validation (Fixed for Jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the service\n",
    "criteria_service = CriteriaValidationService(\n",
    "    region=region,\n",
    "    config=validation_config\n",
    ")\n",
    "\n",
    "print(f\"\\nValidating request: {request_id}\")\n",
    "print(\"This may take a few moments...\")\n",
    "\n",
    "# Run validation - now works in Jupyter thanks to nest_asyncio\n",
    "start_time = time.time()\n",
    "result = criteria_service.validate_request(\n",
    "    request_id=request_id,\n",
    "    config=validation_config\n",
    ")\n",
    "validation_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nValidation completed in {validation_time:.2f} seconds\")\n",
    "print(f\"Request ID: {result.request_id}\")\n",
    "print(f\"Criteria Type: {result.criteria_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display validation responses\n",
    "print(\"\\n=== Validation Results ===\")\n",
    "\n",
    "# Helper function to parse S3 URIs\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "# Read results from S3\n",
    "if result.metadata and 'output_uris' in result.metadata:\n",
    "    for output_uri in result.metadata['output_uris']:\n",
    "        print(f\"\\nReading results from: {output_uri}\")\n",
    "        \n",
    "        # Parse S3 URI and read content\n",
    "        bucket, key = parse_s3_uri(output_uri)\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        responses = json.loads(content)\n",
    "        \n",
    "        # Display each validation response\n",
    "        for idx, response_item in enumerate(responses):\n",
    "            print(f\"\\n--- Criteria {idx + 1} ---\")\n",
    "            print(f\"Question: {response_item.get('question', 'N/A')}\")\n",
    "            print(f\"Recommendation: {response_item.get('Recommendation', 'N/A')}\")\n",
    "            print(f\"Reasoning: {response_item.get('Reasoning', 'N/A')}\")\n",
    "            print(f\"Source Files: {response_item.get('source_file', [])}\")\n",
    "else:\n",
    "    print(\"No validation results found in metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Display Metering and Cost Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metering information with support for nested model-specific structure\n",
    "print(\"\\n=== Token Usage ===\")\n",
    "if result.metering:\n",
    "    # First try the old flat structure for backward compatibility\n",
    "    if 'total_input_tokens' in result.metering:\n",
    "        print(f\"Total Input Tokens: {result.metering.get('total_input_tokens', 0):,}\")\n",
    "        print(f\"Total Output Tokens: {result.metering.get('total_output_tokens', 0):,}\")\n",
    "    else:\n",
    "        # Handle new nested structure: {model_key: {inputTokens: X, outputTokens: Y, totalTokens: Z}}\n",
    "        total_input_tokens = 0\n",
    "        total_output_tokens = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        print(\"\\nPer-Model Token Usage:\")\n",
    "        for model_key, usage in result.metering.items():\n",
    "            if isinstance(usage, dict) and ('inputTokens' in usage or 'outputTokens' in usage):\n",
    "                input_tokens = usage.get('inputTokens', 0)\n",
    "                output_tokens = usage.get('outputTokens', 0)\n",
    "                model_total = usage.get('totalTokens', input_tokens + output_tokens)\n",
    "                \n",
    "                # Extract model name from the key for cleaner display\n",
    "                model_name = model_key.split('/')[-1] if '/' in model_key else model_key\n",
    "                print(f\"  {model_name}:\")\n",
    "                print(f\"    Input Tokens: {input_tokens:,}\")\n",
    "                print(f\"    Output Tokens: {output_tokens:,}\")\n",
    "                print(f\"    Total Tokens: {model_total:,}\")\n",
    "                \n",
    "                # Add to totals\n",
    "                total_input_tokens += input_tokens\n",
    "                total_output_tokens += output_tokens\n",
    "                total_tokens += model_total\n",
    "        \n",
    "        print(f\"\\nTotal Across All Models:\")\n",
    "        print(f\"  Total Input Tokens: {total_input_tokens:,}\")\n",
    "        print(f\"  Total Output Tokens: {total_output_tokens:,}\")\n",
    "        print(f\"  Grand Total Tokens: {total_tokens:,}\")\n",
    "    \n",
    "    # Display per-criteria usage if available (legacy structure)\n",
    "    criteria_usage = result.metering.get('criteria_usage', {})\n",
    "    if criteria_usage:\n",
    "        print(\"\\nPer-Criteria Usage:\")\n",
    "        for criteria_type, usage in criteria_usage.items():\n",
    "            print(f\"  {criteria_type}:\")\n",
    "            print(f\"    Input Tokens: {usage.get('input_tokens', 0):,}\")\n",
    "            print(f\"    Output Tokens: {usage.get('output_tokens', 0):,}\")\n",
    "else:\n",
    "    print(\"No metering data available\")\n",
    "\n",
    "# Display detailed metering structure for debugging (optional)\n",
    "print(\"\\n=== Debug: Raw Metering Data Structure ===\")\n",
    "if result.metering:\n",
    "    print(json.dumps(result.metering, indent=2))\n",
    "else:\n",
    "    print(\"No raw metering data to display\")\n",
    "\n",
    "# Display timing information\n",
    "print(\"\\n=== Timing Information ===\")\n",
    "if result.metadata and 'timing' in result.metadata:\n",
    "    timing = result.metadata['timing']\n",
    "    print(f\"Total Duration: {timing.get('total_duration', 0):.2f} seconds\")\n",
    "    \n",
    "    # Display per-criteria timing\n",
    "    criteria_timing = timing.get('criteria_processing_time', [])\n",
    "    if criteria_timing:\n",
    "        print(\"\\nPer-Criteria Processing Time:\")\n",
    "        for item in criteria_timing:\n",
    "            print(f\"  {item['criteria_type']}: {item['duration']:.2f} seconds\")\n",
    "else:\n",
    "    print(\"No timing data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Clean Up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete objects in a bucket\n",
    "def delete_bucket_objects(bucket_name):\n",
    "    try:\n",
    "        # List all objects in the bucket\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            delete_keys = {'Objects': [{'Key': obj['Key']} for obj in response['Contents']]}\n",
    "            s3_client.delete_objects(Bucket=bucket_name, Delete=delete_keys)\n",
    "            print(f\"Deleted all objects in bucket {bucket_name}\")\n",
    "        else:\n",
    "            print(f\"Bucket {bucket_name} is already empty\")\n",
    "            \n",
    "        # Delete bucket\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Deleted bucket {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up bucket {bucket_name}: {str(e)}\")\n",
    "\n",
    "# Uncomment the following lines to delete the buckets\n",
    "# print(\"Cleaning up resources...\")\n",
    "# delete_bucket_objects(user_history_bucket)\n",
    "# delete_bucket_objects(criteria_bucket)\n",
    "# delete_bucket_objects(output_bucket)\n",
    "# print(\"Cleanup complete\")\n",
    "\n",
    "print(\"\\nâœ… Notebook completed successfully!\")\n",
    "print(\"Uncomment the cleanup section above to delete the test S3 buckets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the criteria validation module capabilities:\n",
    "\n",
    "1. **Async Processing** - Concurrent evaluation of multiple criteria questions\n",
    "2. **Rate Limiting** - Built-in semaphore control for API rate limits\n",
    "3. **Chunking** - Automatic text chunking for large documents\n",
    "4. **Cost Tracking** - Comprehensive token usage and metering\n",
    "5. **Pydantic Validation** - Strong data validation for inputs/outputs\n",
    "6. **S3 Integration** - Seamless reading/writing of validation data\n",
    "7. **Jupyter Compatibility** - Fixed async event loop conflicts with nest_asyncio\n",
    "\n",
    "Key benefits:\n",
    "- **Scalability** - Process multiple criteria types concurrently\n",
    "- **Reliability** - Built-in error handling and retry logic\n",
    "- **Consistency** - Uses common bedrock client for standardized LLM interactions\n",
    "- **Flexibility** - Configurable prompts and criteria types\n",
    "- **Traceability** - Complete audit trail with source file citations\n",
    "\n",
    "The module is designed for healthcare/insurance prior authorization validation but can be adapted for other business rule validation use cases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiic-idp-accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
